{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c30b7efda33442b2868da4b27ba7e44e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b69f6eb91c7f4de0bff368d557d03f27",
              "IPY_MODEL_c84894f20a774360ab65834829b2f69d",
              "IPY_MODEL_bdaf43cceade4273a074a0103393985f"
            ],
            "layout": "IPY_MODEL_9f15d85cc37f46699375e5b4d1db09d8"
          }
        },
        "b69f6eb91c7f4de0bff368d557d03f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26ad7babc828402497334f95a771ddff",
            "placeholder": "​",
            "style": "IPY_MODEL_9fc9b470840649a7a9b285d211748424",
            "value": "Validation sanity check: 100%"
          }
        },
        "c84894f20a774360ab65834829b2f69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e31d8d12b0a483fbfc83d00b7fc10f0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_062ca9cd2e48412eb9a6612b7bbe7df3",
            "value": 1
          }
        },
        "bdaf43cceade4273a074a0103393985f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b2282bee32a4a398f0782b9451bd7f1",
            "placeholder": "​",
            "style": "IPY_MODEL_c68c3fd0e8164c3584f34df75f4db4a0",
            "value": " 2/2 [00:00&lt;00:00, 19.02it/s]"
          }
        },
        "9f15d85cc37f46699375e5b4d1db09d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "26ad7babc828402497334f95a771ddff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fc9b470840649a7a9b285d211748424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e31d8d12b0a483fbfc83d00b7fc10f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "062ca9cd2e48412eb9a6612b7bbe7df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b2282bee32a4a398f0782b9451bd7f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c68c3fd0e8164c3584f34df75f4db4a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b17f8f6cafa440487e05c1ec1139e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2a457b2fe934c48aa9d5a9a284c6ebc",
              "IPY_MODEL_5dd2622cc1b241618c12804873c04ec0",
              "IPY_MODEL_0c56620dfc9e4e5b8ba4078158cf55d4"
            ],
            "layout": "IPY_MODEL_46637e1988e84ddebde5a7b1589be83d"
          }
        },
        "c2a457b2fe934c48aa9d5a9a284c6ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82dcadaeed944512b3cda4a217f51692",
            "placeholder": "​",
            "style": "IPY_MODEL_b62b9d39e7da4ac687cec1f506f85c34",
            "value": "Epoch 4: 100%"
          }
        },
        "5dd2622cc1b241618c12804873c04ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5d99e14c29f49ad8f9f707ca3f45333",
            "max": 16250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63681e37d7d340f29b2f4d556903f59e",
            "value": 16250
          }
        },
        "0c56620dfc9e4e5b8ba4078158cf55d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f295f2448744f46a6dfab50d5c11e33",
            "placeholder": "​",
            "style": "IPY_MODEL_9ab9ba6399d34d07a97d1b365d55aaea",
            "value": " 16250/16250 [03:42&lt;00:00, 72.99it/s, loss=1.133, v_num=0]"
          }
        },
        "46637e1988e84ddebde5a7b1589be83d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "82dcadaeed944512b3cda4a217f51692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b62b9d39e7da4ac687cec1f506f85c34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5d99e14c29f49ad8f9f707ca3f45333": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63681e37d7d340f29b2f4d556903f59e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f295f2448744f46a6dfab50d5c11e33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ab9ba6399d34d07a97d1b365d55aaea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50a39c1dd43a4c458922f5efd1c47b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91d54df5d70c41b88d0706b79843ff23",
              "IPY_MODEL_e4595991bb1e472f9855006ab835cc5c",
              "IPY_MODEL_2349e30967684cd98f9090fa95db5721"
            ],
            "layout": "IPY_MODEL_2f02ac90c158475b89484423a0b367df"
          }
        },
        "91d54df5d70c41b88d0706b79843ff23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dba43bb81bc04787aa24cd8d3a18ed72",
            "placeholder": "​",
            "style": "IPY_MODEL_f83f308c79244fccb9cdacd1cd855bb6",
            "value": "Validating:  98%"
          }
        },
        "e4595991bb1e472f9855006ab835cc5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b6862426dad457197229a9aebb5e577",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dee78207b49649b693501a6d73482c11",
            "value": 1
          }
        },
        "2349e30967684cd98f9090fa95db5721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e957cd784598472ea7e682a237b0b7bb",
            "placeholder": "​",
            "style": "IPY_MODEL_94db642cc4d744c8b1e56ea71bce0e93",
            "value": " 1226/1250 [00:04&lt;00:00, 319.87it/s]"
          }
        },
        "2f02ac90c158475b89484423a0b367df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "dba43bb81bc04787aa24cd8d3a18ed72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f83f308c79244fccb9cdacd1cd855bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b6862426dad457197229a9aebb5e577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dee78207b49649b693501a6d73482c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e957cd784598472ea7e682a237b0b7bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94db642cc4d744c8b1e56ea71bce0e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee4593d664ff4cf29c38bdc4792d2f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82d03742c8154c689da5c3bcfd0a34d8",
              "IPY_MODEL_43a42dcb245f4648b381a73c908807a8",
              "IPY_MODEL_ef188a0963584b0486152a3911ee825f"
            ],
            "layout": "IPY_MODEL_47ec34435fdf446daa067c4308caf1f8"
          }
        },
        "82d03742c8154c689da5c3bcfd0a34d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3dab6f6288742c798a83e65f4158d24",
            "placeholder": "​",
            "style": "IPY_MODEL_220c5f67b9304cd2b6b6e6a8d0f83d28",
            "value": "Validating: 100%"
          }
        },
        "43a42dcb245f4648b381a73c908807a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc0b1a57c3fb4b288541258549071796",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1d0aa361abf466c9cc99d6c3cbd130a",
            "value": 1
          }
        },
        "ef188a0963584b0486152a3911ee825f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7127c9243a62479395b629235b104c96",
            "placeholder": "​",
            "style": "IPY_MODEL_555d387c316f4147a9fc1785d0b9c52d",
            "value": " 1249/1250 [00:03&lt;00:00, 329.16it/s]"
          }
        },
        "47ec34435fdf446daa067c4308caf1f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "d3dab6f6288742c798a83e65f4158d24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "220c5f67b9304cd2b6b6e6a8d0f83d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc0b1a57c3fb4b288541258549071796": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1d0aa361abf466c9cc99d6c3cbd130a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7127c9243a62479395b629235b104c96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "555d387c316f4147a9fc1785d0b9c52d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e50f1e0d5b84856b1e73ca68d56678e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6393e84d47b94653888b309b5c8996e2",
              "IPY_MODEL_fd7d48bb57354467a3f3f6f41553dc77",
              "IPY_MODEL_42644d0b417c40238137a793eb6f7a88"
            ],
            "layout": "IPY_MODEL_3153fe16e78a4c00ba3f5e6605d1e803"
          }
        },
        "6393e84d47b94653888b309b5c8996e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f8624cbfc304417bc8ca8ab27fbbde9",
            "placeholder": "​",
            "style": "IPY_MODEL_73b27e0b60ac4ca4805dbca01ed2aef8",
            "value": "Validating:  99%"
          }
        },
        "fd7d48bb57354467a3f3f6f41553dc77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b10094379ba0445283257e59a95ce88a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9ce9995e0cc40389370e8ad8bcad960",
            "value": 1
          }
        },
        "42644d0b417c40238137a793eb6f7a88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0478a79d1b0c442d8b3a44eb43e7a783",
            "placeholder": "​",
            "style": "IPY_MODEL_02e76d6cd6ed464281901e456ff0e20b",
            "value": " 1232/1250 [00:03&lt;00:00, 324.34it/s]"
          }
        },
        "3153fe16e78a4c00ba3f5e6605d1e803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "3f8624cbfc304417bc8ca8ab27fbbde9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73b27e0b60ac4ca4805dbca01ed2aef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b10094379ba0445283257e59a95ce88a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9ce9995e0cc40389370e8ad8bcad960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0478a79d1b0c442d8b3a44eb43e7a783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02e76d6cd6ed464281901e456ff0e20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bd18db1221d41889e68611e1d0113ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_972895c0c09949688c06a678366fc5e7",
              "IPY_MODEL_a46281a656004209a2b44254b0a0c158",
              "IPY_MODEL_ea9a21eaa004406291bf6b5d47994a66"
            ],
            "layout": "IPY_MODEL_3416d4b029874f7fbde5b0bfade1ce5c"
          }
        },
        "972895c0c09949688c06a678366fc5e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_015b4910e6c046e1ac639aa0db17a0bb",
            "placeholder": "​",
            "style": "IPY_MODEL_3e95640c29164eb68045b4d47d7deda5",
            "value": "Validating:  99%"
          }
        },
        "a46281a656004209a2b44254b0a0c158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c95e6f6eda04455fb4f09bad3f1a9350",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cff9c8665c074c17a8a86555002053f5",
            "value": 1
          }
        },
        "ea9a21eaa004406291bf6b5d47994a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15f254109f244243b8ddd19b1069ef06",
            "placeholder": "​",
            "style": "IPY_MODEL_2289448bbdeb444aa6ef055550bec0cd",
            "value": " 1240/1250 [00:04&lt;00:00, 223.85it/s]"
          }
        },
        "3416d4b029874f7fbde5b0bfade1ce5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "015b4910e6c046e1ac639aa0db17a0bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e95640c29164eb68045b4d47d7deda5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c95e6f6eda04455fb4f09bad3f1a9350": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cff9c8665c074c17a8a86555002053f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15f254109f244243b8ddd19b1069ef06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2289448bbdeb444aa6ef055550bec0cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c98096caee04fdb9b761f6df3f1ec16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e8e140d55294a7887dcbce856d1cde5",
              "IPY_MODEL_f2f2942e12284a978faa85f43e01538b",
              "IPY_MODEL_795f639009dc4d3884338faf8b615daa"
            ],
            "layout": "IPY_MODEL_00627bc9f94c47b185a183faa7409617"
          }
        },
        "7e8e140d55294a7887dcbce856d1cde5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_535c8325a78b4bd498edc5dc88947f68",
            "placeholder": "​",
            "style": "IPY_MODEL_fc28b1bacd964af7a782f036b4dc4df6",
            "value": "Validating: 100%"
          }
        },
        "f2f2942e12284a978faa85f43e01538b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f383fd49d2a4c6cb4ede489917fac0f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d35bfef1239e4c77b533bd243c6fa6c3",
            "value": 1
          }
        },
        "795f639009dc4d3884338faf8b615daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac161e8332414c7bb3a987b29aad9e06",
            "placeholder": "​",
            "style": "IPY_MODEL_07d622d11e5c4bb6841eb192b33ed1c8",
            "value": " 1245/1250 [00:04&lt;00:00, 312.25it/s]"
          }
        },
        "00627bc9f94c47b185a183faa7409617": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "535c8325a78b4bd498edc5dc88947f68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc28b1bacd964af7a782f036b4dc4df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f383fd49d2a4c6cb4ede489917fac0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d35bfef1239e4c77b533bd243c6fa6c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac161e8332414c7bb3a987b29aad9e06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07d622d11e5c4bb6841eb192b33ed1c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.   train・dev・testのコーパスを目視で整える\n",
        "2.   neologdnで正規化し、sudachiで単語分割する\n",
        "3.   LightGBMとSVRの入力のために、分割した単語をTf-idfでベクトル化\n",
        "4.   LSTMとLightGBMとSVRで学習し、学習結果をファイルに出力\n",
        "5.  出力したファイルをアンサンブル(平均)する"
      ],
      "metadata": {
        "id": "__v3JDxLis3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "numpy.set_printoptions(threshold=numpy.inf)"
      ],
      "metadata": {
        "id": "NVRZli_gjyGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_sMOHKujzB4",
        "outputId": "c768bd82-3325-4e63-97a8-99d01ff4083b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path1 = \"/content/drive/MyDrive/研究室コンペ/data/\"\n",
        "path2 = \"/content/drive/MyDrive/研究室コンペ/self_data/\"\n",
        "path3 = \"/content/drive/MyDrive/研究室コンペ/self_data2/\""
      ],
      "metadata": {
        "id": "BliygDHEj0SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from mlxtend.plotting import plot_decision_regions"
      ],
      "metadata": {
        "id": "sK8oY3QGj11g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(openfile):\n",
        "    with open(openfile, 'r') as f:\n",
        "        text = f.read().split(\"\\n\")\n",
        "        text = text[:-1] # train_textの最後に''があるため削除\n",
        "    return text"
      ],
      "metadata": {
        "id": "MjoWZp_hj3Ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データの読み込み\n",
        "train_text = load_data( path2 + \"text.train.txt\")\n",
        "dev_text = load_data( path2 + \"text.dev.txt\") # 検証用\n",
        "test_text = load_data( path2 + \"text.test.txt\") # 提出用\n",
        "\n",
        "# ラベルの読み込み\n",
        "train_label = load_data( path2 + \"label.train.txt\")\n",
        "dev_label = load_data( path2 + \"label.dev.txt\")"
      ],
      "metadata": {
        "id": "xdGRuxRMj41U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sudachiをインストール\n",
        "! pip install sudachipy\n",
        "! pip install sudachidict_core #単語分割用の辞書\n",
        "! pip install sudachidict_full\n",
        "! pip install sudachidict_small"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7E-A1Y6j_ck",
        "outputId": "328b797e-34a8-46ac-91e0-786de6132538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sudachipy\n",
            "  Downloading SudachiPy-0.6.6-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sudachipy\n",
            "Successfully installed sudachipy-0.6.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sudachidict_core\n",
            "  Downloading SudachiDict-core-20230110.tar.gz (9.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: SudachiPy<0.7,>=0.5 in /usr/local/lib/python3.8/dist-packages (from sudachidict_core) (0.6.6)\n",
            "Building wheels for collected packages: sudachidict_core\n",
            "  Building wheel for sudachidict_core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sudachidict_core: filename=SudachiDict_core-20230110-py3-none-any.whl size=71665396 sha256=5b93ef4834e09dea12e670b52edfad31135da17975c4fad0431bc150bb8c1505\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/fb/7b/5a2f84cba933a120cefe3587a01ed20dbc9a033a6bb43672e7\n",
            "Successfully built sudachidict_core\n",
            "Installing collected packages: sudachidict_core\n",
            "Successfully installed sudachidict_core-20230110\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sudachidict_full\n",
            "  Downloading SudachiDict-full-20230110.tar.gz (9.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: SudachiPy<0.7,>=0.5 in /usr/local/lib/python3.8/dist-packages (from sudachidict_full) (0.6.6)\n",
            "Building wheels for collected packages: sudachidict_full\n",
            "  Building wheel for sudachidict_full (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sudachidict_full: filename=SudachiDict_full-20230110-py3-none-any.whl size=126831894 sha256=27589061be18ad99f30ea1b5f3407bc395543a2f98a7165b753ec4d484e20e1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/62/56/81f6933265c2c5bc7148176d2d9ec90383b511834c41590521\n",
            "Successfully built sudachidict_full\n",
            "Installing collected packages: sudachidict_full\n",
            "Successfully installed sudachidict_full-20230110\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sudachidict_small\n",
            "  Downloading SudachiDict-small-20230110.tar.gz (9.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: SudachiPy<0.7,>=0.5 in /usr/local/lib/python3.8/dist-packages (from sudachidict_small) (0.6.6)\n",
            "Building wheels for collected packages: sudachidict_small\n",
            "  Building wheel for sudachidict_small (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sudachidict_small: filename=SudachiDict_small-20230110-py3-none-any.whl size=41771140 sha256=b80a63582398fd558aa6a4b51678a9616d36ae59f769a0fa8c8bf49fee953615\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/07/46/18c5a64479e030287aa5859c49db1571f247943f24f2d44f71\n",
            "Successfully built sudachidict_small\n",
            "Installing collected packages: sudachidict_small\n",
            "Successfully installed sudachidict_small-20230110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sudachiによる正規化を行う関数を定義\n",
        "from sudachipy import Dictionary\n",
        "from sudachipy import SplitMode\n",
        "tokenizer = Dictionary(dict=\"small\").create() #dict=\"full\"\n",
        "\n",
        "def sudachi(text):\n",
        "    after = list()\n",
        "    for token in tokenizer.tokenize(text, SplitMode.A):\n",
        "        word = token.normalized_form() # 正規化あり\n",
        "        pos = \" \".join(token.part_of_speech())\n",
        "        \n",
        "        if word.isnumeric():\n",
        "            word = '0'\n",
        "\n",
        "        after.append(word)\n",
        "        \n",
        "    return after"
      ],
      "metadata": {
        "id": "34fmPNMykBKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install neologdn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IHk6zIDkGhw",
        "outputId": "1d2b0f57-1238-43e1-a598-dc039cf1005f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting neologdn\n",
            "  Downloading neologdn-0.5.1.tar.gz (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: neologdn\n",
            "  Building wheel for neologdn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neologdn: filename=neologdn-0.5.1-cp38-cp38-linux_x86_64.whl size=208738 sha256=a79da9009223823b54d69d367ce9ad4d90aaec7a01c52d6a0d1d369fbd94e14d\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/db/10/b3b26caa63c5da86ea3a25043cc4379a66bb3dd30d6f060a37\n",
            "Successfully built neologdn\n",
            "Installing collected packages: neologdn\n",
            "Successfully installed neologdn-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 単語分割\n",
        "import neologdn\n",
        "\n",
        "train_tokenize = [] \n",
        "dev_tokenize = []\n",
        "test_tokenize = []\n",
        "\n",
        "def tokenize(infile, outfile):\n",
        "    for i in range(len(infile)):\n",
        "        #outfile.append(sudachi(infile[i]))   #正規化なし\n",
        "        outfile.append(sudachi(neologdn.normalize(infile[i])))    #正規化あり\n",
        "\n",
        "tokenize(train_text, train_tokenize)\n",
        "tokenize(dev_text, dev_tokenize)\n",
        "tokenize(test_text, test_tokenize)\n",
        "\n",
        "# ファイルに書き込み\n",
        "def writefile(infile, outfile):\n",
        "    with open(outfile, 'w') as f:\n",
        "        for i, wordlist in enumerate(infile):\n",
        "            f.write(\" \".join([str(word) for word in wordlist]) + '\\n')\n",
        "\n",
        "writefile(train_tokenize, \"train.txt\")\n",
        "writefile(dev_tokenize, \"dev.txt\")\n",
        "writefile(test_tokenize, \"test.txt\")"
      ],
      "metadata": {
        "id": "smeDN-otkHzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"train.txt\", 'r') as f:\n",
        "    traintext = f.read().split(\"\\n\")\n",
        "    traintext = traintext[:-1]\n",
        "with open(\"test.txt\", 'r') as f:\n",
        "    testtext = f.read().split(\"\\n\")\n",
        "    testtext = testtext[:-1]\n",
        "with open(\"dev.txt\", 'r') as f:\n",
        "    devtext = f.read().split(\"\\n\")\n",
        "    devtext = devtext[:-1]"
      ],
      "metadata": {
        "id": "RnP2-ELikXqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM"
      ],
      "metadata": {
        "id": "VJqvp_KpjOUa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVzFbZ9Hio7N",
        "outputId": "8e84e953-87bb-4cac-fe7d-d5863c5f5548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.6.0\n",
            "  Downloading torch-1.6.0-cp38-cp38-manylinux1_x86_64.whl (748.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m748.8/748.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.6.0) (1.21.6)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.6.0 which is incompatible.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.6.0 which is incompatible.\n",
            "fastai 2.7.10 requires torch<1.14,>=1.7, but you have torch 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.7.0\n",
            "  Downloading torchtext-0.7.0-cp38-cp38-manylinux1_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.7.0) (2.25.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from torchtext==0.7.0) (1.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext==0.7.0) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.7.0) (4.64.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.7.0) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.7.0) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.7.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.7.0) (1.24.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from torch->torchtext==0.7.0) (0.16.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.14.1\n",
            "    Uninstalling torchtext-0.14.1:\n",
            "      Successfully uninstalled torchtext-0.14.1\n",
            "Successfully installed sentencepiece-0.1.97 torchtext-0.7.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-lightning==1.0.8\n",
            "  Downloading pytorch_lightning-1.0.8-py3-none-any.whl (561 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.4/561.4 KB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.0.8) (1.6.0)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.0.8) (2.11.2)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.0.8) (4.64.1)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.3.tar.gz (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 KB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fsspec>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.0.8) (2023.1.0)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.0.8) (1.21.6)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.0.8) (6.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (2.16.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (1.4.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (2.25.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (3.4.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (3.19.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (1.51.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (4.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (6.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (2022.12.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (3.12.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (3.2.2)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492036 sha256=f891520acce9c5f73f308eb1387c40f0accd699ed3e2dc6b57cc4f02cf5e1b1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/0b/ee/e6994fadb42c1354dcccb139b0bf2795271bddfe6253ccdf11\n",
            "Successfully built future\n",
            "Installing collected packages: future, pytorch-lightning\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.10 requires torch<1.14,>=1.7, but you have torch 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed future-0.18.3 pytorch-lightning-1.0.8\n"
          ]
        }
      ],
      "source": [
        "! pip install torch==1.6.0\n",
        "! pip install torchtext==0.7.0\n",
        "! pip install pytorch-lightning==1.0.8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.data import Example, Field, Dataset, BucketIterator"
      ],
      "metadata": {
        "id": "yXvN8Uswkb91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train =  np.array([x for x in list(map (int, train_label))]) #ラベルを0始まりに\n",
        "y_dev =  np.array([x for x in list(map (int, dev_label))])\n",
        "\n",
        "label2id = dict()\n",
        "for label in sorted(y_train):\n",
        "    label2id[label] = len(label2id)-1 # ラベルを0始まりに\n",
        "\n",
        "label2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGk4ImpwkdwF",
        "outputId": "a7330ca0-828d-4c4c-a2d2-595b89ab8238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{-2: 0, -1: 1, 0: 2, 1: 3, 2: 4}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#データの読み込み\n",
        "\n",
        "seed = 64\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "batch_size = 2\n",
        "\n",
        "text_field = Field(sequential=True, use_vocab=True) \n",
        "label_field = Field(sequential=False, use_vocab=False, is_target=True)\n",
        "fields = [(\"x\", text_field), (\"t\", label_field)]\n",
        "\n",
        "def load_corpus(text, labels):\n",
        "    examples = list()\n",
        "    for line, label in zip(text,labels) :\n",
        "        word_list = line.strip()\n",
        "        label_id = label2id[label]\n",
        "        examples.append(Example.fromlist([word_list, label_id], fields))\n",
        "    return Dataset(examples, fields)\n",
        "\n",
        "dataset_train = load_corpus(traintext, y_train)\n",
        "dataset_val = load_corpus(devtext,y_dev)\n",
        "y_test = [0] * 2500\n",
        "dataset_test = load_corpus(testtext, y_test)\n",
        "\n",
        "# 語彙を登録（訓練データに含まれる単語にIDを割り振る）\n",
        "text_field.build_vocab(dataset_train, min_freq=3) # 3回以上出てくる単語だけ学習に使う\n",
        "\n",
        "# データセットオブジェクトからデータローダーを作成\n",
        "dataloader_train = BucketIterator(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "dataloader_val = BucketIterator(dataset_val, batch_size=batch_size, shuffle=False) # ラベルの偏りはどうでもいいためシャッフルしない\n",
        "dataloader_test = BucketIterator(dataset_test, batch_size=1, shuffle=False) # ラベルの偏りはどうでもいいためシャッフルしな"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UjF6KzykhZ9",
        "outputId": "ab0861c9-4980-4d32-b853-a066d0d6f768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "n_embed = 64  # 単語ベクトルの次元 \n",
        "n_hidden = 128  # 文ベクトルの次元\n",
        "n_layers = 2  # RNN層の数\n",
        "dropout = 0.15\n",
        "bidirectional = True"
      ],
      "metadata": {
        "id": "a0XYnOxBkqOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RNNによるテキスト分類\n",
        "\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "\n",
        "class RNN(pl.LightningModule):\n",
        "\n",
        "    # 埋め込み層, 隠れ層, 全結合層の定義   (ニューラルネットワークの形)\n",
        "    def __init__(self, n_input, n_embed, n_hidden, n_layers, n_output, dropout, bidirectional):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embed = nn.Embedding(num_embeddings=n_input, embedding_dim=n_embed, padding_idx=1) # 埋め込み層　nn.Embedding:単語を単語ベクトルに．n_input:モデルに何単語学習させるか．embedding_dim：何次元の単語ベクトルか\n",
        "        self.lstm = nn.LSTM(input_size=n_embed, hidden_size=n_hidden, num_layers=n_layers, dropout=dropout, bidirectional=bidirectional) # input_size：入力が何次元か．hidden_size：RNN(h)が何次元か．num_layers：RNNが何層か．bidirectional：双方向か片方向か\n",
        "        self.fc = nn.Linear(in_features=n_hidden * (2 if bidirectional==True else 1), out_features=n_output) # 全結合層 1層のニューラルネットワークを作る　out_features：ラベルの種類(negative.positiveなどの5種類) 両方向のとき，入力*2\n",
        "        self.drop1 = nn.Dropout(dropout)\n",
        "        self.drop2 = nn.Dropout(dropout)\n",
        " \n",
        "    # 順伝播\n",
        "    def forward(self, x):\n",
        "        y = self.embed(x)\n",
        "        y = self.drop1(y)\n",
        "        o, (h, c) = self.lstm(y) # embed：単語ベクトルを作る ->それをlstmに入れる  o, h, c  o(上に出てくるh)とh(横に出ていく・再入力されるh)はおなじ\n",
        "        y = self.drop1(o)\n",
        "        return self.fc(o[-1]) #oの一番最後は全体を表している \n",
        "\n",
        "    # 訓練用データのバッチを受け取って損失を計算\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, t = batch\n",
        "        y = self(x)\n",
        "        loss = self.lossfun(y, t)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "    \n",
        "    # 検証用データのバッチを受け取って損失を計算\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, t = batch\n",
        "        y = self(x)\n",
        "        loss = self.lossfun(y, t)\n",
        "        self.log(\"val_loss\", loss)\n",
        "\n",
        "    # 評価用データのバッチを受け取って分類の正解率を計算\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, t = batch\n",
        "        y = self(x)\n",
        "        y = torch.argmax(y, dim=1)\n",
        "        accuracy = torch.sum(t == y).item() / (len(y) * 1.0)\n",
        "        self.log(\"test_acc\", accuracy)\n",
        "\n",
        "    # 損失関数を設定\n",
        "    def lossfun(self, y, t):\n",
        "        return F.cross_entropy(y, t) # kappa_loss(y, t)\n",
        "\n",
        "    # 最適化手法を設定\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "sMnmZx2zkvJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練\n",
        "\n",
        "# モデルの保存用ディレクトリがすでにあり、新たに訓練する場合は、そのディレクトリを消す\n",
        "! rm -r model*\n",
        "\n",
        "n_input = len(text_field.vocab)\n",
        "n_output = len(label2id)  # 出力ベクトルの次元（=ラベルの種類数）\n",
        "\n",
        "rnn1 = RNN(n_input, n_embed, n_hidden, n_layers, n_output, dropout, bidirectional) # これを学習させていく\n",
        "\n",
        "# 訓練中にモデルを保存するための設定\n",
        "checkpoint = pl.callbacks.ModelCheckpoint(\n",
        "    # 検証用データにおける損失が最も小さいモデルを保存する\n",
        "    monitor=\"val_loss\", mode=\"min\", save_top_k=1,\n",
        "    # モデルファイル（重みのみ）を \"model\" というディレクトリに保存する\n",
        "    save_weights_only=True, dirpath=\"model1/\"\n",
        ")\n",
        "\n",
        "# 訓練\n",
        "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=3, verbose=False, mode=\"min\")\n",
        "trainer = pl.Trainer(gpus=1, callbacks=[checkpoint, early_stop_callback]) \n",
        "trainer.fit(rnn1, dataloader_train, dataloader_val)\n",
        "\n",
        "# ベストモデルの確認\n",
        "print(\"ベストモデル: \", checkpoint.best_model_path)\n",
        "print(\"ベストモデルの検証用データにおける損失: \", checkpoint.best_model_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538,
          "referenced_widgets": [
            "c30b7efda33442b2868da4b27ba7e44e",
            "b69f6eb91c7f4de0bff368d557d03f27",
            "c84894f20a774360ab65834829b2f69d",
            "bdaf43cceade4273a074a0103393985f",
            "9f15d85cc37f46699375e5b4d1db09d8",
            "26ad7babc828402497334f95a771ddff",
            "9fc9b470840649a7a9b285d211748424",
            "4e31d8d12b0a483fbfc83d00b7fc10f0",
            "062ca9cd2e48412eb9a6612b7bbe7df3",
            "1b2282bee32a4a398f0782b9451bd7f1",
            "c68c3fd0e8164c3584f34df75f4db4a0",
            "7b17f8f6cafa440487e05c1ec1139e1b",
            "c2a457b2fe934c48aa9d5a9a284c6ebc",
            "5dd2622cc1b241618c12804873c04ec0",
            "0c56620dfc9e4e5b8ba4078158cf55d4",
            "46637e1988e84ddebde5a7b1589be83d",
            "82dcadaeed944512b3cda4a217f51692",
            "b62b9d39e7da4ac687cec1f506f85c34",
            "c5d99e14c29f49ad8f9f707ca3f45333",
            "63681e37d7d340f29b2f4d556903f59e",
            "0f295f2448744f46a6dfab50d5c11e33",
            "9ab9ba6399d34d07a97d1b365d55aaea",
            "50a39c1dd43a4c458922f5efd1c47b5f",
            "91d54df5d70c41b88d0706b79843ff23",
            "e4595991bb1e472f9855006ab835cc5c",
            "2349e30967684cd98f9090fa95db5721",
            "2f02ac90c158475b89484423a0b367df",
            "dba43bb81bc04787aa24cd8d3a18ed72",
            "f83f308c79244fccb9cdacd1cd855bb6",
            "1b6862426dad457197229a9aebb5e577",
            "dee78207b49649b693501a6d73482c11",
            "e957cd784598472ea7e682a237b0b7bb",
            "94db642cc4d744c8b1e56ea71bce0e93",
            "ee4593d664ff4cf29c38bdc4792d2f8b",
            "82d03742c8154c689da5c3bcfd0a34d8",
            "43a42dcb245f4648b381a73c908807a8",
            "ef188a0963584b0486152a3911ee825f",
            "47ec34435fdf446daa067c4308caf1f8",
            "d3dab6f6288742c798a83e65f4158d24",
            "220c5f67b9304cd2b6b6e6a8d0f83d28",
            "fc0b1a57c3fb4b288541258549071796",
            "c1d0aa361abf466c9cc99d6c3cbd130a",
            "7127c9243a62479395b629235b104c96",
            "555d387c316f4147a9fc1785d0b9c52d",
            "5e50f1e0d5b84856b1e73ca68d56678e",
            "6393e84d47b94653888b309b5c8996e2",
            "fd7d48bb57354467a3f3f6f41553dc77",
            "42644d0b417c40238137a793eb6f7a88",
            "3153fe16e78a4c00ba3f5e6605d1e803",
            "3f8624cbfc304417bc8ca8ab27fbbde9",
            "73b27e0b60ac4ca4805dbca01ed2aef8",
            "b10094379ba0445283257e59a95ce88a",
            "b9ce9995e0cc40389370e8ad8bcad960",
            "0478a79d1b0c442d8b3a44eb43e7a783",
            "02e76d6cd6ed464281901e456ff0e20b",
            "5bd18db1221d41889e68611e1d0113ad",
            "972895c0c09949688c06a678366fc5e7",
            "a46281a656004209a2b44254b0a0c158",
            "ea9a21eaa004406291bf6b5d47994a66",
            "3416d4b029874f7fbde5b0bfade1ce5c",
            "015b4910e6c046e1ac639aa0db17a0bb",
            "3e95640c29164eb68045b4d47d7deda5",
            "c95e6f6eda04455fb4f09bad3f1a9350",
            "cff9c8665c074c17a8a86555002053f5",
            "15f254109f244243b8ddd19b1069ef06",
            "2289448bbdeb444aa6ef055550bec0cd",
            "9c98096caee04fdb9b761f6df3f1ec16",
            "7e8e140d55294a7887dcbce856d1cde5",
            "f2f2942e12284a978faa85f43e01538b",
            "795f639009dc4d3884338faf8b615daa",
            "00627bc9f94c47b185a183faa7409617",
            "535c8325a78b4bd498edc5dc88947f68",
            "fc28b1bacd964af7a782f036b4dc4df6",
            "4f383fd49d2a4c6cb4ede489917fac0f",
            "d35bfef1239e4c77b533bd243c6fa6c3",
            "ac161e8332414c7bb3a987b29aad9e06",
            "07d622d11e5c4bb6841eb192b33ed1c8"
          ]
        },
        "id": "lxYCPUIfkxpK",
        "outputId": "e6fe5c65-bd85-4df4-c116-dc6f84778f7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'model*': No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: True, used: True\n",
            "INFO:lightning:GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning:TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type      | Params\n",
            "------------------------------------\n",
            "0 | embed | Embedding | 668 K \n",
            "1 | lstm  | LSTM      | 593 K \n",
            "2 | fc    | Linear    | 1.3 K \n",
            "3 | drop1 | Dropout   | 0     \n",
            "4 | drop2 | Dropout   | 0     \n",
            "INFO:lightning:\n",
            "  | Name  | Type      | Params\n",
            "------------------------------------\n",
            "0 | embed | Embedding | 668 K \n",
            "1 | lstm  | LSTM      | 593 K \n",
            "2 | fc    | Linear    | 1.3 K \n",
            "3 | drop1 | Dropout   | 0     \n",
            "4 | drop2 | Dropout   | 0     \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c30b7efda33442b2868da4b27ba7e44e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b17f8f6cafa440487e05c1ec1139e1b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50a39c1dd43a4c458922f5efd1c47b5f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee4593d664ff4cf29c38bdc4792d2f8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e50f1e0d5b84856b1e73ca68d56678e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bd18db1221d41889e68611e1d0113ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c98096caee04fdb9b761f6df3f1ec16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ベストモデル:  /content/model1/epoch=1.ckpt\n",
            "ベストモデルの検証用データにおける損失:  tensor(1.3956, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# devに対するQWK\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "model = RNN(n_input, n_embed, n_hidden, n_layers, n_output, dropout, bidirectional) # これを学習させていく\n",
        "checkpoint_path = checkpoint.best_model_path\n",
        "best_model = model.load_from_checkpoint(checkpoint_path, n_input=n_input, n_embed=n_embed, n_hidden=n_hidden, n_layers= n_layers, n_output=n_output, dropout=dropout, bidirectional=bidirectional)\n",
        "\n",
        "\n",
        "dataloader_val_ = BucketIterator(dataset_val, batch_size=1, shuffle=False) #kappa計算用のデータローダー\n",
        "\n",
        "y_dev_ =  np.array([x+2 for x in list(map (int, dev_label))])\n",
        "\n",
        "# 正解率の計算\n",
        "def test_model(test_loader):\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        accs = [] # 各バッチごとの結果格納用\n",
        "        preds = []\n",
        "\n",
        "        for batch in test_loader:\n",
        "            x, t = batch\n",
        "            x = x.to(device)\n",
        "            t = t.to(device)\n",
        "            y = best_model(x).to(device)\n",
        "\n",
        "            y_label = torch.argmax(y, dim=1)\n",
        "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
        "            accs.append(acc)\n",
        "            preds.append(y_label.item()) \n",
        "\n",
        "    avg_acc = torch.tensor(accs).mean()\n",
        "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
        "    \n",
        "    qwk = cohen_kappa_score(y_dev_, preds, weights='quadratic')\n",
        "    print('QWK=', qwk)\n",
        "\n",
        "# テストデータで結果確認\n",
        "test_model(dataloader_val_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf4TgVDsk5In",
        "outputId": "bdda8ca5-c362-49d0-c608-e0dad4d660d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 36.5%\n",
            "QWK= 0.40223814890572696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "seed 42\n",
        "Accuracy: 35.3%\n",
        "Std: 0.4779\n",
        "QWK= 0.44142112494024854\n",
        "```\n"
      ],
      "metadata": {
        "id": "Uc7H_s3qlHZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 提出用データに対して推論\n",
        "model = RNN(n_input, n_embed, n_hidden, n_layers, n_output, dropout, bidirectional) # これを学習させていく\n",
        "checkpoint_path = checkpoint.best_model_path\n",
        "best_model = model.load_from_checkpoint(checkpoint_path, n_input=n_input, n_embed=n_embed, n_hidden=n_hidden, n_layers= n_layers, n_output=n_output, dropout=dropout, bidirectional=bidirectional)\n",
        "\n",
        "def test_model(test_loader):\n",
        "    f = open(\"eval_seed\"+str(seed)+\".txt\", \"w\")\n",
        "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        accs = [] # 各バッチごとの結果格納用\n",
        "        preds = []\n",
        "\n",
        "        for batch in test_loader:\n",
        "            x, t = batch\n",
        "            x = x.to(device)\n",
        "            t = t.to(device)\n",
        "            y = best_model(x).to(device)\n",
        "\n",
        "            y_label = torch.argmax(y, dim=1)\n",
        "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
        "            accs.append(acc)\n",
        "            preds.append(y_label.item()-2) \n",
        "\n",
        "            f.write(str(y_label.item()-2))\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    f.close()\n",
        "    # 全体の平均を算出\n",
        "    avg_acc = torch.tensor(accs).mean()\n",
        "    std_acc = torch.tensor(accs).std()\n",
        "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
        "    print('Std: {:.4f}'.format(std_acc))\n",
        "\n",
        "# テストデータで結果確認\n",
        "test_model(dataloader_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBvFDVg9lJex",
        "outputId": "71f680d0-54bb-45e7-c021-e7249b2d4b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 43.3%\n",
            "Std: 0.4956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LightGBM + Optuna"
      ],
      "metadata": {
        "id": "VXQNBolFjS1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "nZM8BU3rjY14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sudachiによる正規化を行う関数を定義\n",
        "from sudachipy import Dictionary\n",
        "from sudachipy import SplitMode\n",
        "tokenizer = Dictionary(dict=\"small\").create() #dict=\"full\"\n",
        "\n",
        "def sudachi(text):\n",
        "    after = list()\n",
        "    for token in tokenizer.tokenize(text, SplitMode.C):\n",
        "        # word = token.surface() # 正規化なし\n",
        "        word = token.normalized_form() # 正規化あり\n",
        "        pos = \" \".join(token.part_of_speech())\n",
        "        pos = pos.split(\" \")\n",
        "        \n",
        "        if word.isnumeric():\n",
        "            word = '0'\n",
        "\n",
        "        after.append(word)\n",
        "\n",
        "    return after"
      ],
      "metadata": {
        "id": "QXvrVeGulatl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 単語分割\n",
        "import neologdn\n",
        "\n",
        "train_tokenize = [] \n",
        "dev_tokenize = []\n",
        "test_tokenize = []\n",
        "\n",
        "def tokenize(infile, outfile):\n",
        "    for i in range(len(infile)):\n",
        "        #outfile.append(sudachi(infile[i]))   #正規化なし\n",
        "        outfile.append(sudachi(neologdn.normalize(infile[i])))    #正規化あり\n",
        "\n",
        "tokenize(train_text, train_tokenize)\n",
        "tokenize(dev_text, dev_tokenize)\n",
        "tokenize(test_text, test_tokenize)\n",
        "\n",
        "def writefile(infile, outfile):\n",
        "    with open(outfile, 'w') as f:\n",
        "        for i, wordlist in enumerate(infile):\n",
        "            f.write(\" \".join([str(word) for word in wordlist]) + '\\n')\n",
        "\n",
        "writefile(train_tokenize, \"train.txt\")\n",
        "writefile(dev_tokenize, \"dev.txt\")\n",
        "writefile(test_tokenize, \"test.txt\")"
      ],
      "metadata": {
        "id": "5UGQ-c4Ilgqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import random\n",
        "\n",
        "with open(\"train.txt\", 'r') as f:\n",
        "    traintext = f.read().split(\"\\n\")\n",
        "    traintext = traintext[:-1]\n",
        "with open(\"test.txt\", 'r') as f:\n",
        "    testtext = f.read().split(\"\\n\")\n",
        "    testtext = testtext[:-1]\n",
        "with open(\"dev.txt\", 'r') as f:\n",
        "    devtext = f.read().split(\"\\n\")\n",
        "    devtext = devtext[:-1]\n",
        "\n",
        "vectorizer = TfidfVectorizer(smooth_idf=True, analyzer='char', norm='l1') \n",
        "\n",
        "x_train = vectorizer.fit_transform(traintext)\n",
        "x_test = vectorizer.transform(testtext)\n",
        "x_dev = vectorizer.transform(devtext)"
      ],
      "metadata": {
        "id": "gb4toTeRll5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"x_trainの形状：\", x_train.shape)\n",
        "print(\"x_devの形状：\", x_dev.shape)\n",
        "print(\"x_testの形状：\", x_test.shape)\n",
        "\n",
        "y_train =  np.array(list(map (int, train_label)))\n",
        "y_dev =  np.array(list(map (int, dev_label)))\n",
        "print(\"y_trainの形状：\", y_train.shape)    \n",
        "print(\"y_devの形状：\", y_dev.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kaVkYY4lrP5",
        "outputId": "bd99a3a0-67ad-46fc-fc6c-83687d0f9129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_trainの形状： (30000, 3231)\n",
            "x_devの形状： (2500, 3231)\n",
            "x_testの形状： (2500, 3231)\n",
            "y_trainの形状： (30000,)\n",
            "y_devの形状： (2500,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Oputunaで閾値探索するためのclass\n",
        "def cal_qwk(y_true, y_pred):\n",
        "    \"\"\"QWK (Quadratic Weighted Kappa) を計算する関数\"\"\"\n",
        "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
        "    \n",
        "class OptunaRounder:\n",
        "    \"\"\"Optuna を使って QWK の最適な閾値を探索するクラス\"\"\"\n",
        "\n",
        "    def __init__(self, y_true_, y_pred):\n",
        "        # 真のラベル\n",
        "        self.y_true_ = y_true_\n",
        "        # print(y_true)\n",
        "        # 予測したラベル\n",
        "        self.y_pred = y_pred\n",
        "        # print(y_pred)\n",
        "        # ラベルの種類\n",
        "        self.labels = np.unique(y_true_)\n",
        "    \n",
        "    def adjust(self, y_pred_, thresholds):\n",
        "        \"\"\"閾値にもとづいて予測を補正するメソッド\"\"\"\n",
        "        opt_y_pred = pd.cut(y_pred_, [-np.inf] + thresholds + [np.inf], labels=self.labels)\n",
        "        # print(\"関数:\", opt_y_pred)\n",
        "        return opt_y_pred\n",
        "        \n",
        "\n",
        "    def __call__(self, trial):\n",
        "        \"\"\"最大化したい目的関数\"\"\"\n",
        "        # 閾値を Define by run で追加していく\n",
        "        thresholds = []\n",
        "        # ラベルの数 - 1 が必要な閾値の数になる\n",
        "        for i in range(len(self.labels) - 1):\n",
        "            # 閾値の下限 (既存の最大 or ラベルの最小値)\n",
        "            low = max(thresholds) if i > 0 else min(self.labels)\n",
        "            # 閾値の上限 (ラベルの最大値)\n",
        "            high = max(self.labels)\n",
        "            # 閾値の候補を追加する\n",
        "            t = trial.suggest_uniform(f't{i}', low, high)\n",
        "            thresholds.append(t)\n",
        "\n",
        "        # 閾値の候補を元に QWK を計算する\n",
        "        opt_y_pred_ = self.adjust(self.y_pred, thresholds)\n",
        "        # print(\"QWK:\",opt_y_pred_)\n",
        "        return cal_qwk(self.y_true_, opt_y_pred_)\n",
        "\n",
        "# https://blog.amedama.jp/entry/optuna-qwk-optimization"
      ],
      "metadata": {
        "id": "Sc9c39Celvqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "def lgb_custom_metric_qwk_regression(preds, data):\n",
        "    \"\"\"LightGBM のカスタムメトリックを計算する関数\n",
        "\n",
        "    回帰問題として解いた予測から QWK を計算する\"\"\"\n",
        "    # 正解ラベル\n",
        "    y_true = data.get_label()\n",
        "    # 予測ラベル\n",
        "    y_pred = np.clip(preds, -2, 2) # 単純に予測値を clip \n",
        "    y_pred = [int(Decimal(str(num)).quantize(Decimal('0'), rounding=ROUND_HALF_UP)) for num in y_pred] # 四捨五入\n",
        "\n",
        "    # QWK を計算する\n",
        "    return 'qwk', cohen_kappa_score(y_true, y_pred, weights='quadratic'), True\n",
        "# https://blog.amedama.jp/entry/optuna-qwk-optimization"
      ],
      "metadata": {
        "id": "1cuBiSZ-l-cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6iVUUlMmGSf",
        "outputId": "66b997e1-682b-46bc-e5ed-21e3bfa4b4be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.1.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 KB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.4.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optuna) (1.21.6)\n",
            "Collecting cmaes>=0.9.1\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.9.3-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.6/210.6 KB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (6.0.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (5.10.2)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.12.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.9.3 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Optunaでパラメータ探索 \n",
        "\n",
        "from optuna.integration import lightgbm as lgb\n",
        "from decimal import Decimal, ROUND_HALF_UP, ROUND_HALF_EVEN\n",
        "\n",
        "###### ここからがLightGBMの実装 ###### lower()\n",
        "dtrain = lgb.Dataset(x_train, label=y_train)\n",
        "ddev = lgb.Dataset(x_dev,label= y_dev)\n",
        "\n",
        "seed = 109\n",
        "\n",
        "# 使用するパラメータ\n",
        "params = {'objective': 'regression',  # 最小化させるべき損失関数\n",
        "         'metric': 'rmse',#'lgb_custom_metric_qwk_regression',  # 学習時に使用する評価指標\n",
        "         'random_state': seed,  # 乱数シード\n",
        "         'boosting_type': 'gbdt',  # boosting_type\n",
        "         'verbose': -1\n",
        "          }\n",
        "verbose_eval = 0  # この数字を1にすると学習時のスコア推移がコマンドライン表示される\n",
        "# https://qiita.com/c60evaporator/items/2b7a2820d575e212bcf4\n",
        "\n",
        "# early_stoppingを指定してLightGBM学習　回帰\n",
        "gbm = lgb.train(params, dtrain,\n",
        "                valid_sets=[ddev],  # early_stoppingの評価用データ\n",
        "                #feval=lgb_custom_metric_qwk_regression,\n",
        "                num_boost_round=10000,  # 最大学習サイクル数。early_stopping使用時は大きな値を入力\n",
        "                callbacks=[lgb.early_stopping(stopping_rounds=32, verbose=True)] # early_stopping用コールバック関数\n",
        "                )\n",
        "best_params = gbm.params\n",
        "print(\"Best params:\", best_params)\n",
        "# https://qiita.com/c60evaporator/items/2b7a2820d575e212bcf4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUY0Ke3LmHo7",
        "outputId": "1a23e148-fc11-4505-df07-2e40d31d6f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-13 18:22:59,362]\u001b[0m A new study created in memory with name: no-name-db6806de-f964-47f1-a2bb-ce271396c068\u001b[0m\n",
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 32 rounds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "feature_fraction, val_score: 1.054274:   0%|          | 0/7 [00:28<?, ?it/s]\u001b[A\n",
            "feature_fraction, val_score: 1.054274:  14%|#4        | 1/7 [00:28<02:53, 28.90s/it]\u001b[A\u001b[32m[I 2023-02-13 18:23:28,294]\u001b[0m Trial 0 finished with value: 1.0542737753472917 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 1.0542737753472917.\u001b[0m\n",
            "\n",
            "feature_fraction, val_score: 1.054274:  14%|#4        | 1/7 [00:28<02:53, 28.90s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[181]\tvalid_0's rmse: 1.05427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "feature_fraction, val_score: 1.054146:  14%|#4        | 1/7 [00:54<02:53, 28.90s/it]\u001b[A\n",
            "feature_fraction, val_score: 1.054146:  29%|##8       | 2/7 [00:54<02:15, 27.01s/it]\u001b[A\u001b[32m[I 2023-02-13 18:23:53,975]\u001b[0m Trial 1 finished with value: 1.0541464074674738 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 1.0541464074674738.\u001b[0m\n",
            "\n",
            "feature_fraction, val_score: 1.054146:  29%|##8       | 2/7 [00:54<02:15, 27.01s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[210]\tvalid_0's rmse: 1.05415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "feature_fraction, val_score: 1.052950:  29%|##8       | 2/7 [01:18<02:15, 27.01s/it]\u001b[A\n",
            "feature_fraction, val_score: 1.052950:  43%|####2     | 3/7 [01:18<01:42, 25.62s/it]\u001b[A\u001b[32m[I 2023-02-13 18:24:17,946]\u001b[0m Trial 2 finished with value: 1.0529496934486504 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 2 with value: 1.0529496934486504.\u001b[0m\n",
            "\n",
            "feature_fraction, val_score: 1.052950:  43%|####2     | 3/7 [01:18<01:42, 25.62s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[199]\tvalid_0's rmse: 1.05295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "feature_fraction, val_score: 1.050713:  43%|####2     | 3/7 [01:32<01:42, 25.62s/it]\u001b[A\n",
            "feature_fraction, val_score: 1.050713:  57%|#####7    | 4/7 [01:32<01:03, 21.19s/it]\u001b[A\u001b[32m[I 2023-02-13 18:24:32,331]\u001b[0m Trial 3 finished with value: 1.050712567200257 and parameters: {'feature_fraction': 0.4}. Best is trial 3 with value: 1.050712567200257.\u001b[0m\n",
            "\n",
            "feature_fraction, val_score: 1.050713:  57%|#####7    | 4/7 [01:32<01:03, 21.19s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[174]\tvalid_0's rmse: 1.05071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "feature_fraction, val_score: 1.050713:  57%|#####7    | 4/7 [01:48<01:03, 21.19s/it]\u001b[A\n",
            "feature_fraction, val_score: 1.050713:  71%|#######1  | 5/7 [01:48<00:38, 19.19s/it]\u001b[A\u001b[32m[I 2023-02-13 18:24:47,990]\u001b[0m Trial 4 finished with value: 1.050712567200257 and parameters: {'feature_fraction': 0.5}. Best is trial 3 with value: 1.050712567200257.\u001b[0m\n",
            "\n",
            "feature_fraction, val_score: 1.050713:  71%|#######1  | 5/7 [01:48<00:38, 19.19s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[174]\tvalid_0's rmse: 1.05071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "feature_fraction, val_score: 1.050713:  71%|#######1  | 5/7 [02:08<00:38, 19.19s/it]\u001b[A\n",
            "feature_fraction, val_score: 1.050713:  86%|########5 | 6/7 [02:08<00:19, 19.38s/it]\u001b[A\u001b[32m[I 2023-02-13 18:25:07,733]\u001b[0m Trial 5 finished with value: 1.050712567200257 and parameters: {'feature_fraction': 0.7}. Best is trial 3 with value: 1.050712567200257.\u001b[0m\n",
            "\n",
            "feature_fraction, val_score: 1.050713:  86%|########5 | 6/7 [02:08<00:19, 19.38s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[174]\tvalid_0's rmse: 1.05071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "feature_fraction, val_score: 1.050713:  86%|########5 | 6/7 [02:29<00:19, 19.38s/it]\u001b[A\n",
            "feature_fraction, val_score: 1.050713: 100%|##########| 7/7 [02:29<00:00, 19.92s/it]\u001b[A\u001b[32m[I 2023-02-13 18:25:28,767]\u001b[0m Trial 6 finished with value: 1.050712567200257 and parameters: {'feature_fraction': 0.8}. Best is trial 3 with value: 1.050712567200257.\u001b[0m\n",
            "feature_fraction, val_score: 1.050713: 100%|##########| 7/7 [02:29<00:00, 21.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[174]\tvalid_0's rmse: 1.05071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "num_leaves, val_score: 1.050713:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[174]\tvalid_0's rmse: 1.05071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "num_leaves, val_score: 1.050713:   0%|          | 0/20 [01:08<?, ?it/s]\u001b[A\n",
            "num_leaves, val_score: 1.050713:   5%|5         | 1/20 [01:08<21:42, 68.56s/it]\u001b[A\u001b[32m[I 2023-02-13 18:26:37,355]\u001b[0m Trial 7 finished with value: 1.050712567200257 and parameters: {'num_leaves': 240}. Best is trial 7 with value: 1.050712567200257.\u001b[0m\n",
            "\n",
            "num_leaves, val_score: 1.050713:   5%|5         | 1/20 [01:08<21:42, 68.56s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050713:   5%|5         | 1/20 [01:29<21:42, 68.56s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050713:  10%|#         | 2/20 [01:29<12:14, 40.81s/it]\u001b[A\u001b[32m[I 2023-02-13 18:26:58,740]\u001b[0m Trial 8 finished with value: 1.050712567200257 and parameters: {'num_leaves': 53}. Best is trial 7 with value: 1.050712567200257.\u001b[0m\n",
            "\n",
            "num_leaves, val_score: 1.050713:  10%|#         | 2/20 [01:29<12:14, 40.81s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[174]\tvalid_0's rmse: 1.05071\n",
            "Early stopping, best iteration is:\n",
            "[174]\tvalid_0's rmse: 1.05071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "num_leaves, val_score: 1.050713:  10%|#         | 2/20 [02:42<12:14, 40.81s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050713:  15%|#5        | 3/20 [02:42<15:41, 55.37s/it]\u001b[A\u001b[32m[I 2023-02-13 18:28:11,448]\u001b[0m Trial 9 finished with value: 1.050712567200257 and parameters: {'num_leaves': 249}. Best is trial 7 with value: 1.050712567200257.\u001b[0m\n",
            "\n",
            "num_leaves, val_score: 1.050713:  15%|#5        | 3/20 [02:42<15:41, 55.37s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050713:  15%|#5        | 3/20 [03:00<15:41, 55.37s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050713:  20%|##        | 4/20 [03:00<10:50, 40.63s/it]\u001b[A\u001b[32m[I 2023-02-13 18:28:29,468]\u001b[0m Trial 10 finished with value: 1.050712567200257 and parameters: {'num_leaves': 42}. Best is trial 7 with value: 1.050712567200257.\u001b[0m\n",
            "\n",
            "num_leaves, val_score: 1.050713:  20%|##        | 4/20 [03:00<10:50, 40.63s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[174]\tvalid_0's rmse: 1.05071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "num_leaves, val_score: 1.050713:  20%|##        | 4/20 [03:47<10:50, 40.63s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050713:  25%|##5       | 5/20 [03:47<10:43, 42.90s/it]\u001b[A\u001b[32m[I 2023-02-13 18:29:16,399]\u001b[0m Trial 11 finished with value: 1.050712567200257 and parameters: {'num_leaves': 158}. Best is trial 7 with value: 1.050712567200257.\u001b[0m\n",
            "\n",
            "num_leaves, val_score: 1.050713:  25%|##5       | 5/20 [03:47<10:43, 42.90s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[174]\tvalid_0's rmse: 1.05071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "num_leaves, val_score: 1.050137:  25%|##5       | 5/20 [04:05<10:43, 42.90s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050137:  30%|###       | 6/20 [04:05<07:59, 34.25s/it]\u001b[A\u001b[32m[I 2023-02-13 18:29:33,858]\u001b[0m Trial 12 finished with value: 1.0501366052204348 and parameters: {'num_leaves': 38}. Best is trial 12 with value: 1.0501366052204348.\u001b[0m\n",
            "\n",
            "num_leaves, val_score: 1.050137:  30%|###       | 6/20 [04:05<07:59, 34.25s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[202]\tvalid_0's rmse: 1.05014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "num_leaves, val_score: 1.050137:  30%|###       | 6/20 [04:29<07:59, 34.25s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050137:  35%|###5      | 7/20 [04:29<06:43, 31.05s/it]\u001b[A\u001b[32m[I 2023-02-13 18:29:58,322]\u001b[0m Trial 13 finished with value: 1.0501366052204348 and parameters: {'num_leaves': 56}. Best is trial 12 with value: 1.0501366052204348.\u001b[0m\n",
            "\n",
            "num_leaves, val_score: 1.050137:  35%|###5      | 7/20 [04:29<06:43, 31.05s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[202]\tvalid_0's rmse: 1.05014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "num_leaves, val_score: 1.050137:  35%|###5      | 7/20 [04:41<06:43, 31.05s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050137:  40%|####      | 8/20 [04:41<04:59, 24.99s/it]\u001b[A\u001b[32m[I 2023-02-13 18:30:10,350]\u001b[0m Trial 14 finished with value: 1.0501366052204348 and parameters: {'num_leaves': 23}. Best is trial 12 with value: 1.0501366052204348.\u001b[0m\n",
            "\n",
            "num_leaves, val_score: 1.050137:  40%|####      | 8/20 [04:41<04:59, 24.99s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[202]\tvalid_0's rmse: 1.05014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "num_leaves, val_score: 1.050137:  40%|####      | 8/20 [05:08<04:59, 24.99s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050137:  45%|####5     | 9/20 [05:08<04:41, 25.61s/it]\u001b[A\u001b[32m[I 2023-02-13 18:30:37,298]\u001b[0m Trial 15 finished with value: 1.0501366052204348 and parameters: {'num_leaves': 68}. Best is trial 12 with value: 1.0501366052204348.\u001b[0m\n",
            "\n",
            "num_leaves, val_score: 1.050137:  45%|####5     | 9/20 [05:08<04:41, 25.61s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[202]\tvalid_0's rmse: 1.05014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "num_leaves, val_score: 1.050137:  45%|####5     | 9/20 [05:43<04:41, 25.61s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050137:  50%|#####     | 10/20 [05:43<04:45, 28.55s/it]\u001b[A\u001b[32m[I 2023-02-13 18:31:12,431]\u001b[0m Trial 16 finished with value: 1.0501366052204348 and parameters: {'num_leaves': 91}. Best is trial 12 with value: 1.0501366052204348.\u001b[0m\n",
            "\n",
            "num_leaves, val_score: 1.050137:  50%|#####     | 10/20 [05:43<04:45, 28.55s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[202]\tvalid_0's rmse: 1.05014\n",
            "Early stopping, best iteration is:\n",
            "[202]\tvalid_0's rmse: 1.05014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "num_leaves, val_score: 1.050137:  50%|#####     | 10/20 [06:30<04:45, 28.55s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050137:  55%|#####5    | 11/20 [06:30<05:06, 34.10s/it]\u001b[A\u001b[32m[I 2023-02-13 18:31:59,129]\u001b[0m Trial 17 finished with value: 1.0501366052204348 and parameters: {'num_leaves': 129}. Best is trial 12 with value: 1.0501366052204348.\u001b[0m\n",
            "\n",
            "num_leaves, val_score: 1.050137:  55%|#####5    | 11/20 [06:30<05:06, 34.10s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050137:  55%|#####5    | 11/20 [06:36<05:06, 34.10s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050137:  60%|######    | 12/20 [06:36<03:25, 25.72s/it]\u001b[A\u001b[32m[I 2023-02-13 18:32:05,679]\u001b[0m Trial 18 finished with value: 1.0501366052204348 and parameters: {'num_leaves': 10}. Best is trial 12 with value: 1.0501366052204348.\u001b[0m\n",
            "\n",
            "num_leaves, val_score: 1.050137:  60%|######    | 12/20 [06:36<03:25, 25.72s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[202]\tvalid_0's rmse: 1.05014\n",
            "Early stopping, best iteration is:\n",
            "[202]\tvalid_0's rmse: 1.05014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "num_leaves, val_score: 1.050137:  60%|######    | 12/20 [07:16<03:25, 25.72s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050137:  65%|######5   | 13/20 [07:16<03:28, 29.79s/it]\u001b[A\u001b[32m[I 2023-02-13 18:32:44,850]\u001b[0m Trial 19 finished with value: 1.0501366052204348 and parameters: {'num_leaves': 108}. Best is trial 12 with value: 1.0501366052204348.\u001b[0m\n",
            "\n",
            "num_leaves, val_score: 1.050137:  65%|######5   | 13/20 [07:16<03:28, 29.79s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050137:  65%|######5   | 13/20 [08:17<03:28, 29.79s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050137:  70%|#######   | 14/20 [08:17<03:56, 39.42s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[202]\tvalid_0's rmse: 1.05014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-13 18:33:46,513]\u001b[0m Trial 20 finished with value: 1.0501366052204348 and parameters: {'num_leaves': 184}. Best is trial 12 with value: 1.0501366052204348.\u001b[0m\n",
            "\n",
            "num_leaves, val_score: 1.050137:  70%|#######   | 14/20 [08:17<03:56, 39.42s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050137:  70%|#######   | 14/20 [08:48<03:56, 39.42s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050137:  75%|#######5  | 15/20 [08:48<03:04, 36.81s/it]\u001b[A\u001b[32m[I 2023-02-13 18:34:17,285]\u001b[0m Trial 21 finished with value: 1.0501366052204348 and parameters: {'num_leaves': 79}. Best is trial 12 with value: 1.0501366052204348.\u001b[0m\n",
            "\n",
            "num_leaves, val_score: 1.050137:  75%|#######5  | 15/20 [08:48<03:04, 36.81s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[202]\tvalid_0's rmse: 1.05014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "num_leaves, val_score: 1.050137:  75%|#######5  | 15/20 [09:06<03:04, 36.81s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050137:  80%|########  | 16/20 [09:06<02:04, 31.22s/it]\u001b[A\u001b[32m[I 2023-02-13 18:34:35,499]\u001b[0m Trial 22 finished with value: 1.0501366052204348 and parameters: {'num_leaves': 39}. Best is trial 12 with value: 1.0501366052204348.\u001b[0m\n",
            "\n",
            "num_leaves, val_score: 1.050137:  80%|########  | 16/20 [09:06<02:04, 31.22s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[202]\tvalid_0's rmse: 1.05014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "num_leaves, val_score: 1.050137:  80%|########  | 16/20 [09:09<02:04, 31.22s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050137:  85%|########5 | 17/20 [09:09<01:08, 22.80s/it]\u001b[A\u001b[32m[I 2023-02-13 18:34:38,741]\u001b[0m Trial 23 finished with value: 1.0501366052204348 and parameters: {'num_leaves': 5}. Best is trial 12 with value: 1.0501366052204348.\u001b[0m\n",
            "\n",
            "num_leaves, val_score: 1.050137:  85%|########5 | 17/20 [09:09<01:08, 22.80s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[202]\tvalid_0's rmse: 1.05014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "num_leaves, val_score: 1.050137:  85%|########5 | 17/20 [09:48<01:08, 22.80s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050137:  90%|######### | 18/20 [09:48<00:54, 27.47s/it]\u001b[A\u001b[32m[I 2023-02-13 18:35:17,078]\u001b[0m Trial 24 finished with value: 1.0501366052204348 and parameters: {'num_leaves': 100}. Best is trial 12 with value: 1.0501366052204348.\u001b[0m\n",
            "\n",
            "num_leaves, val_score: 1.050137:  90%|######### | 18/20 [09:48<00:54, 27.47s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[202]\tvalid_0's rmse: 1.05014\n",
            "Early stopping, best iteration is:\n",
            "[202]\tvalid_0's rmse: 1.05014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "num_leaves, val_score: 1.050137:  90%|######### | 18/20 [10:48<00:54, 27.47s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050137:  95%|#########5| 19/20 [10:48<00:37, 37.18s/it]\u001b[A\u001b[32m[I 2023-02-13 18:36:16,878]\u001b[0m Trial 25 finished with value: 1.0501366052204348 and parameters: {'num_leaves': 172}. Best is trial 12 with value: 1.0501366052204348.\u001b[0m\n",
            "\n",
            "num_leaves, val_score: 1.050137:  95%|#########5| 19/20 [10:48<00:37, 37.18s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050137:  95%|#########5| 19/20 [11:13<00:37, 37.18s/it]\u001b[A\n",
            "num_leaves, val_score: 1.050137: 100%|##########| 20/20 [11:13<00:00, 33.79s/it]\u001b[A\u001b[32m[I 2023-02-13 18:36:42,778]\u001b[0m Trial 26 finished with value: 1.0501366052204348 and parameters: {'num_leaves': 63}. Best is trial 12 with value: 1.0501366052204348.\u001b[0m\n",
            "num_leaves, val_score: 1.050137: 100%|##########| 20/20 [11:13<00:00, 33.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[202]\tvalid_0's rmse: 1.05014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "bagging, val_score: 1.050137:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "bagging, val_score: 1.050137:   0%|          | 0/10 [00:19<?, ?it/s]\u001b[A\n",
            "bagging, val_score: 1.050137:  10%|#         | 1/10 [00:19<02:54, 19.33s/it]\u001b[A\u001b[32m[I 2023-02-13 18:37:02,145]\u001b[0m Trial 27 finished with value: 1.0501366052204348 and parameters: {'bagging_fraction': 0.7552417943771015, 'bagging_freq': 7}. Best is trial 27 with value: 1.0501366052204348.\u001b[0m\n",
            "\n",
            "bagging, val_score: 1.050137:  10%|#         | 1/10 [00:19<02:54, 19.33s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[202]\tvalid_0's rmse: 1.05014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "bagging, val_score: 1.050137:  10%|#         | 1/10 [00:41<02:54, 19.33s/it]\u001b[A\n",
            "bagging, val_score: 1.050137:  20%|##        | 2/10 [00:41<02:46, 20.76s/it]\u001b[A\u001b[32m[I 2023-02-13 18:37:23,900]\u001b[0m Trial 28 finished with value: 1.0501366052204348 and parameters: {'bagging_fraction': 0.8987643809995189, 'bagging_freq': 3}. Best is trial 27 with value: 1.0501366052204348.\u001b[0m\n",
            "\n",
            "bagging, val_score: 1.050137:  20%|##        | 2/10 [00:41<02:46, 20.76s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[202]\tvalid_0's rmse: 1.05014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "bagging, val_score: 1.049917:  20%|##        | 2/10 [00:55<02:46, 20.76s/it]\u001b[A\n",
            "bagging, val_score: 1.049917:  30%|###       | 3/10 [00:56<02:06, 18.09s/it]\u001b[A\u001b[32m[I 2023-02-13 18:37:38,814]\u001b[0m Trial 29 finished with value: 1.0499168102984264 and parameters: {'bagging_fraction': 0.6248082310546615, 'bagging_freq': 4}. Best is trial 29 with value: 1.0499168102984264.\u001b[0m\n",
            "\n",
            "bagging, val_score: 1.049917:  30%|###       | 3/10 [00:56<02:06, 18.09s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[146]\tvalid_0's rmse: 1.04992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "bagging, val_score: 1.049917:  30%|###       | 3/10 [01:09<02:06, 18.09s/it]\u001b[A\n",
            "bagging, val_score: 1.049917:  40%|####      | 4/10 [01:09<01:36, 16.15s/it]\u001b[A\u001b[32m[I 2023-02-13 18:37:51,991]\u001b[0m Trial 30 finished with value: 1.0499168102984264 and parameters: {'bagging_fraction': 0.5075931986175612, 'bagging_freq': 7}. Best is trial 29 with value: 1.0499168102984264.\u001b[0m\n",
            "\n",
            "bagging, val_score: 1.049917:  40%|####      | 4/10 [01:09<01:36, 16.15s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[146]\tvalid_0's rmse: 1.04992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "bagging, val_score: 1.049917:  40%|####      | 4/10 [01:23<01:36, 16.15s/it]\u001b[A\n",
            "bagging, val_score: 1.049917:  50%|#####     | 5/10 [01:23<01:17, 15.57s/it]\u001b[A\u001b[32m[I 2023-02-13 18:38:06,527]\u001b[0m Trial 31 finished with value: 1.0499168102984264 and parameters: {'bagging_fraction': 0.8534291727417946, 'bagging_freq': 4}. Best is trial 29 with value: 1.0499168102984264.\u001b[0m\n",
            "\n",
            "bagging, val_score: 1.049917:  50%|#####     | 5/10 [01:23<01:17, 15.57s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[146]\tvalid_0's rmse: 1.04992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "bagging, val_score: 1.049917:  50%|#####     | 5/10 [01:37<01:17, 15.57s/it]\u001b[A\n",
            "bagging, val_score: 1.049917:  60%|######    | 6/10 [01:37<00:59, 14.84s/it]\u001b[A\u001b[32m[I 2023-02-13 18:38:19,944]\u001b[0m Trial 32 finished with value: 1.0499168102984264 and parameters: {'bagging_fraction': 0.587176329099518, 'bagging_freq': 5}. Best is trial 29 with value: 1.0499168102984264.\u001b[0m\n",
            "\n",
            "bagging, val_score: 1.049917:  60%|######    | 6/10 [01:37<00:59, 14.84s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[146]\tvalid_0's rmse: 1.04992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "bagging, val_score: 1.049917:  60%|######    | 6/10 [01:53<00:59, 14.84s/it]\u001b[A\n",
            "bagging, val_score: 1.049917:  70%|#######   | 7/10 [01:53<00:46, 15.34s/it]\u001b[A\u001b[32m[I 2023-02-13 18:38:36,324]\u001b[0m Trial 33 finished with value: 1.0499168102984264 and parameters: {'bagging_fraction': 0.7158891790233837, 'bagging_freq': 1}. Best is trial 29 with value: 1.0499168102984264.\u001b[0m\n",
            "\n",
            "bagging, val_score: 1.049917:  70%|#######   | 7/10 [01:53<00:46, 15.34s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[146]\tvalid_0's rmse: 1.04992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "bagging, val_score: 1.046628:  70%|#######   | 7/10 [02:08<00:46, 15.34s/it]\u001b[A\n",
            "bagging, val_score: 1.046628:  80%|########  | 8/10 [02:08<00:30, 15.29s/it]\u001b[A\u001b[32m[I 2023-02-13 18:38:51,491]\u001b[0m Trial 34 finished with value: 1.0466283771216556 and parameters: {'bagging_fraction': 0.6334180791467596, 'bagging_freq': 2}. Best is trial 34 with value: 1.0466283771216556.\u001b[0m\n",
            "\n",
            "bagging, val_score: 1.046628:  80%|########  | 8/10 [02:08<00:30, 15.29s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "bagging, val_score: 1.046628:  80%|########  | 8/10 [02:24<00:30, 15.29s/it]\u001b[A\n",
            "bagging, val_score: 1.046628:  90%|######### | 9/10 [02:24<00:15, 15.47s/it]\u001b[A\u001b[32m[I 2023-02-13 18:39:07,354]\u001b[0m Trial 35 finished with value: 1.0466283771216556 and parameters: {'bagging_fraction': 0.8767316450677329, 'bagging_freq': 3}. Best is trial 34 with value: 1.0466283771216556.\u001b[0m\n",
            "\n",
            "bagging, val_score: 1.046628:  90%|######### | 9/10 [02:24<00:15, 15.47s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "bagging, val_score: 1.046628:  90%|######### | 9/10 [02:39<00:15, 15.47s/it]\u001b[A\n",
            "bagging, val_score: 1.046628: 100%|##########| 10/10 [02:39<00:00, 15.22s/it]\u001b[A\u001b[32m[I 2023-02-13 18:39:22,026]\u001b[0m Trial 36 finished with value: 1.0466283771216556 and parameters: {'bagging_fraction': 0.4943376227773457, 'bagging_freq': 3}. Best is trial 34 with value: 1.0466283771216556.\u001b[0m\n",
            "bagging, val_score: 1.046628: 100%|##########| 10/10 [02:39<00:00, 15.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "feature_fraction_stage2, val_score: 1.046628:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "feature_fraction_stage2, val_score: 1.046628:   0%|          | 0/3 [00:16<?, ?it/s]\u001b[A\n",
            "feature_fraction_stage2, val_score: 1.046628:  33%|###3      | 1/3 [00:16<00:32, 16.06s/it]\u001b[A\u001b[32m[I 2023-02-13 18:39:38,119]\u001b[0m Trial 37 finished with value: 1.0466283771216556 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 1.0466283771216556.\u001b[0m\n",
            "\n",
            "feature_fraction_stage2, val_score: 1.046628:  33%|###3      | 1/3 [00:16<00:32, 16.06s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "feature_fraction_stage2, val_score: 1.046628:  33%|###3      | 1/3 [00:32<00:32, 16.06s/it]\u001b[A\n",
            "feature_fraction_stage2, val_score: 1.046628:  67%|######6   | 2/3 [00:32<00:16, 16.43s/it]\u001b[A\u001b[32m[I 2023-02-13 18:39:54,800]\u001b[0m Trial 38 finished with value: 1.0466283771216556 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 1.0466283771216556.\u001b[0m\n",
            "\n",
            "feature_fraction_stage2, val_score: 1.046628:  67%|######6   | 2/3 [00:32<00:16, 16.43s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "feature_fraction_stage2, val_score: 1.046628:  67%|######6   | 2/3 [00:48<00:16, 16.43s/it]\u001b[A\n",
            "feature_fraction_stage2, val_score: 1.046628: 100%|##########| 3/3 [00:48<00:00, 16.07s/it]\u001b[A\u001b[32m[I 2023-02-13 18:40:10,451]\u001b[0m Trial 39 finished with value: 1.0466283771216556 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 37 with value: 1.0466283771216556.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 1.046628: 100%|##########| 3/3 [00:48<00:00, 16.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:   0%|          | 0/20 [00:16<?, ?it/s]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:   5%|5         | 1/20 [00:16<05:22, 16.96s/it]\u001b[A\u001b[32m[I 2023-02-13 18:40:27,436]\u001b[0m Trial 40 finished with value: 1.0466283771216556 and parameters: {'lambda_l1': 5.4118837775305933e-08, 'lambda_l2': 0.09579884727810596}. Best is trial 40 with value: 1.0466283771216556.\u001b[0m\n",
            "\n",
            "regularization_factors, val_score: 1.046628:   5%|5         | 1/20 [00:16<05:22, 16.96s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "regularization_factors, val_score: 1.046628:   5%|5         | 1/20 [00:32<05:22, 16.96s/it]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:  10%|#         | 2/20 [00:32<04:49, 16.07s/it]\u001b[A\u001b[32m[I 2023-02-13 18:40:42,880]\u001b[0m Trial 41 finished with value: 1.0466283771216556 and parameters: {'lambda_l1': 1.633970267441761, 'lambda_l2': 6.133048753380494e-07}. Best is trial 40 with value: 1.0466283771216556.\u001b[0m\n",
            "\n",
            "regularization_factors, val_score: 1.046628:  10%|#         | 2/20 [00:32<04:49, 16.07s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "regularization_factors, val_score: 1.046628:  10%|#         | 2/20 [00:48<04:49, 16.07s/it]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:  15%|#5        | 3/20 [00:48<04:34, 16.17s/it]\u001b[A\u001b[32m[I 2023-02-13 18:40:59,181]\u001b[0m Trial 42 finished with value: 1.0466283765229367 and parameters: {'lambda_l1': 2.1494432695100207e-07, 'lambda_l2': 8.294339649119542e-05}. Best is trial 42 with value: 1.0466283765229367.\u001b[0m\n",
            "\n",
            "regularization_factors, val_score: 1.046628:  15%|#5        | 3/20 [00:48<04:34, 16.17s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "regularization_factors, val_score: 1.046628:  15%|#5        | 3/20 [01:03<04:34, 16.17s/it]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:  20%|##        | 4/20 [01:03<04:12, 15.78s/it]\u001b[A\u001b[32m[I 2023-02-13 18:41:14,362]\u001b[0m Trial 43 finished with value: 1.0466283765229367 and parameters: {'lambda_l1': 1.4680067891952834e-06, 'lambda_l2': 0.004976929513511948}. Best is trial 42 with value: 1.0466283765229367.\u001b[0m\n",
            "\n",
            "regularization_factors, val_score: 1.046628:  20%|##        | 4/20 [01:03<04:12, 15.78s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "regularization_factors, val_score: 1.046628:  20%|##        | 4/20 [01:19<04:12, 15.78s/it]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:  25%|##5       | 5/20 [01:19<03:54, 15.61s/it]\u001b[A\u001b[32m[I 2023-02-13 18:41:29,676]\u001b[0m Trial 44 finished with value: 1.0466283765229367 and parameters: {'lambda_l1': 1.3768615388458308e-08, 'lambda_l2': 0.4684814187338205}. Best is trial 42 with value: 1.0466283765229367.\u001b[0m\n",
            "\n",
            "regularization_factors, val_score: 1.046628:  25%|##5       | 5/20 [01:19<03:54, 15.61s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "regularization_factors, val_score: 1.046628:  25%|##5       | 5/20 [01:35<03:54, 15.61s/it]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:  30%|###       | 6/20 [01:35<03:39, 15.69s/it]\u001b[A\u001b[32m[I 2023-02-13 18:41:45,519]\u001b[0m Trial 45 finished with value: 1.0466283765229367 and parameters: {'lambda_l1': 1.9506802583737927e-06, 'lambda_l2': 2.2525011873806347e-08}. Best is trial 42 with value: 1.0466283765229367.\u001b[0m\n",
            "\n",
            "regularization_factors, val_score: 1.046628:  30%|###       | 6/20 [01:35<03:39, 15.69s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "regularization_factors, val_score: 1.046628:  30%|###       | 6/20 [01:50<03:39, 15.69s/it]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:  35%|###5      | 7/20 [01:50<03:22, 15.59s/it]\u001b[A\u001b[32m[I 2023-02-13 18:42:00,891]\u001b[0m Trial 46 finished with value: 1.0466283765229367 and parameters: {'lambda_l1': 1.8768134260585245e-08, 'lambda_l2': 0.023165394687679808}. Best is trial 42 with value: 1.0466283765229367.\u001b[0m\n",
            "\n",
            "regularization_factors, val_score: 1.046628:  35%|###5      | 7/20 [01:50<03:22, 15.59s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "regularization_factors, val_score: 1.046628:  35%|###5      | 7/20 [02:05<03:22, 15.59s/it]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:  40%|####      | 8/20 [02:05<03:06, 15.55s/it]\u001b[A\u001b[32m[I 2023-02-13 18:42:16,366]\u001b[0m Trial 47 finished with value: 1.0466283765229367 and parameters: {'lambda_l1': 0.15040772080616424, 'lambda_l2': 0.0009178894078648313}. Best is trial 42 with value: 1.0466283765229367.\u001b[0m\n",
            "\n",
            "regularization_factors, val_score: 1.046628:  40%|####      | 8/20 [02:05<03:06, 15.55s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "regularization_factors, val_score: 1.046628:  40%|####      | 8/20 [02:21<03:06, 15.55s/it]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:  45%|####5     | 9/20 [02:21<02:50, 15.51s/it]\u001b[A\u001b[32m[I 2023-02-13 18:42:31,798]\u001b[0m Trial 48 finished with value: 1.0466283765229367 and parameters: {'lambda_l1': 0.0013745830000784286, 'lambda_l2': 1.8111594470093702e-07}. Best is trial 42 with value: 1.0466283765229367.\u001b[0m\n",
            "\n",
            "regularization_factors, val_score: 1.046628:  45%|####5     | 9/20 [02:21<02:50, 15.51s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "regularization_factors, val_score: 1.046628:  45%|####5     | 9/20 [02:36<02:50, 15.51s/it]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:  50%|#####     | 10/20 [02:36<02:34, 15.45s/it]\u001b[A\u001b[32m[I 2023-02-13 18:42:47,096]\u001b[0m Trial 49 finished with value: 1.0466283751831178 and parameters: {'lambda_l1': 2.1006326378056314e-05, 'lambda_l2': 1.7524210532753124e-08}. Best is trial 49 with value: 1.0466283751831178.\u001b[0m\n",
            "\n",
            "regularization_factors, val_score: 1.046628:  50%|#####     | 10/20 [02:36<02:34, 15.45s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "regularization_factors, val_score: 1.046628:  50%|#####     | 10/20 [02:51<02:34, 15.45s/it]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:  55%|#####5    | 11/20 [02:51<02:18, 15.42s/it]\u001b[A\u001b[32m[I 2023-02-13 18:43:02,452]\u001b[0m Trial 50 finished with value: 1.0466283751831178 and parameters: {'lambda_l1': 8.976676240459449e-05, 'lambda_l2': 2.3104307580783408e-05}. Best is trial 49 with value: 1.0466283751831178.\u001b[0m\n",
            "\n",
            "regularization_factors, val_score: 1.046628:  55%|#####5    | 11/20 [02:51<02:18, 15.42s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "regularization_factors, val_score: 1.046628:  55%|#####5    | 11/20 [03:07<02:18, 15.42s/it]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:  60%|######    | 12/20 [03:07<02:03, 15.43s/it]\u001b[A\u001b[32m[I 2023-02-13 18:43:17,912]\u001b[0m Trial 51 finished with value: 1.0466283751831178 and parameters: {'lambda_l1': 4.680526983257076e-05, 'lambda_l2': 1.1713592332293186e-05}. Best is trial 49 with value: 1.0466283751831178.\u001b[0m\n",
            "\n",
            "regularization_factors, val_score: 1.046628:  60%|######    | 12/20 [03:07<02:03, 15.43s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "regularization_factors, val_score: 1.046628:  60%|######    | 12/20 [03:22<02:03, 15.43s/it]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:  65%|######5   | 13/20 [03:22<01:47, 15.41s/it]\u001b[A\u001b[32m[I 2023-02-13 18:43:33,262]\u001b[0m Trial 52 finished with value: 1.0466283751831178 and parameters: {'lambda_l1': 0.00011851020211129796, 'lambda_l2': 1.1494352053441464e-08}. Best is trial 49 with value: 1.0466283751831178.\u001b[0m\n",
            "\n",
            "regularization_factors, val_score: 1.046628:  65%|######5   | 13/20 [03:22<01:47, 15.41s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "regularization_factors, val_score: 1.046628:  65%|######5   | 13/20 [03:38<01:47, 15.41s/it]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:  70%|#######   | 14/20 [03:38<01:32, 15.40s/it]\u001b[A\u001b[32m[I 2023-02-13 18:43:48,657]\u001b[0m Trial 53 finished with value: 1.0466283751831178 and parameters: {'lambda_l1': 0.001633029608026928, 'lambda_l2': 6.038057023538182}. Best is trial 49 with value: 1.0466283751831178.\u001b[0m\n",
            "\n",
            "regularization_factors, val_score: 1.046628:  70%|#######   | 14/20 [03:38<01:32, 15.40s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "regularization_factors, val_score: 1.046628:  70%|#######   | 14/20 [03:53<01:32, 15.40s/it]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:  75%|#######5  | 15/20 [03:53<01:17, 15.41s/it]\u001b[A\u001b[32m[I 2023-02-13 18:44:04,077]\u001b[0m Trial 54 finished with value: 1.0466283751831178 and parameters: {'lambda_l1': 8.69067765610809e-06, 'lambda_l2': 5.609528634480075e-06}. Best is trial 49 with value: 1.0466283751831178.\u001b[0m\n",
            "\n",
            "regularization_factors, val_score: 1.046628:  75%|#######5  | 15/20 [03:53<01:17, 15.41s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "regularization_factors, val_score: 1.046628:  75%|#######5  | 15/20 [04:08<01:17, 15.41s/it]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:  80%|########  | 16/20 [04:08<01:01, 15.38s/it]\u001b[A\u001b[32m[I 2023-02-13 18:44:19,402]\u001b[0m Trial 55 finished with value: 1.0466283751831178 and parameters: {'lambda_l1': 0.00046392926144233504, 'lambda_l2': 0.00016272995285589628}. Best is trial 49 with value: 1.0466283751831178.\u001b[0m\n",
            "\n",
            "regularization_factors, val_score: 1.046628:  80%|########  | 16/20 [04:08<01:01, 15.38s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "regularization_factors, val_score: 1.046628:  80%|########  | 16/20 [04:24<01:01, 15.38s/it]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:  85%|########5 | 17/20 [04:24<00:46, 15.37s/it]\u001b[A\u001b[32m[I 2023-02-13 18:44:34,731]\u001b[0m Trial 56 finished with value: 1.0466283751831178 and parameters: {'lambda_l1': 0.012578730668818552, 'lambda_l2': 7.392914698703714e-07}. Best is trial 49 with value: 1.0466283751831178.\u001b[0m\n",
            "\n",
            "regularization_factors, val_score: 1.046628:  85%|########5 | 17/20 [04:24<00:46, 15.37s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "regularization_factors, val_score: 1.046628:  85%|########5 | 17/20 [04:39<00:46, 15.37s/it]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:  90%|######### | 18/20 [04:39<00:30, 15.34s/it]\u001b[A\u001b[32m[I 2023-02-13 18:44:50,024]\u001b[0m Trial 57 finished with value: 1.0466283751831178 and parameters: {'lambda_l1': 1.1472265180800114e-05, 'lambda_l2': 5.178296135174621e-06}. Best is trial 49 with value: 1.0466283751831178.\u001b[0m\n",
            "\n",
            "regularization_factors, val_score: 1.046628:  90%|######### | 18/20 [04:39<00:30, 15.34s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "regularization_factors, val_score: 1.046628:  90%|######### | 18/20 [04:56<00:30, 15.34s/it]\u001b[A\n",
            "regularization_factors, val_score: 1.046628:  95%|#########5| 19/20 [04:56<00:15, 15.96s/it]\u001b[A\u001b[32m[I 2023-02-13 18:45:07,403]\u001b[0m Trial 58 finished with value: 1.0466283751831178 and parameters: {'lambda_l1': 7.213659343212656e-05, 'lambda_l2': 9.936317249944875e-08}. Best is trial 49 with value: 1.0466283751831178.\u001b[0m\n",
            "\n",
            "regularization_factors, val_score: 1.046628:  95%|#########5| 19/20 [04:56<00:15, 15.96s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "regularization_factors, val_score: 1.046628:  95%|#########5| 19/20 [05:14<00:15, 15.96s/it]\u001b[A\n",
            "regularization_factors, val_score: 1.046628: 100%|##########| 20/20 [05:14<00:00, 16.30s/it]\u001b[A\u001b[32m[I 2023-02-13 18:45:24,501]\u001b[0m Trial 59 finished with value: 1.0466283751831178 and parameters: {'lambda_l1': 0.008326325620860267, 'lambda_l2': 1.0243516422736778e-08}. Best is trial 49 with value: 1.0466283751831178.\u001b[0m\n",
            "regularization_factors, val_score: 1.046628: 100%|##########| 20/20 [05:14<00:00, 15.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            "min_data_in_leaf, val_score: 1.046628:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            "min_data_in_leaf, val_score: 1.046628:   0%|          | 0/5 [00:11<?, ?it/s]\u001b[A\n",
            "min_data_in_leaf, val_score: 1.046628:  20%|##        | 1/5 [00:11<00:44, 11.15s/it]\u001b[A\u001b[32m[I 2023-02-13 18:45:35,676]\u001b[0m Trial 60 finished with value: 1.0466283751831178 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 1.0466283751831178.\u001b[0m\n",
            "\n",
            "min_data_in_leaf, val_score: 1.046628:  20%|##        | 1/5 [00:11<00:44, 11.15s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "min_data_in_leaf, val_score: 1.046628:  20%|##        | 1/5 [00:23<00:44, 11.15s/it]\u001b[A\n",
            "min_data_in_leaf, val_score: 1.046628:  40%|####      | 2/5 [00:23<00:36, 12.13s/it]\u001b[A\u001b[32m[I 2023-02-13 18:45:48,485]\u001b[0m Trial 61 finished with value: 1.0466283751831178 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 1.0466283751831178.\u001b[0m\n",
            "\n",
            "min_data_in_leaf, val_score: 1.046628:  40%|####      | 2/5 [00:23<00:36, 12.13s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "min_data_in_leaf, val_score: 1.046628:  40%|####      | 2/5 [00:43<00:36, 12.13s/it]\u001b[A\n",
            "min_data_in_leaf, val_score: 1.046628:  60%|######    | 3/5 [00:43<00:30, 15.42s/it]\u001b[A\u001b[32m[I 2023-02-13 18:46:07,829]\u001b[0m Trial 62 finished with value: 1.0466283751831178 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 1.0466283751831178.\u001b[0m\n",
            "\n",
            "min_data_in_leaf, val_score: 1.046628:  60%|######    | 3/5 [00:43<00:30, 15.42s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "min_data_in_leaf, val_score: 1.046628:  60%|######    | 3/5 [00:59<00:30, 15.42s/it]\u001b[A\n",
            "min_data_in_leaf, val_score: 1.046628:  80%|########  | 4/5 [00:59<00:15, 15.85s/it]\u001b[A\u001b[32m[I 2023-02-13 18:46:24,337]\u001b[0m Trial 63 finished with value: 1.0466283751831178 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 1.0466283751831178.\u001b[0m\n",
            "\n",
            "min_data_in_leaf, val_score: 1.046628:  80%|########  | 4/5 [00:59<00:15, 15.85s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "min_data_in_leaf, val_score: 1.046628:  80%|########  | 4/5 [01:15<00:15, 15.85s/it]\u001b[A\n",
            "min_data_in_leaf, val_score: 1.046628: 100%|##########| 5/5 [01:15<00:00, 15.80s/it]\u001b[A\u001b[32m[I 2023-02-13 18:46:40,038]\u001b[0m Trial 64 finished with value: 1.0466283751831178 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 1.0466283751831178.\u001b[0m\n",
            "min_data_in_leaf, val_score: 1.046628: 100%|##########| 5/5 [01:15<00:00, 15.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n",
            "Best params: {'objective': 'regression', 'metric': 'rmse', 'random_state': 109, 'boosting_type': 'gbdt', 'verbose': -1, 'feature_pre_filter': False, 'lambda_l1': 2.1006326378056314e-05, 'lambda_l2': 1.7524210532753124e-08, 'num_leaves': 38, 'feature_fraction': 0.4, 'bagging_fraction': 0.6334180791467596, 'bagging_freq': 2, 'min_child_samples': 20}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#探索したパラメータで学習\n",
        "import lightgbm as lgb\n",
        "\n",
        "dtrain = lgb.Dataset(x_train, label=y_train)\n",
        "ddev = lgb.Dataset(x_dev,label= y_dev)\n",
        "\n",
        "# 使用するパラメータ\n",
        "params = best_params\n",
        "verbose_eval = 0  # この数字を1にすると学習時のスコア推移がコマンドライン表示される\n",
        "# https://qiita.com/c60evaporator/items/2b7a2820d575e212bcf4\n",
        "\n",
        "# early_stoppingを指定してLightGBM学習　回帰\n",
        "gbm = lgb.train(params, dtrain,\n",
        "                valid_sets=[ddev],  # early_stoppingの評価用データ\n",
        "                # feval=lgb_custom_metric_qwk_regression,\n",
        "                num_boost_round=10000,  # 最大学習サイクル数。early_stopping使用時は大きな値を入力\n",
        "                callbacks=[lgb.early_stopping(stopping_rounds=32, verbose=True)] # early_stopping用コールバック関数\n",
        "                )\n",
        "\n",
        "# https://qiita.com/c60evaporator/items/2b7a2820d575e212bcf4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWPIwzHQmVG9",
        "outputId": "793bcd94-eb11-43f4-d5ad-3a3954b726ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\tvalid_0's rmse: 1.19165\n",
            "Training until validation scores don't improve for 32 rounds.\n",
            "[2]\tvalid_0's rmse: 1.18369\n",
            "[3]\tvalid_0's rmse: 1.17632\n",
            "[4]\tvalid_0's rmse: 1.16965\n",
            "[5]\tvalid_0's rmse: 1.16285\n",
            "[6]\tvalid_0's rmse: 1.15801\n",
            "[7]\tvalid_0's rmse: 1.15151\n",
            "[8]\tvalid_0's rmse: 1.14688\n",
            "[9]\tvalid_0's rmse: 1.14434\n",
            "[10]\tvalid_0's rmse: 1.1396\n",
            "[11]\tvalid_0's rmse: 1.13612\n",
            "[12]\tvalid_0's rmse: 1.13361\n",
            "[13]\tvalid_0's rmse: 1.13069\n",
            "[14]\tvalid_0's rmse: 1.1271\n",
            "[15]\tvalid_0's rmse: 1.12418\n",
            "[16]\tvalid_0's rmse: 1.12137\n",
            "[17]\tvalid_0's rmse: 1.11906\n",
            "[18]\tvalid_0's rmse: 1.1171\n",
            "[19]\tvalid_0's rmse: 1.11406\n",
            "[20]\tvalid_0's rmse: 1.112\n",
            "[21]\tvalid_0's rmse: 1.11008\n",
            "[22]\tvalid_0's rmse: 1.10896\n",
            "[23]\tvalid_0's rmse: 1.10638\n",
            "[24]\tvalid_0's rmse: 1.10368\n",
            "[25]\tvalid_0's rmse: 1.10264\n",
            "[26]\tvalid_0's rmse: 1.10025\n",
            "[27]\tvalid_0's rmse: 1.09795\n",
            "[28]\tvalid_0's rmse: 1.0957\n",
            "[29]\tvalid_0's rmse: 1.09458\n",
            "[30]\tvalid_0's rmse: 1.09327\n",
            "[31]\tvalid_0's rmse: 1.09091\n",
            "[32]\tvalid_0's rmse: 1.08899\n",
            "[33]\tvalid_0's rmse: 1.08765\n",
            "[34]\tvalid_0's rmse: 1.08622\n",
            "[35]\tvalid_0's rmse: 1.085\n",
            "[36]\tvalid_0's rmse: 1.08393\n",
            "[37]\tvalid_0's rmse: 1.08281\n",
            "[38]\tvalid_0's rmse: 1.08194\n",
            "[39]\tvalid_0's rmse: 1.08066\n",
            "[40]\tvalid_0's rmse: 1.0793\n",
            "[41]\tvalid_0's rmse: 1.07826\n",
            "[42]\tvalid_0's rmse: 1.07708\n",
            "[43]\tvalid_0's rmse: 1.0759\n",
            "[44]\tvalid_0's rmse: 1.07497\n",
            "[45]\tvalid_0's rmse: 1.07384\n",
            "[46]\tvalid_0's rmse: 1.07345\n",
            "[47]\tvalid_0's rmse: 1.07248\n",
            "[48]\tvalid_0's rmse: 1.07166\n",
            "[49]\tvalid_0's rmse: 1.07159\n",
            "[50]\tvalid_0's rmse: 1.071\n",
            "[51]\tvalid_0's rmse: 1.07035\n",
            "[52]\tvalid_0's rmse: 1.06958\n",
            "[53]\tvalid_0's rmse: 1.06853\n",
            "[54]\tvalid_0's rmse: 1.06731\n",
            "[55]\tvalid_0's rmse: 1.067\n",
            "[56]\tvalid_0's rmse: 1.06659\n",
            "[57]\tvalid_0's rmse: 1.06559\n",
            "[58]\tvalid_0's rmse: 1.06513\n",
            "[59]\tvalid_0's rmse: 1.06452\n",
            "[60]\tvalid_0's rmse: 1.06363\n",
            "[61]\tvalid_0's rmse: 1.06257\n",
            "[62]\tvalid_0's rmse: 1.06213\n",
            "[63]\tvalid_0's rmse: 1.06175\n",
            "[64]\tvalid_0's rmse: 1.06133\n",
            "[65]\tvalid_0's rmse: 1.06124\n",
            "[66]\tvalid_0's rmse: 1.06085\n",
            "[67]\tvalid_0's rmse: 1.06032\n",
            "[68]\tvalid_0's rmse: 1.05975\n",
            "[69]\tvalid_0's rmse: 1.05949\n",
            "[70]\tvalid_0's rmse: 1.05966\n",
            "[71]\tvalid_0's rmse: 1.05911\n",
            "[72]\tvalid_0's rmse: 1.05877\n",
            "[73]\tvalid_0's rmse: 1.05874\n",
            "[74]\tvalid_0's rmse: 1.05814\n",
            "[75]\tvalid_0's rmse: 1.05785\n",
            "[76]\tvalid_0's rmse: 1.05775\n",
            "[77]\tvalid_0's rmse: 1.05803\n",
            "[78]\tvalid_0's rmse: 1.0576\n",
            "[79]\tvalid_0's rmse: 1.05712\n",
            "[80]\tvalid_0's rmse: 1.05718\n",
            "[81]\tvalid_0's rmse: 1.05703\n",
            "[82]\tvalid_0's rmse: 1.05689\n",
            "[83]\tvalid_0's rmse: 1.05658\n",
            "[84]\tvalid_0's rmse: 1.05567\n",
            "[85]\tvalid_0's rmse: 1.05535\n",
            "[86]\tvalid_0's rmse: 1.0549\n",
            "[87]\tvalid_0's rmse: 1.05462\n",
            "[88]\tvalid_0's rmse: 1.05462\n",
            "[89]\tvalid_0's rmse: 1.05456\n",
            "[90]\tvalid_0's rmse: 1.05424\n",
            "[91]\tvalid_0's rmse: 1.05443\n",
            "[92]\tvalid_0's rmse: 1.05396\n",
            "[93]\tvalid_0's rmse: 1.05327\n",
            "[94]\tvalid_0's rmse: 1.05336\n",
            "[95]\tvalid_0's rmse: 1.05363\n",
            "[96]\tvalid_0's rmse: 1.05374\n",
            "[97]\tvalid_0's rmse: 1.05373\n",
            "[98]\tvalid_0's rmse: 1.0533\n",
            "[99]\tvalid_0's rmse: 1.05285\n",
            "[100]\tvalid_0's rmse: 1.05248\n",
            "[101]\tvalid_0's rmse: 1.05264\n",
            "[102]\tvalid_0's rmse: 1.05246\n",
            "[103]\tvalid_0's rmse: 1.05222\n",
            "[104]\tvalid_0's rmse: 1.05215\n",
            "[105]\tvalid_0's rmse: 1.05212\n",
            "[106]\tvalid_0's rmse: 1.05162\n",
            "[107]\tvalid_0's rmse: 1.0515\n",
            "[108]\tvalid_0's rmse: 1.05148\n",
            "[109]\tvalid_0's rmse: 1.05116\n",
            "[110]\tvalid_0's rmse: 1.05086\n",
            "[111]\tvalid_0's rmse: 1.05052\n",
            "[112]\tvalid_0's rmse: 1.05003\n",
            "[113]\tvalid_0's rmse: 1.05021\n",
            "[114]\tvalid_0's rmse: 1.04995\n",
            "[115]\tvalid_0's rmse: 1.05021\n",
            "[116]\tvalid_0's rmse: 1.04982\n",
            "[117]\tvalid_0's rmse: 1.04952\n",
            "[118]\tvalid_0's rmse: 1.04977\n",
            "[119]\tvalid_0's rmse: 1.04967\n",
            "[120]\tvalid_0's rmse: 1.04966\n",
            "[121]\tvalid_0's rmse: 1.05012\n",
            "[122]\tvalid_0's rmse: 1.04977\n",
            "[123]\tvalid_0's rmse: 1.04948\n",
            "[124]\tvalid_0's rmse: 1.04899\n",
            "[125]\tvalid_0's rmse: 1.04867\n",
            "[126]\tvalid_0's rmse: 1.0489\n",
            "[127]\tvalid_0's rmse: 1.04899\n",
            "[128]\tvalid_0's rmse: 1.04889\n",
            "[129]\tvalid_0's rmse: 1.04905\n",
            "[130]\tvalid_0's rmse: 1.04908\n",
            "[131]\tvalid_0's rmse: 1.04951\n",
            "[132]\tvalid_0's rmse: 1.04914\n",
            "[133]\tvalid_0's rmse: 1.04902\n",
            "[134]\tvalid_0's rmse: 1.04868\n",
            "[135]\tvalid_0's rmse: 1.04862\n",
            "[136]\tvalid_0's rmse: 1.049\n",
            "[137]\tvalid_0's rmse: 1.04883\n",
            "[138]\tvalid_0's rmse: 1.04861\n",
            "[139]\tvalid_0's rmse: 1.04886\n",
            "[140]\tvalid_0's rmse: 1.04884\n",
            "[141]\tvalid_0's rmse: 1.04852\n",
            "[142]\tvalid_0's rmse: 1.0485\n",
            "[143]\tvalid_0's rmse: 1.04834\n",
            "[144]\tvalid_0's rmse: 1.0482\n",
            "[145]\tvalid_0's rmse: 1.04828\n",
            "[146]\tvalid_0's rmse: 1.04826\n",
            "[147]\tvalid_0's rmse: 1.0486\n",
            "[148]\tvalid_0's rmse: 1.04828\n",
            "[149]\tvalid_0's rmse: 1.04843\n",
            "[150]\tvalid_0's rmse: 1.04866\n",
            "[151]\tvalid_0's rmse: 1.04836\n",
            "[152]\tvalid_0's rmse: 1.04854\n",
            "[153]\tvalid_0's rmse: 1.04851\n",
            "[154]\tvalid_0's rmse: 1.04883\n",
            "[155]\tvalid_0's rmse: 1.04848\n",
            "[156]\tvalid_0's rmse: 1.04844\n",
            "[157]\tvalid_0's rmse: 1.04833\n",
            "[158]\tvalid_0's rmse: 1.0484\n",
            "[159]\tvalid_0's rmse: 1.04776\n",
            "[160]\tvalid_0's rmse: 1.04715\n",
            "[161]\tvalid_0's rmse: 1.0473\n",
            "[162]\tvalid_0's rmse: 1.04723\n",
            "[163]\tvalid_0's rmse: 1.04753\n",
            "[164]\tvalid_0's rmse: 1.04751\n",
            "[165]\tvalid_0's rmse: 1.04742\n",
            "[166]\tvalid_0's rmse: 1.04713\n",
            "[167]\tvalid_0's rmse: 1.04684\n",
            "[168]\tvalid_0's rmse: 1.04663\n",
            "[169]\tvalid_0's rmse: 1.04696\n",
            "[170]\tvalid_0's rmse: 1.04724\n",
            "[171]\tvalid_0's rmse: 1.04744\n",
            "[172]\tvalid_0's rmse: 1.04746\n",
            "[173]\tvalid_0's rmse: 1.04749\n",
            "[174]\tvalid_0's rmse: 1.04768\n",
            "[175]\tvalid_0's rmse: 1.04771\n",
            "[176]\tvalid_0's rmse: 1.0475\n",
            "[177]\tvalid_0's rmse: 1.04768\n",
            "[178]\tvalid_0's rmse: 1.04803\n",
            "[179]\tvalid_0's rmse: 1.04793\n",
            "[180]\tvalid_0's rmse: 1.048\n",
            "[181]\tvalid_0's rmse: 1.04776\n",
            "[182]\tvalid_0's rmse: 1.04803\n",
            "[183]\tvalid_0's rmse: 1.0484\n",
            "[184]\tvalid_0's rmse: 1.04923\n",
            "[185]\tvalid_0's rmse: 1.04934\n",
            "[186]\tvalid_0's rmse: 1.04966\n",
            "[187]\tvalid_0's rmse: 1.04999\n",
            "[188]\tvalid_0's rmse: 1.05042\n",
            "[189]\tvalid_0's rmse: 1.05041\n",
            "[190]\tvalid_0's rmse: 1.05024\n",
            "[191]\tvalid_0's rmse: 1.05067\n",
            "[192]\tvalid_0's rmse: 1.05085\n",
            "[193]\tvalid_0's rmse: 1.05096\n",
            "[194]\tvalid_0's rmse: 1.05076\n",
            "[195]\tvalid_0's rmse: 1.05079\n",
            "[196]\tvalid_0's rmse: 1.05118\n",
            "[197]\tvalid_0's rmse: 1.05112\n",
            "[198]\tvalid_0's rmse: 1.05128\n",
            "[199]\tvalid_0's rmse: 1.05142\n",
            "[200]\tvalid_0's rmse: 1.05179\n",
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's rmse: 1.04663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPJ9xQkj-tRJ",
        "outputId": "8465e744-915a-4769-ebb7-b034359d2092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.8/dist-packages (3.1.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.9.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.4.46)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.8/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from optuna) (0.9.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (6.0.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (5.10.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.12.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optuna を使って QWK の閾値を最適化\n",
        "import optuna\n",
        "\n",
        "y_pred = gbm.predict(x_dev)\n",
        "y_pred = np.clip(y_pred, -2, 2)\n",
        "y_pred_dev = [int(Decimal(str(num)).quantize(Decimal('0'), rounding=ROUND_HALF_UP)) for num in y_pred]\n",
        "# print(type(y_dev))\n",
        "objective = OptunaRounder(y_dev, y_pred_dev)\n",
        "# print(y_pred_)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100, timeout=100)\n",
        "\n",
        "# 見つけた閾値\n",
        "best_thresholds = sorted(study.best_params.values())\n",
        "print(f'Optimized thresholds: {best_thresholds}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "391q4lHamidE",
        "outputId": "2430e591-f177-4334-f7df-c42580430400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-13 18:47:12,916]\u001b[0m A new study created in memory with name: no-name-b72069b9-1f6b-4d4f-a002-55e4b2b265f9\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:12,927]\u001b[0m Trial 0 finished with value: 0.010384373668737568 and parameters: {'t0': 1.2855961548787351, 't1': 1.8280949980789245, 't2': 1.9017821460464197, 't3': 1.9182631050831989}. Best is trial 0 with value: 0.010384373668737568.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:12,934]\u001b[0m Trial 1 finished with value: 0.018031725923273956 and parameters: {'t0': -1.7421612249005727, 't1': 1.206848911198013, 't2': 1.6535019144063816, 't3': 1.7458021437565148}. Best is trial 1 with value: 0.018031725923273956.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:12,941]\u001b[0m Trial 2 finished with value: 0.010384373668737568 and parameters: {'t0': 1.2395614862485016, 't1': 1.6771459532774637, 't2': 1.775368895627924, 't3': 1.8487917350619958}. Best is trial 1 with value: 0.018031725923273956.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:12,947]\u001b[0m Trial 3 finished with value: 0.010384373668737568 and parameters: {'t0': 1.893671147764194, 't1': 1.9641408780270058, 't2': 1.9822943803601474, 't3': 1.9874165975740572}. Best is trial 1 with value: 0.018031725923273956.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:12,953]\u001b[0m Trial 4 finished with value: 0.18495788101781863 and parameters: {'t0': -1.0934386312637554, 't1': -0.5303288339246399, 't2': 1.8407631089696643, 't3': 1.9040684807873776}. Best is trial 4 with value: 0.18495788101781863.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:12,960]\u001b[0m Trial 5 finished with value: 0.018031725923273956 and parameters: {'t0': -1.3348522598091899, 't1': 1.0826878372551643, 't2': 1.6346169848646541, 't3': 1.9087383023464024}. Best is trial 4 with value: 0.18495788101781863.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:12,967]\u001b[0m Trial 6 finished with value: 0.09901153441157773 and parameters: {'t0': -0.29415546838658857, 't1': 1.01415995145483, 't2': 1.6137672615105592, 't3': 1.6607856504347545}. Best is trial 4 with value: 0.18495788101781863.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:12,974]\u001b[0m Trial 7 finished with value: 0.018031725923273956 and parameters: {'t0': -1.827816627522906, 't1': 1.618246908782778, 't2': 1.9327260763498944, 't3': 1.9764911863260948}. Best is trial 4 with value: 0.18495788101781863.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:12,983]\u001b[0m Trial 8 finished with value: 0.07163940898884946 and parameters: {'t0': 0.9841323806623832, 't1': 1.4702509478992598, 't2': 1.6206569494416232, 't3': 1.7208500959064725}. Best is trial 4 with value: 0.18495788101781863.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:12,990]\u001b[0m Trial 9 finished with value: 0.21539738596895508 and parameters: {'t0': -0.4599058152802993, 't1': 0.364628259849316, 't2': 1.9056583943794816, 't3': 1.9802879596552092}. Best is trial 9 with value: 0.21539738596895508.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,009]\u001b[0m Trial 10 finished with value: 0.3080316234251903 and parameters: {'t0': -0.2559454550134521, 't1': 0.3453330674266203, 't2': 0.9377068469630058, 't3': 1.2880385910406604}. Best is trial 10 with value: 0.3080316234251903.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,030]\u001b[0m Trial 11 finished with value: 0.3080316234251903 and parameters: {'t0': -0.32241401419199667, 't1': 0.3882633689827558, 't2': 0.8369870388937056, 't3': 1.2312692275737267}. Best is trial 10 with value: 0.3080316234251903.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,051]\u001b[0m Trial 12 finished with value: 0.19615274042022368 and parameters: {'t0': 0.23690993385798897, 't1': 0.5215423933851531, 't2': 0.7807424427559005, 't3': 1.1422525345328385}. Best is trial 10 with value: 0.3080316234251903.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,075]\u001b[0m Trial 13 finished with value: 0.19615274042022368 and parameters: {'t0': 0.25727359015051987, 't1': 0.4940321309376007, 't2': 0.8864947971172001, 't3': 1.2341182293192883}. Best is trial 10 with value: 0.3080316234251903.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,096]\u001b[0m Trial 14 finished with value: 0.3484939450622294 and parameters: {'t0': -0.79647526759893, 't1': 0.05116357373935487, 't2': 0.34636494292670783, 't3': 0.8124037812837545}. Best is trial 14 with value: 0.3484939450622294.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,114]\u001b[0m Trial 15 finished with value: 0.4281620024285576 and parameters: {'t0': -0.7459242942134579, 't1': -0.01656552952241752, 't2': 0.29354630011163285, 't3': 0.6261019444219256}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,136]\u001b[0m Trial 16 finished with value: 0.35263820504637644 and parameters: {'t0': -0.9105767589528272, 't1': -0.16362663306975456, 't2': -0.02598897554740942, 't3': 0.5252084501658576}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,158]\u001b[0m Trial 17 finished with value: 0.35263820504637644 and parameters: {'t0': -0.9680547985914687, 't1': -0.7532629802062697, 't2': -0.3568715010722363, 't3': 0.266993143499503}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,182]\u001b[0m Trial 18 finished with value: 0.23551695129316375 and parameters: {'t0': -1.512018106627746, 't1': -1.3469163447410657, 't2': -0.5991771652768988, 't3': 0.12365320965464965}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,203]\u001b[0m Trial 19 finished with value: 0.3484939450622294 and parameters: {'t0': -0.7518144338741335, 't1': 0.007133583505751648, 't2': 0.356096674121552, 't3': 0.5888242493392436}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,227]\u001b[0m Trial 20 finished with value: 0.06418510427615776 and parameters: {'t0': -1.9642928707538696, 't1': -1.885690096022714, 't2': -1.1888671089541127, 't3': -0.21158710067253872}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,248]\u001b[0m Trial 21 finished with value: 0.40051359854249924 and parameters: {'t0': -1.0826963947833004, 't1': -0.2564477489623769, 't2': 0.07183557687294873, 't3': 0.5600818781939787}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,270]\u001b[0m Trial 22 finished with value: 0.40051359854249924 and parameters: {'t0': -1.3175145654903162, 't1': -0.26916828795552794, 't2': 0.2875039249373915, 't3': 0.7611085623268281}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,292]\u001b[0m Trial 23 finished with value: 0.40051359854249924 and parameters: {'t0': -1.3091556537159394, 't1': -0.37225257658878885, 't2': 0.3444100213842448, 't3': 0.9588515314705985}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,315]\u001b[0m Trial 24 finished with value: 0.34680632275724144 and parameters: {'t0': -1.5530917834686608, 't1': -0.27118233321011936, 't2': 0.5997906337886358, 't3': 1.4427503688432246}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,338]\u001b[0m Trial 25 finished with value: 0.14812027016030604 and parameters: {'t0': -1.2013126860971848, 't1': 0.10004725777004554, 't2': 1.3492851163047397, 't3': 1.6580376778627146}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,360]\u001b[0m Trial 26 finished with value: 0.21539738596895508 and parameters: {'t0': -0.6570201422041437, 't1': 0.7664568040594201, 't2': 1.357502673880481, 't3': 1.626533408167273}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,384]\u001b[0m Trial 27 finished with value: 0.40051359854249924 and parameters: {'t0': -1.4992672038696586, 't1': -0.5649762798189143, 't2': 0.14617393146041488, 't3': 0.8098968592215313}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,406]\u001b[0m Trial 28 finished with value: 0.34680632275724144 and parameters: {'t0': -1.1014877657405782, 't1': -0.047005425089922545, 't2': 0.6755214621545231, 't3': 1.4402827628703645}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,430]\u001b[0m Trial 29 finished with value: 0.40051359854249924 and parameters: {'t0': -1.984584074681866, 't1': -0.7674827641093489, 't2': 0.023688272799410548, 't3': 0.6558233323882204}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,454]\u001b[0m Trial 30 finished with value: 0.21539738596895508 and parameters: {'t0': -0.5515377792370518, 't1': 0.20175470838250514, 't2': 1.1330494082656224, 't3': 1.514984942160114}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,477]\u001b[0m Trial 31 finished with value: 0.40051359854249924 and parameters: {'t0': -1.3078100606361447, 't1': -0.25491864156314437, 't2': 0.47945556495248404, 't3': 0.996151808106146}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,499]\u001b[0m Trial 32 finished with value: 0.40051359854249924 and parameters: {'t0': -1.584760042344266, 't1': -0.41764502253766744, 't2': 0.45908510967910904, 't3': 0.9411284400668423}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,522]\u001b[0m Trial 33 finished with value: 0.34680632275724144 and parameters: {'t0': -1.0282584243554427, 't1': -0.15568910617115772, 't2': 0.5913749739082904, 't3': 1.0380551995738097}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,545]\u001b[0m Trial 34 finished with value: 0.40051359854249924 and parameters: {'t0': -1.673494959877468, 't1': -0.37531507340695314, 't2': 0.2587998534017112, 't3': 0.8224045552775956}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,568]\u001b[0m Trial 35 finished with value: 0.2612996796259417 and parameters: {'t0': -1.2781766022078305, 't1': 0.18439616536474285, 't2': 0.6958928621364666, 't3': 1.1184557856338855}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,595]\u001b[0m Trial 36 finished with value: 0.4281620024285576 and parameters: {'t0': -0.9509464336146016, 't1': -0.07715661918103406, 't2': 0.5554130330980966, 't3': 0.9600401390311674}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,618]\u001b[0m Trial 37 finished with value: 0.4281620024285576 and parameters: {'t0': -0.8536744552125692, 't1': -0.03593740862916395, 't2': 0.5302046161900887, 't3': 0.8706048426267734}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,641]\u001b[0m Trial 38 finished with value: 0.3080316234251903 and parameters: {'t0': -0.7269659214083792, 't1': 0.22247300450559088, 't2': 0.9124768018163427, 't3': 1.3282937784570437}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,664]\u001b[0m Trial 39 finished with value: 0.21539738596895508 and parameters: {'t0': -0.8691330190683901, 't1': 0.6660786842984652, 't2': 1.783397086062795, 't3': 1.9359822432769596}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,687]\u001b[0m Trial 40 finished with value: 0.40051359854249924 and parameters: {'t0': -1.0929022330085338, 't1': -0.10156832441475024, 't2': 0.5119149196858546, 't3': 0.8980482831481973}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,712]\u001b[0m Trial 41 finished with value: 0.3080316234251903 and parameters: {'t0': -0.9704807009507823, 't1': 0.022205427978026014, 't2': 0.6902025882327059, 't3': 1.071691500948093}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,735]\u001b[0m Trial 42 finished with value: 0.3484939450622294 and parameters: {'t0': -0.5457668654890566, 't1': 0.10187663777402922, 't2': 0.5512999750586844, 't3': 0.8975067240749826}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,759]\u001b[0m Trial 43 finished with value: 0.40051359854249924 and parameters: {'t0': -1.35707170350168, 't1': -0.11999747820444925, 't2': 0.4601538099325182, 't3': 0.7293703106806741}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,782]\u001b[0m Trial 44 finished with value: 0.40051359854249924 and parameters: {'t0': -1.7399174357346443, 't1': -0.6135817048434775, 't2': 0.2020101458409582, 't3': 0.7276615110296972}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,806]\u001b[0m Trial 45 finished with value: 0.09901153441157773 and parameters: {'t0': -0.41276266977045883, 't1': 1.342609836879027, 't2': 1.8436100859123759, 't3': 1.9609574402496661}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,831]\u001b[0m Trial 46 finished with value: 0.14812027016030604 and parameters: {'t0': -1.159746961930756, 't1': 0.2986096115686393, 't2': 1.085054132973216, 't3': 1.7641897711055021}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,865]\u001b[0m Trial 47 finished with value: 0.21539738596895508 and parameters: {'t0': -0.12942442190261683, 't1': 0.9354018205612105, 't2': 1.667347822926616, 't3': 1.8532582397655921}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,890]\u001b[0m Trial 48 finished with value: 0.3080316234251903 and parameters: {'t0': -0.64432869746224, 't1': 0.1336653936301935, 't2': 0.9770967362509932, 't3': 1.3647443483972592}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,915]\u001b[0m Trial 49 finished with value: 0.21539738596895508 and parameters: {'t0': -0.8372867187416976, 't1': 0.46500629139692035, 't2': 1.3008469840146097, 't3': 1.863302874838963}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,938]\u001b[0m Trial 50 finished with value: 0.34680632275724144 and parameters: {'t0': -1.1176131078639289, 't1': -0.006917126319028188, 't2': 0.81276039913367, 't3': 1.1742677385572207}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,962]\u001b[0m Trial 51 finished with value: 0.40051359854249924 and parameters: {'t0': -1.425906240126221, 't1': -0.30564272868618164, 't2': 0.3782086194872549, 't3': 0.9798261903194823}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:13,986]\u001b[0m Trial 52 finished with value: 0.34680632275724144 and parameters: {'t0': -1.350264970624937, 't1': -0.18003085773838007, 't2': 0.39768381653498575, 't3': 1.0345179900578625}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,010]\u001b[0m Trial 53 finished with value: 0.4281620024285576 and parameters: {'t0': -0.9546034089398097, 't1': -0.07604558648140372, 't2': 0.3167463269616009, 't3': 0.8562751276620877}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,033]\u001b[0m Trial 54 finished with value: 0.4281620024285576 and parameters: {'t0': -0.9408407181343349, 't1': -0.00945663132418334, 't2': 0.6108397736331914, 't3': 0.8541567999627959}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,059]\u001b[0m Trial 55 finished with value: 0.3484939450622294 and parameters: {'t0': -0.9241985778434886, 't1': 0.3303184480669459, 't2': 0.7267054207325936, 't3': 0.9065275635127892}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,083]\u001b[0m Trial 56 finished with value: 0.4281620024285576 and parameters: {'t0': -0.7803420982965701, 't1': -0.042834419868101645, 't2': 0.611269828030155, 't3': 0.8642703442521628}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,106]\u001b[0m Trial 57 finished with value: 0.3924196098870515 and parameters: {'t0': -0.7957864772049151, 't1': -0.048080079987242355, 't2': 0.6430213328976861, 't3': 1.0863419664249772}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,132]\u001b[0m Trial 58 finished with value: 0.3080316234251903 and parameters: {'t0': -0.46586347410067813, 't1': 0.09786790474196468, 't2': 0.7533602382820065, 't3': 1.015738433850266}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,159]\u001b[0m Trial 59 finished with value: 0.3484939450622294 and parameters: {'t0': -0.6617761692998656, 't1': 0.25730571387848566, 't2': 0.6294280940885875, 't3': 0.9395735971740338}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,188]\u001b[0m Trial 60 finished with value: 0.3484939450622294 and parameters: {'t0': -0.9236363143977511, 't1': 0.040701231463669274, 't2': 0.5568228717675019, 't3': 0.856144661712251}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,215]\u001b[0m Trial 61 finished with value: 0.40051359854249924 and parameters: {'t0': -1.0239726558296336, 't1': -0.16757342693289556, 't2': 0.44410813831108403, 't3': 0.8557186051039795}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,241]\u001b[0m Trial 62 finished with value: 0.4281620024285576 and parameters: {'t0': -0.7831842553460775, 't1': -0.10183565322578231, 't2': 0.5302844441160167, 't3': 0.7760414887647249}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,263]\u001b[0m Trial 63 finished with value: 0.4281620024285576 and parameters: {'t0': -0.7885013744679157, 't1': -0.056535930682866775, 't2': 0.5384114463577824, 't3': 0.7759673501779294}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,291]\u001b[0m Trial 64 finished with value: 0.3484939450622294 and parameters: {'t0': -0.3010058633608963, 't1': 0.1342861008414638, 't2': 0.6274441075175137, 't3': 0.986370024591093}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,318]\u001b[0m Trial 65 finished with value: 0.4281620024285576 and parameters: {'t0': -0.5825853223375378, 't1': -0.02640976021847189, 't2': 0.7991218469376569, 't3': 0.9304671457018666}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,343]\u001b[0m Trial 66 finished with value: 0.3484939450622294 and parameters: {'t0': -0.7408587055330514, 't1': 0.26425880344185704, 't2': 0.5728462127585964, 't3': 0.8874970612768125}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,367]\u001b[0m Trial 67 finished with value: 0.3484939450622294 and parameters: {'t0': -0.39353533920506834, 't1': 0.052602169895013165, 't2': 0.7441224023647525, 't3': 0.9607738896347657}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,389]\u001b[0m Trial 68 finished with value: 0.3159871244635194 and parameters: {'t0': -1.197030724749443, 't1': 0.3996024833120262, 't2': 0.8577550878144449, 't3': 0.976208069107557}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,415]\u001b[0m Trial 69 finished with value: 0.3484939450622294 and parameters: {'t0': -0.49433836244809054, 't1': 0.18325599734338388, 't2': 0.4993806882351026, 't3': 0.8419522975902275}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,440]\u001b[0m Trial 70 finished with value: 0.4281620024285576 and parameters: {'t0': -0.888083553171184, 't1': -0.18981324627043633, 't2': 0.39695827826886326, 't3': 0.7864607684030653}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,465]\u001b[0m Trial 71 finished with value: 0.4281620024285576 and parameters: {'t0': -0.7901897190587412, 't1': -0.0657548072816165, 't2': 0.5299093178889474, 't3': 0.7892561411408909}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,488]\u001b[0m Trial 72 finished with value: 0.40051359854249924 and parameters: {'t0': -1.0037591414615896, 't1': -0.06543880225525235, 't2': 0.6489792156800659, 't3': 0.8816262882936646}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,513]\u001b[0m Trial 73 finished with value: 0.3484939450622294 and parameters: {'t0': -0.6580477769784039, 't1': 0.04429986896587913, 't2': 0.5638481017351078, 't3': 0.8224562627240608}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,539]\u001b[0m Trial 74 finished with value: 0.4281620024285576 and parameters: {'t0': -0.82206421065994, 't1': -0.23049298591335665, 't2': 0.49507660073556226, 't3': 0.7650587603957196}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,564]\u001b[0m Trial 75 finished with value: 0.40051359854249924 and parameters: {'t0': -1.216482457666967, 't1': -0.40531328886960494, 't2': 0.26240063921635526, 't3': 0.6908213790165713}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,596]\u001b[0m Trial 76 finished with value: 0.4281620024285576 and parameters: {'t0': -0.9708453370053929, 't1': -0.1491691824471485, 't2': 0.4405385309342372, 't3': 0.7401848830920016}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,647]\u001b[0m Trial 77 finished with value: 0.4281620024285576 and parameters: {'t0': -0.717519332475238, 't1': -0.10574516328646263, 't2': 0.33507565828362723, 't3': 0.6640233331617372}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,687]\u001b[0m Trial 78 finished with value: 0.4281620024285576 and parameters: {'t0': -0.5651797948263425, 't1': -0.03309863039015773, 't2': 0.6951877446762293, 't3': 0.8608682801977887}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,723]\u001b[0m Trial 79 finished with value: 0.40051359854249924 and parameters: {'t0': -1.1150197567181812, 't1': -0.3327734417240391, 't2': 0.4214757502947427, 't3': 0.8146429362650899}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,765]\u001b[0m Trial 80 finished with value: 0.3484939450622294 and parameters: {'t0': -0.17985850792180003, 't1': 0.07718977517941886, 't2': 0.5862687610758868, 't3': 0.9096585568184149}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,805]\u001b[0m Trial 81 finished with value: 0.4281620024285576 and parameters: {'t0': -0.6109244586650475, 't1': -0.017505254254994326, 't2': 0.7812789194746215, 't3': 0.9303288995493849}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,844]\u001b[0m Trial 82 finished with value: 0.4281620024285576 and parameters: {'t0': -0.8590686112883645, 't1': -0.2333963549675994, 't2': 0.5350091510338603, 't3': 0.846604366774703}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,895]\u001b[0m Trial 83 finished with value: 0.3159871244635194 and parameters: {'t0': -1.0386899907764333, 't1': 0.20289250474562487, 't2': 0.6290759798133471, 't3': 0.9318889426215086}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,944]\u001b[0m Trial 84 finished with value: 0.3484939450622294 and parameters: {'t0': -0.53096557580204, 't1': 0.009850505828399234, 't2': 0.6832982634108715, 't3': 0.8792149343498898}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,971]\u001b[0m Trial 85 finished with value: 0.4281620024285576 and parameters: {'t0': -0.6906506120894065, 't1': -0.09556560188804046, 't2': 0.4805502208150938, 't3': 0.7840199808419486}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:14,996]\u001b[0m Trial 86 finished with value: 0.3080316234251903 and parameters: {'t0': -0.7708103724414095, 't1': 0.1500159098559115, 't2': 0.5195981811443089, 't3': 1.0134921253582125}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:15,024]\u001b[0m Trial 87 finished with value: 0.3484939450622294 and parameters: {'t0': -0.3572678911701178, 't1': 0.006170461332501195, 't2': 0.8281217607247046, 't3': 0.9301024388289904}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:15,050]\u001b[0m Trial 88 finished with value: 0.4281620024285576 and parameters: {'t0': -0.91796115743625, 't1': -0.20252589549013336, 't2': 0.3103856526662802, 't3': 0.7242748984013694}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:15,075]\u001b[0m Trial 89 finished with value: 0.4281620024285576 and parameters: {'t0': -0.48173497542019483, 't1': -0.12342580340685312, 't2': 0.3683678591589963, 't3': 0.7610937687276275}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:15,102]\u001b[0m Trial 90 finished with value: 0.3484939450622294 and parameters: {'t0': -0.5939899495346277, 't1': 0.12368052412846511, 't2': 0.5971213180184697, 't3': 0.8321473504412047}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:15,125]\u001b[0m Trial 91 finished with value: 0.4281620024285576 and parameters: {'t0': -0.8738013540960791, 't1': -0.19766543457822514, 't2': 0.4089741543823729, 't3': 0.7949444774394178}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:15,154]\u001b[0m Trial 92 finished with value: 0.40051359854249924 and parameters: {'t0': -1.025775870001712, 't1': -0.31645316068835927, 't2': 0.37244472152937935, 't3': 0.7819686650886242}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:15,183]\u001b[0m Trial 93 finished with value: 0.4281620024285576 and parameters: {'t0': -0.8599041480396743, 't1': -0.08219295991347327, 't2': 0.4623854373241998, 't3': 0.815457290458723}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:15,211]\u001b[0m Trial 94 finished with value: 0.40051359854249924 and parameters: {'t0': -1.2105363177483188, 't1': -0.44920846754997973, 't2': 0.2964983308773743, 't3': 0.6984049694859445}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:15,244]\u001b[0m Trial 95 finished with value: 0.4281620024285576 and parameters: {'t0': -0.7284685936394222, 't1': -0.15084781731613603, 't2': 0.40962850359432523, 't3': 0.8820442814325614}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:15,273]\u001b[0m Trial 96 finished with value: 0.40051359854249924 and parameters: {'t0': -1.1423503421137875, 't1': -0.304872788877907, 't2': 0.7359382609380865, 't3': 0.9081073733083833}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:15,301]\u001b[0m Trial 97 finished with value: 0.4281620024285576 and parameters: {'t0': -0.9528175696790183, 't1': -0.25359498654087603, 't2': 0.6039868437958167, 't3': 0.8582496027339155}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:15,331]\u001b[0m Trial 98 finished with value: 0.3159871244635194 and parameters: {'t0': -1.052404806554137, 't1': 0.26787248680158904, 't2': 0.5334706394132667, 't3': 0.9686995064640322}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n",
            "<ipython-input-33-d7407117602e>:37: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t = trial.suggest_uniform(f't{i}', low, high)\n",
            "\u001b[32m[I 2023-02-13 18:47:15,359]\u001b[0m Trial 99 finished with value: 0.4281620024285576 and parameters: {'t0': -0.6147084227588143, 't1': -0.03783501724331258, 't2': 0.4772185395325597, 't3': 0.753219572306439}. Best is trial 15 with value: 0.4281620024285576.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized thresholds: [-0.7459242942134579, -0.01656552952241752, 0.29354630011163285, 0.6261019444219256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 閾値を最適化する前の QWK\n",
        "y_pred = gbm.predict(x_dev)\n",
        "y_pred = np.clip(y_pred, -2, 2)\n",
        "y_pred = [int(Decimal(str(num)).quantize(Decimal('0'), rounding=ROUND_HALF_UP)) for num in y_pred]\n",
        "qwk = cohen_kappa_score(y_dev,y_pred, weights='quadratic')\n",
        "\n",
        "# 閾値を最適化した場合の QWK\n",
        "optimized_oof_y_pred = objective.adjust(y_pred_dev, best_thresholds)\n",
        "optimized_oof_qwk = cal_qwk(y_dev, optimized_oof_y_pred)\n",
        "\n",
        "# 書き込み\n",
        "f = open(\"LightGBM_Oputuna_dev_small_C_seed\"+str()+\".txt\", \"w\")\n",
        "for labeldata in optimized_oof_y_pred:\n",
        "    f.write(str(labeldata))\n",
        "    f.write(\"\\n\")\n",
        "f.close()\n",
        "\n",
        "print('最適化前のQWK=', qwk)\n",
        "print('最適化後のQWK=',optimized_oof_qwk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKlZo1VMmnZu",
        "outputId": "c16038ef-be89-418c-af26-12cb35e50ea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最適化前のQWK= 0.34680632275724144\n",
            "最適化後のQWK= 0.4281620024285576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 提出データに対して推論\n",
        "y_pred = gbm.predict(x_test)\n",
        "y_pred = np.clip(y_pred, -2, 2)\n",
        "\n",
        "y_preds = objective.adjust(y_pred, best_thresholds)\n",
        "\n",
        "# 書き込み\n",
        "f = open(\"LightGBM_Oputuna_eval_small_C_seed\"+str()+\".txt\", \"w\")\n",
        "for labeldata in y_preds:\n",
        "    f.write(str(labeldata))\n",
        "    f.write(\"\\n\")\n",
        "f.close()"
      ],
      "metadata": {
        "id": "DPtGih-4nKNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVR"
      ],
      "metadata": {
        "id": "9x7KtilVjXeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sudachiによる正規化を行う関数を定義\n",
        "from sudachipy import Dictionary\n",
        "from sudachipy import SplitMode\n",
        "tokenizer = Dictionary(dict=\"full\").create() #dict=\"small\"\n",
        "\n",
        "def sudachi(text):\n",
        "    after = list()\n",
        "    for token in tokenizer.tokenize(text, SplitMode.C):\n",
        "        # word = token.surface() # 正規化なし\n",
        "        word = token.normalized_form() # 正規化あり\n",
        "        pos = \" \".join(token.part_of_speech())\n",
        "        \n",
        "        if word.isnumeric():\n",
        "            word = '0'\n",
        "\n",
        "        after.append(word)\n",
        "\n",
        "    return after"
      ],
      "metadata": {
        "id": "jjMzdS5xjZSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import neologdn\n",
        "\n",
        "train_tokenize = [] \n",
        "dev_tokenize = []\n",
        "test_tokenize = []\n",
        "\n",
        "def tokenize(infile, outfile):\n",
        "    for i in range(len(infile)):\n",
        "        #outfile.append(sudachi(infile[i]))   #正規化なし\n",
        "        outfile.append(sudachi(neologdn.normalize(infile[i])))    #正規化あり\n",
        "\n",
        "tokenize(train_text, train_tokenize)\n",
        "tokenize(dev_text, dev_tokenize)\n",
        "tokenize(test_text, test_tokenize)\n",
        "\n",
        "def writefile(infile, outfile):\n",
        "    with open(outfile, 'w') as f:\n",
        "        for i, wordlist in enumerate(infile):\n",
        "            f.write(\" \".join([str(word) for word in wordlist]) + '\\n')\n",
        "            \n",
        "writefile(train_tokenize, \"train.txt\")\n",
        "writefile(dev_tokenize, \"dev.txt\")\n",
        "writefile(test_tokenize, \"test.txt\")"
      ],
      "metadata": {
        "id": "rKPcFzRynV_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import random\n",
        "\n",
        "with open(\"train.txt\", 'r') as f:\n",
        "    traintext = f.read().split(\"\\n\")\n",
        "    traintext = traintext[:-1]\n",
        "with open(\"test.txt\", 'r') as f:\n",
        "    testtext = f.read().split(\"\\n\")\n",
        "    testtext = testtext[:-1]\n",
        "with open(\"dev.txt\", 'r') as f:\n",
        "    devtext = f.read().split(\"\\n\")\n",
        "    devtext = devtext[:-1]\n",
        "    \n",
        "vectorizer = TfidfVectorizer(smooth_idf=True, analyzer='char', norm='l1') \n",
        "\n",
        "x_train = vectorizer.fit_transform(traintext)\n",
        "x_test = vectorizer.transform(testtext)\n",
        "x_dev = vectorizer.transform(devtext)"
      ],
      "metadata": {
        "id": "jO9dw4xEnjA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"x_trainの形状：\", x_train.shape)\n",
        "print(\"x_devの形状：\", x_dev.shape)\n",
        "print(\"x_testの形状：\", x_test.shape)\n",
        "\n",
        "y_train =  np.array(list(map (int, train_label)))\n",
        "y_dev =  np.array(list(map (int, dev_label)))\n",
        "print(\"y_trainの形状：\", y_train.shape)    \n",
        "print(\"y_devの形状：\", y_dev.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5PX1wvGnnel",
        "outputId": "166777a4-9915-4aab-c66e-bb7add82b656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_trainの形状： (30000, 3248)\n",
            "x_devの形状： (2500, 3248)\n",
            "x_testの形状： (2500, 3248)\n",
            "y_trainの形状： (30000,)\n",
            "y_devの形状： (2500,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "from decimal import Decimal, ROUND_HALF_UP, ROUND_HALF_EVEN\n",
        "best_qwk = 0\n",
        "best_c = 0\n",
        "for c in [11, 12, 13, 14]: # 0.1, 1, 8, 10, 11, 12, 13, 14, 15, 20, 100]:\n",
        "    model = SVR(C=c, kernel='rbf')\n",
        "    model.fit(x_train, y_train)\n",
        "    y_pred = model.predict(x_dev)\n",
        "    y_pred = [int(Decimal(str(num)).quantize(Decimal('0'), rounding=ROUND_HALF_UP)) for num in y_pred] #y_pred =  np.clip(y_pred, -2, 2)\n",
        "\n",
        "    qwk = cohen_kappa_score(y_dev, y_pred, weights='quadratic')\n",
        "    if qwk > best_qwk:\n",
        "        best_qwk = qwk\n",
        "        best_c = c\n",
        "    print(\"QWK = %f  C = %s\" % (qwk, str(c)))\n",
        "print(\"最適なハイパーパラメタは C = %s\" % str(best_c))"
      ],
      "metadata": {
        "id": "Tmypwn8unpFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "QWK = 0.244240  C = 0.1\n",
        "QWK = 0.342857  C = 1\n",
        "QWK = 0.358512  C = 8\n",
        "QWK = 0.360366  C = 10\n",
        "QWK = 0.361996  C = 11\n",
        "QWK = 0.358468  C = 12\n",
        "QWK = 0.355736  C = 15\n",
        "QWK = 0.355241  C = 20\n",
        "QWK = 0.354434  C = 100\n",
        "最適なハイパーパラメタは C = 11\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "QKWQMaesnrVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_qwk(y_true, y_pred):\n",
        "    \"\"\"QWK (Quadratic Weighted Kappa) を計算する関数\"\"\"\n",
        "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
        "    \n",
        "class OptunaRounder:\n",
        "    \"\"\"Optuna を使って QWK の最適な閾値を探索するクラス\"\"\"\n",
        "\n",
        "    def __init__(self, y_true_, y_pred):\n",
        "        # 真のラベル\n",
        "        self.y_true_ = y_true_\n",
        "        # print(y_true)\n",
        "        \n",
        "        # 予測したラベル\n",
        "        self.y_pred = y_pred\n",
        "        # print(y_pred)\n",
        "        # ラベルの種類\n",
        "        self.labels = np.unique(y_true_)\n",
        "    \n",
        "    def adjust(self, y_pred_, thresholds):\n",
        "        \"\"\"閾値にもとづいて予測を補正するメソッド\"\"\"\n",
        "        opt_y_pred = pd.cut(y_pred_, [-np.inf] + thresholds + [np.inf], labels=self.labels)\n",
        "        # print(\"関数:\", opt_y_pred)\n",
        "        return opt_y_pred\n",
        "        \n",
        "\n",
        "    def __call__(self, trial):\n",
        "        \"\"\"最大化したい目的関数\"\"\"\n",
        "        # 閾値を Define by run で追加していく\n",
        "        thresholds = []\n",
        "        # ラベルの数 - 1 が必要な閾値の数になる\n",
        "        for i in range(len(self.labels) - 1):\n",
        "            # 閾値の下限 (既存の最大 or ラベルの最小値)\n",
        "            low = max(thresholds) if i > 0 else min(self.labels)\n",
        "            # 閾値の上限 (ラベルの最大値)\n",
        "            high = max(self.labels)\n",
        "            # 閾値の候補を追加する\n",
        "            t = trial.suggest_uniform(f't{i}', low, high)\n",
        "            thresholds.append(t)\n",
        "\n",
        "        # 閾値の候補を元に QWK を計算する\n",
        "        opt_y_pred_ = self.adjust(self.y_pred, thresholds)\n",
        "        # print(\"QWK:\",opt_y_pred_)\n",
        "        return cal_qwk(self.y_true_, opt_y_pred_)\n"
      ],
      "metadata": {
        "id": "2xJGhiKdn607"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "fHliasT316JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "model = SVR(C=best_c, kernel='rbf')\n",
        "model.fit(x_train, y_train)\n",
        "y_pred = model.predict(x_dev)\n",
        "\n",
        "y_pred_dev = [int(Decimal(str(num)).quantize(Decimal('0'), rounding=ROUND_HALF_UP)) for num in y_pred]\n",
        "\n",
        "objective = OptunaRounder(y_dev, y_pred_dev)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=200, timeout=100)\n",
        "\n",
        "# 見つけた閾値\n",
        "best_thresholds = sorted(study.best_params.values())\n",
        "print(f'Optimized thresholds: {best_thresholds}')\n"
      ],
      "metadata": {
        "id": "0hZAw6f2n8tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 閾値を最適化した場合の QWK\n",
        "optimized_oof_y_pred = objective.adjust(y_pred_dev, best_thresholds)\n",
        "\n",
        "optimized_oof_qwk = cal_qwk(y_dev, optimized_oof_y_pred)\n",
        "\n",
        "print('閾値最適化前のQWK', cal_qwk(y_dev, y_pred))\n",
        "print('閾値最適化後のQWK', optimized_oof_qwk)"
      ],
      "metadata": {
        "id": "nvNzHsFln-J4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 提出データに対して推論\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# 最適化した閾値をアンサンブル結果に反映\n",
        "y_preds = objective.adjust(y_pred, best_thresholds)\n",
        "\n",
        "# 書き込み\n",
        "f = open(\"SVR_eval_oputuna_C\"+str(best_c)+\".txt\", \"w\")\n",
        "for labeldata in y_preds:\n",
        "    f.write(str(int(labeldata)))\n",
        "    f.write(\"\\n\")\n",
        "f.close()"
      ],
      "metadata": {
        "id": "PKr5pknLoerR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#アンサンブル\n"
      ],
      "metadata": {
        "id": "ggyL5XPooowp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enspath = \"/content/drive/MyDrive/研究室コンペ/2_アンサンブル/\"\n",
        "enspath2 = \"/content/drive/MyDrive/研究室コンペ/2_アンサンブル_QWK/\"\n",
        "\n",
        "# 提出用データに対しての出力のみを保存\n",
        "# 閾値最適化のためにdevの出力も保存"
      ],
      "metadata": {
        "id": "trF63B9FoqYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(openfile):\n",
        "    with open(enspath + openfile, 'r') as f:\n",
        "        text = f.read().split(\"\\n\")\n",
        "        text = text[:-1] \n",
        "    return text\n",
        "\n",
        "def load_data2(openfile):\n",
        "    with open(enspath2 + openfile, 'r') as f:\n",
        "        text = f.read().split(\"\\n\")\n",
        "        text = text[:-1]\n",
        "    return text\n",
        "\n",
        "def get_label(result):\n",
        "    return [int(x) for x in result]"
      ],
      "metadata": {
        "id": "zpKbt46Yo1F5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f0 = 'LightGBM_Oputuna1.txt'\n",
        "#LSTM\n",
        "f1 = '提出0.329.txt'\n",
        "f2 = '提出0.419.txt'\n",
        "f3 = '提出0.450.txt' #\n",
        "f4 = '提出0.381.txt'\n",
        "f5 = '提出0.453.txt' #\n",
        "f6 = '提出0.455.txt' #\n",
        "f7 = '提出0.388.txt'\n",
        "f8 = '提出0.438.txt'  \n",
        "f9 = '提出0.401C.txt'\n",
        "f10 = '提出0.405.txt'  \n",
        "f11 = '提出0.451.txt'  #\n",
        "f12 = '提出0.411.txt'\n",
        "f13 = '提出0.414.txt'  \n",
        "f14 = '提出0.439.txt'  \n",
        "f15 = '提出linear2rnn1.txt'\n",
        "\n",
        "# CatBoost+Oputuna\n",
        "eval_0 = 'CatBoost_Oputuna_eval.txt'\n",
        "# LSTM\n",
        "eval_1 = 'eval_seed0_0.421.txt'\n",
        "eval_2 = 'eval_seed123_0.441.txt'\n",
        "eval_3 = 'eval_seed1234_0.448.txt'\n",
        "eval_4 = 'eval_seed2023_0.432.txt'\n",
        "eval_5 = 'eval_seed32_0.410.txt'\n",
        "eval_6 = 'eval_seed32_0.442_rnn2.txt'\n",
        "eval_7 = 'eval_seed42_0.456.txt' #\n",
        "eval_8 = 'eval_seed64rnn2_0.426.txt'\n",
        "# LightGBM+Oputuna\n",
        "eval_9 = 'LightGBM_Oputuna_eval_small_C_seed1234.txt' \n",
        "eval_10 = 'LightGBM_Oputuna_eval_small_C_seed32.txt'\n",
        "eval_11 = 'LightGBM_Oputuna_eval_small_C_seed42.txt'#\n",
        "eval_12 = 'LightGBM_Oputuna_eval.txt'\n",
        "# linearSVR\n",
        "eval_13 = 'linearSVR_eval_oputuna_C150_seed605.txt'\n",
        "eval_14 = 'linearSVR_eval_oputuna_C160_seed1234.txt'\n",
        "eval_15 = 'linearSVR_eval_oputuna_C160_seed22.txt'\n",
        "eval_16 = 'linearSVR_eval_oputuna_C190_seed123.txt'\n",
        "eval_17 = 'linearSVR_eval_oputuna_C190_seed42.txt'\n",
        "# SVR\n",
        "eval_18 = 'SVR_eval_oputuna_C11.txt' #"
      ],
      "metadata": {
        "id": "QgpYcY7kpbjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ファイルの読み込み\n",
        "res0 = load_data(f0)\n",
        "res1 = load_data(f1)\n",
        "res2 = load_data(f2)\n",
        "res3 = load_data(f3)\n",
        "res4 = load_data(f4)\n",
        "res5 = load_data(f5)\n",
        "res6 = load_data(f6)\n",
        "res7 = load_data(f7)\n",
        "res8 = load_data(f8)\n",
        "res9 = load_data(f9)\n",
        "res10 = load_data(f10)\n",
        "res11 = load_data(f11)\n",
        "res12 = load_data(f12)\n",
        "res13 = load_data(f13)\n",
        "res14 = load_data(f14)\n",
        "res15 = load_data(f15)\n",
        "\n",
        "res0_2 = load_data2(eval_0)\n",
        "res1_2 = load_data2(eval_1)\n",
        "res2_2 = load_data2(eval_2)\n",
        "res3_2 = load_data2(eval_3)\n",
        "res4_2 = load_data2(eval_4)\n",
        "res5_2 = load_data2(eval_5)\n",
        "res6_2 = load_data2(eval_6)\n",
        "res7_2 = load_data2(eval_7)\n",
        "res8_2 = load_data2(eval_8)\n",
        "res9_2 = load_data2(eval_9)\n",
        "res10_2 = load_data2(eval_10)\n",
        "res11_2 = load_data2(eval_11)\n",
        "res12_2 = load_data2(eval_12)\n",
        "res13_2 = load_data2(eval_13)\n",
        "res14_2 = load_data2(eval_14)\n",
        "res15_2 = load_data2(eval_15)\n",
        "res16_2 = load_data2(eval_16)\n",
        "res17_2 = load_data2(eval_17)\n",
        "res18_2 = load_data2(eval_18)"
      ],
      "metadata": {
        "id": "2EKkLrPWp2bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ラベルの取り出し\n",
        "res0 = get_label(res0)\n",
        "res1 = get_label(res1)\n",
        "res2 = get_label(res2)\n",
        "res3 = get_label(res3) #\n",
        "res4 = get_label(res4)\n",
        "res5 = get_label(res5) #\n",
        "res6 = get_label(res6) #\n",
        "res7 = get_label(res7)\n",
        "res8 = get_label(res8)\n",
        "res9 = get_label(res9)\n",
        "res10 = get_label(res10)\n",
        "res11 = get_label(res11) #\n",
        "res12 = get_label(res12)\n",
        "res13 = get_label(res13)\n",
        "res14 = get_label(res14)\n",
        "res15 = get_label(res15)\n",
        "\n",
        "res0_2 = get_label(res0_2)\n",
        "res1_2 = get_label(res1_2)\n",
        "res2_2 = get_label(res2_2)\n",
        "res3_2 = get_label(res3_2)\n",
        "res4_2 = get_label(res4_2)\n",
        "res5_2 = get_label(res5_2)\n",
        "res6_2 = get_label(res6_2)\n",
        "res7_2 = get_label(res7_2) #\n",
        "res8_2 = get_label(res8_2)\n",
        "res9_2 = get_label(res9_2)\n",
        "res10_2 = get_label(res10_2)\n",
        "res11_2 = get_label(res11_2) #\n",
        "res12_2 = get_label(res12_2)\n",
        "res13_2 = get_label(res13_2)\n",
        "res14_2 = get_label(res14_2)\n",
        "res15_2 = get_label(res15_2)\n",
        "res16_2 = get_label(res16_2)\n",
        "res17_2 = get_label(res17_2)\n",
        "res18_2 = get_label(res18_2) #"
      ],
      "metadata": {
        "id": "00Bu0up0p6XN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from decimal import Decimal, ROUND_HALF_UP, ROUND_HALF_EVEN\n",
        "    \n",
        "ens = []\n",
        "for i in range(len(res0)):\n",
        "    # label = float(res3[i]+res5[i]+res6[i]+res11[i]+res11_2[i]+res17_2[i]+res18_2[i])/7 #0.524\n",
        "    # label = float(res6[i]+res7_2[i]+res11_2[i]+res18_2[i])/4 # 0.512\n",
        "    # label = float(res5[i]+res6[i]+res11[i]+res7_2[i]+res11_2[i]+res18_2[i])/5 #0.522\n",
        "    label = float(res3[i]+res5[i]+res6[i]+res11[i]+res7_2[i]+res11_2[i]+res18_2[i])/6 #0.529\n",
        "    label = int(Decimal(str(label)).quantize(Decimal('0'), rounding=ROUND_HALF_UP))\n",
        "    print(label)\n",
        "    ens.append(label)\n",
        "#\n",
        "# 書き込み\n",
        "f = open(\"ensemble_eval.txt\", \"w\")\n",
        "for labeldata in ens:\n",
        "    f.write(str(int(labeldata)))\n",
        "    f.write(\"\\n\")\n",
        "f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXwcgl82qDV8",
        "outputId": "c9bc6a22-4150-4ddb-8aa0-dc45a9f855db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "-1\n",
            "-1\n",
            "1\n",
            "2\n",
            "0\n",
            "2\n",
            "1\n",
            "2\n",
            "0\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "0\n",
            "0\n",
            "-1\n",
            "1\n",
            "0\n",
            "0\n",
            "-2\n",
            "1\n",
            "2\n",
            "2\n",
            "0\n",
            "-1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "-1\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "-2\n",
            "1\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "2\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "-1\n",
            "1\n",
            "-1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "-2\n",
            "2\n",
            "-1\n",
            "1\n",
            "1\n",
            "-1\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "-1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "-1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "-1\n",
            "1\n",
            "-1\n",
            "-1\n",
            "1\n",
            "-1\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "2\n",
            "-2\n",
            "1\n",
            "-2\n",
            "1\n",
            "1\n",
            "-1\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "2\n",
            "-1\n",
            "1\n",
            "-1\n",
            "0\n",
            "2\n",
            "2\n",
            "2\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "-1\n",
            "0\n",
            "1\n",
            "-2\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "0\n",
            "1\n",
            "0\n",
            "-1\n",
            "0\n",
            "0\n",
            "-1\n",
            "-1\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "-1\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "0\n",
            "0\n",
            "-2\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "-1\n",
            "1\n",
            "1\n",
            "2\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "-1\n",
            "1\n",
            "2\n",
            "1\n",
            "-1\n",
            "2\n",
            "-2\n",
            "1\n",
            "1\n",
            "1\n",
            "-1\n",
            "0\n",
            "-1\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "-1\n",
            "-2\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "-1\n",
            "-1\n",
            "2\n",
            "0\n",
            "-1\n",
            "1\n",
            "-1\n",
            "1\n",
            "-2\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "-1\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "-1\n",
            "1\n",
            "1\n",
            "-1\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "-1\n",
            "-1\n",
            "2\n",
            "-1\n",
            "0\n",
            "-2\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "2\n",
            "0\n",
            "-1\n",
            "2\n",
            "1\n",
            "2\n",
            "0\n",
            "2\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "-1\n",
            "-1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "-1\n",
            "-2\n",
            "-1\n",
            "0\n",
            "-1\n",
            "1\n",
            "1\n",
            "-1\n",
            "2\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "-1\n",
            "-1\n",
            "0\n",
            "2\n",
            "1\n",
            "-1\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "-1\n",
            "-1\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "-1\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "0\n",
            "1\n",
            "0\n",
            "-1\n",
            "0\n",
            "-1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "-1\n",
            "0\n",
            "1\n",
            "-1\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "-1\n",
            "-1\n",
            "2\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "0\n",
            "2\n",
            "0\n",
            "-1\n",
            "2\n",
            "2\n",
            "-1\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "1\n",
            "-2\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "-1\n",
            "1\n",
            "2\n",
            "2\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "-1\n",
            "2\n",
            "1\n",
            "0\n",
            "0\n",
            "-2\n",
            "-1\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "-1\n",
            "0\n",
            "-1\n",
            "0\n",
            "-2\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "-2\n",
            "1\n",
            "2\n",
            "-1\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "-1\n",
            "1\n",
            "-2\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "-1\n",
            "1\n",
            "0\n",
            "-1\n",
            "0\n",
            "-1\n",
            "2\n",
            "-1\n",
            "0\n",
            "2\n",
            "0\n",
            "0\n",
            "-2\n",
            "2\n",
            "0\n",
            "0\n",
            "2\n",
            "-1\n",
            "1\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "-1\n",
            "0\n",
            "-1\n",
            "-2\n",
            "0\n",
            "1\n",
            "0\n",
            "-2\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "-1\n",
            "1\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "-2\n",
            "0\n",
            "0\n",
            "-1\n",
            "2\n",
            "2\n",
            "1\n",
            "-1\n",
            "-1\n",
            "-2\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "2\n",
            "2\n",
            "0\n",
            "-1\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "1\n",
            "-1\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "0\n",
            "-1\n",
            "1\n",
            "0\n",
            "-1\n",
            "-1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "-1\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "-1\n",
            "2\n",
            "1\n",
            "1\n",
            "-2\n",
            "0\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "0\n",
            "-1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "-2\n",
            "-1\n",
            "0\n",
            "-1\n",
            "-1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "0\n",
            "-1\n",
            "1\n",
            "-1\n",
            "-1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "-1\n",
            "0\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "0\n",
            "2\n",
            "-2\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "-1\n",
            "1\n",
            "2\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "1\n",
            "1\n",
            "0\n",
            "-2\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "-1\n",
            "1\n",
            "2\n",
            "-1\n",
            "-1\n",
            "2\n",
            "1\n",
            "-1\n",
            "1\n",
            "-2\n",
            "-1\n",
            "0\n",
            "-1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "-2\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "-1\n",
            "2\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "-1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "-1\n",
            "2\n",
            "0\n",
            "-1\n",
            "0\n",
            "0\n",
            "2\n",
            "-2\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "-2\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "-1\n",
            "1\n",
            "-1\n",
            "0\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "2\n",
            "-1\n",
            "0\n",
            "0\n",
            "-1\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "-1\n",
            "0\n",
            "-2\n",
            "-1\n",
            "1\n",
            "-1\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "-1\n",
            "1\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "-2\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "-1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "-1\n",
            "-1\n",
            "2\n",
            "1\n",
            "0\n",
            "2\n",
            "0\n",
            "-1\n",
            "-2\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "-1\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "-2\n",
            "-1\n",
            "1\n",
            "-1\n",
            "-1\n",
            "0\n",
            "2\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "2\n",
            "0\n",
            "0\n",
            "-1\n",
            "-1\n",
            "1\n",
            "0\n",
            "-1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "0\n",
            "2\n",
            "0\n",
            "-1\n",
            "0\n",
            "2\n",
            "0\n",
            "0\n",
            "2\n",
            "1\n",
            "2\n",
            "-1\n",
            "1\n",
            "1\n",
            "-2\n",
            "2\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "1\n",
            "1\n",
            "-1\n",
            "1\n",
            "2\n",
            "1\n",
            "-1\n",
            "0\n",
            "-1\n",
            "-2\n",
            "1\n",
            "0\n",
            "0\n",
            "-2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "-1\n",
            "0\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "1\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "-2\n",
            "1\n",
            "-1\n",
            "0\n",
            "0\n",
            "-1\n",
            "-1\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "2\n",
            "0\n",
            "-1\n",
            "-1\n",
            "0\n",
            "1\n",
            "-1\n",
            "-1\n",
            "1\n",
            "-1\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "1\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "-1\n",
            "0\n",
            "1\n",
            "-2\n",
            "1\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "0\n",
            "2\n",
            "-1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "-1\n",
            "0\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "1\n",
            "-1\n",
            "-1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "-1\n",
            "-1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "-1\n",
            "-2\n",
            "-1\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "-1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "2\n",
            "1\n",
            "0\n",
            "0\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "0\n",
            "0\n",
            "2\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "-1\n",
            "0\n",
            "0\n",
            "2\n",
            "2\n",
            "-1\n",
            "0\n",
            "-1\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "2\n",
            "1\n",
            "0\n",
            "0\n",
            "-2\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "-1\n",
            "0\n",
            "-1\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "-1\n",
            "1\n",
            "1\n",
            "-1\n",
            "0\n",
            "0\n",
            "1\n",
            "-2\n",
            "1\n",
            "-1\n",
            "1\n",
            "1\n",
            "-1\n",
            "1\n",
            "-2\n",
            "-1\n",
            "1\n",
            "0\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "-1\n",
            "2\n",
            "1\n",
            "-1\n",
            "-1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "2\n",
            "-2\n",
            "-1\n",
            "-1\n",
            "0\n",
            "-1\n",
            "0\n",
            "0\n",
            "2\n",
            "1\n",
            "2\n",
            "-1\n",
            "0\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "-1\n",
            "2\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "-2\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "-1\n",
            "-1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "-2\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "-2\n",
            "1\n",
            "1\n",
            "1\n",
            "-2\n",
            "0\n",
            "-1\n",
            "1\n",
            "-1\n",
            "2\n",
            "-1\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "-1\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "-1\n",
            "1\n",
            "1\n",
            "-1\n",
            "2\n",
            "1\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "2\n",
            "-1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "-1\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "-2\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "-1\n",
            "2\n",
            "0\n",
            "2\n",
            "0\n",
            "0\n",
            "-1\n",
            "1\n",
            "-1\n",
            "1\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "2\n",
            "-1\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "-1\n",
            "-1\n",
            "2\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "-1\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "-2\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "-1\n",
            "-2\n",
            "-1\n",
            "-1\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "-1\n",
            "0\n",
            "-2\n",
            "1\n",
            "-1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "-1\n",
            "-1\n",
            "2\n",
            "2\n",
            "-2\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "-2\n",
            "-1\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "-1\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "2\n",
            "0\n",
            "2\n",
            "0\n",
            "2\n",
            "-1\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "-2\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "-1\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "-1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "-1\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "-1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "2\n",
            "0\n",
            "0\n",
            "-1\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "-2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "-2\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "2\n",
            "-1\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "-1\n",
            "-1\n",
            "0\n",
            "-1\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "2\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "2\n",
            "-2\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "2\n",
            "0\n",
            "0\n",
            "-1\n",
            "-1\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "-1\n",
            "1\n",
            "-1\n",
            "-1\n",
            "-2\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "2\n",
            "2\n",
            "-1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "-2\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "-1\n",
            "1\n",
            "2\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "2\n",
            "-1\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "-1\n",
            "1\n",
            "-1\n",
            "0\n",
            "0\n",
            "-1\n",
            "-1\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "-2\n",
            "1\n",
            "-1\n",
            "-1\n",
            "2\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "1\n",
            "1\n",
            "1\n",
            "-1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "2\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "-2\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "0\n",
            "-1\n",
            "2\n",
            "0\n",
            "-1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "-1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "-1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "-2\n",
            "-1\n",
            "1\n",
            "0\n",
            "0\n",
            "-1\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "-2\n",
            "1\n",
            "1\n",
            "2\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "-1\n",
            "1\n",
            "0\n",
            "-1\n",
            "0\n",
            "-1\n",
            "1\n",
            "2\n",
            "0\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "-2\n",
            "-1\n",
            "1\n",
            "-2\n",
            "0\n",
            "0\n",
            "-1\n",
            "2\n",
            "0\n",
            "-1\n",
            "-1\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "-1\n",
            "-2\n",
            "1\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "-1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "-1\n",
            "2\n",
            "-1\n",
            "0\n",
            "1\n",
            "-2\n",
            "1\n",
            "0\n",
            "0\n",
            "-1\n",
            "0\n",
            "2\n",
            "-1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "-1\n",
            "-1\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "-2\n",
            "-1\n",
            "-1\n",
            "1\n",
            "2\n",
            "-1\n",
            "0\n",
            "1\n",
            "-1\n",
            "2\n",
            "2\n",
            "0\n",
            "-1\n",
            "-1\n",
            "1\n",
            "1\n",
            "-1\n",
            "-1\n",
            "2\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "-1\n",
            "1\n",
            "-1\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "-1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "2\n",
            "0\n",
            "-2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "-1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "2\n",
            "-2\n",
            "-1\n",
            "0\n",
            "-1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "2\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "1\n",
            "0\n",
            "-2\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "2\n",
            "-1\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "-1\n",
            "0\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "-1\n",
            "-1\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "0\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "-1\n",
            "-1\n",
            "2\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "2\n",
            "1\n",
            "0\n",
            "-1\n",
            "2\n",
            "2\n",
            "-1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "-2\n",
            "1\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "-1\n",
            "0\n",
            "-1\n",
            "1\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "-2\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "2\n",
            "-1\n",
            "0\n",
            "-1\n",
            "-1\n",
            "1\n",
            "0\n",
            "-1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "-2\n",
            "1\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "-1\n",
            "-1\n",
            "0\n",
            "-1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "2\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "1\n",
            "-1\n",
            "2\n",
            "-1\n",
            "-1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "-1\n",
            "-2\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "-1\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "1\n",
            "1\n",
            "-1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "-2\n",
            "-1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "-1\n",
            "0\n",
            "-1\n",
            "-2\n",
            "2\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "0\n",
            "-1\n",
            "1\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "-2\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "-1\n",
            "-2\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "-1\n",
            "0\n",
            "1\n",
            "1\n",
            "-1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "-1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "-1\n",
            "2\n",
            "0\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "-1\n",
            "2\n",
            "2\n",
            "2\n",
            "-1\n",
            "0\n",
            "-1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "-1\n",
            "2\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "2\n",
            "-1\n",
            "-1\n",
            "1\n",
            "0\n",
            "1\n",
            "-1\n",
            "0\n",
            "-1\n",
            "0\n",
            "-1\n",
            "-1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "-2\n",
            "1\n",
            "0\n",
            "-1\n",
            "0\n",
            "1\n",
            "-1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "-1\n",
            "1\n",
            "0\n",
            "-1\n",
            "2\n",
            "-2\n",
            "1\n",
            "1\n",
            "-1\n",
            "1\n",
            "1\n",
            "0\n",
            "-1\n",
            "0\n",
            "-1\n",
            "0\n",
            "-1\n",
            "0\n",
            "1\n",
            "0\n",
            "-1\n",
            "-2\n",
            "-2\n",
            "0\n",
            "2\n",
            "2\n",
            "0\n",
            "-2\n",
            "0\n",
            "0\n",
            "-1\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "0\n",
            "-1\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "-1\n",
            "0\n",
            "1\n",
            "0\n",
            "-1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "2\n",
            "-1\n",
            "0\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "-1\n",
            "0\n",
            "1\n",
            "2\n",
            "-1\n",
            "0\n",
            "2\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "res3+res5+res6+res11+res11_2+res17_2+res18_2 #0.524\n",
        "res6+res7_2+res11_2+res18_2 # 0.512\n",
        "res5+res6+res11+res7_2+res11_2+res18_2 #0.522\n",
        "res3+res5+res6+res11+res7_2+res11_2+res18_2 #0.529\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "XILJYd1dvKc5"
      }
    }
  ]
}