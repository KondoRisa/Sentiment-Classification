{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   train・dev・testのコーパスを目視で整える\n",
        "2.   neologdnで正規化し、sudachiで単語分割する\n",
        "3.   単語分割したものをTfidfでベクトル化する\n",
        "4.   LightGBMとCatBoostとSVRで学習し、学習結果をファイルに出力\n",
        "5.  出力したファイルを、重みづけしながらアンサンブルを行う\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q9IdEgDPIVAx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "re03DzWyXjs5"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "numpy.set_printoptions(threshold=numpy.inf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-kzHvMB-z1u",
        "outputId": "34e930bf-ca52-42ca-8d48-4156106db282"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXPMQzv6hHBC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import random\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OkNqY6_RnSU"
      },
      "outputs": [],
      "source": [
        "def load_data(openfile):\n",
        "    with open(openfile, 'r') as f:\n",
        "        text = f.read().split(\"\\n\")\n",
        "        text = text[:-1] # train_textの最後に''があるため削除\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygcF-ApiSM8T"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/研究室コンペ/self_data2/\"\n",
        "\n",
        "# データの読み込み\n",
        "train_text = load_data( path + \"text.train.txt\") # 訓練用 30000\n",
        "dev_text = load_data( path + \"text.dev.txt\") # 検証用 2500\n",
        "test_text = load_data( path + \"text.test.txt\") # 提出用 2500\n",
        "\n",
        "# ラベルの読み込み\n",
        "train_label = load_data( path + \"label.train.txt\")\n",
        "dev_label = load_data( path + \"label.dev.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1OkceZB8-xm"
      },
      "outputs": [],
      "source": [
        "# 顔文字除去X\n",
        "train_text_demoji = train_text\n",
        "test_text_demoji = test_text\n",
        "dev_text_demoji = dev_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDygO3RD-_FT",
        "outputId": "cb2346e0-94b7-4679-f3a7-086bc66cc407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sudachipy\n",
            "  Downloading SudachiPy-0.6.6-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sudachipy\n",
            "Successfully installed sudachipy-0.6.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sudachidict_full\n",
            "  Downloading SudachiDict-full-20221021.tar.gz (9.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: SudachiPy<0.7,>=0.5 in /usr/local/lib/python3.8/dist-packages (from sudachidict_full) (0.6.6)\n",
            "Building wheels for collected packages: sudachidict_full\n",
            "  Building wheel for sudachidict_full (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sudachidict_full: filename=SudachiDict_full-20221021-py3-none-any.whl size=126781795 sha256=006893775940f1a69f4b19540b8e980276d43342d37be9ed5c6609ed32a056ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/4d/d6/bb157c10462a4ee8def3e005b58f6660853bc6202d12d8f128\n",
            "Successfully built sudachidict_full\n",
            "Installing collected packages: sudachidict_full\n",
            "Successfully installed sudachidict_full-20221021\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sudachidict_small\n",
            "  Downloading SudachiDict-small-20221021.tar.gz (9.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: SudachiPy<0.7,>=0.5 in /usr/local/lib/python3.8/dist-packages (from sudachidict_small) (0.6.6)\n",
            "Building wheels for collected packages: sudachidict_small\n",
            "  Building wheel for sudachidict_small (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sudachidict_small: filename=SudachiDict_small-20221021-py3-none-any.whl size=41770971 sha256=7753efb1fde2f81abbb93f2d1b28984d8de60def41fdd723fa1446b5a486a551\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/b4/e4/c8b0025c7b0dd91b66eed3d135d495bd1f19401aa574ff6a45\n",
            "Successfully built sudachidict_small\n",
            "Installing collected packages: sudachidict_small\n",
            "Successfully installed sudachidict_small-20221021\n"
          ]
        }
      ],
      "source": [
        "#sudachiをインストール\n",
        "! pip install sudachipy\n",
        "! pip install sudachidict_full\n",
        "! pip install sudachidict_small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCGnWiHk_Fzu"
      },
      "outputs": [],
      "source": [
        "#sudachiによる正規化を行う関数を定義\n",
        "from sudachipy import Dictionary\n",
        "from sudachipy import SplitMode\n",
        "tokenizer = Dictionary(dict=\"small\").create()\n",
        "\n",
        "def sudachi(text):\n",
        "    after = list()\n",
        "    for token in tokenizer.tokenize(text, SplitMode.C):\n",
        "        word = token.normalized_form() # 正規化あり\n",
        "        pos = \" \".join(token.part_of_speech())\n",
        "        \n",
        "        if word.isnumeric():\n",
        "            word = '0'\n",
        "\n",
        "        after.append(word)\n",
        "\n",
        "    return after"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install neologdn"
      ],
      "metadata": {
        "id": "7wuVYquJ3z1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7e1fe61-cee7-4839-d5da-6eb4b08549f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting neologdn\n",
            "  Downloading neologdn-0.5.1.tar.gz (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: neologdn\n",
            "  Building wheel for neologdn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neologdn: filename=neologdn-0.5.1-cp38-cp38-linux_x86_64.whl size=178326 sha256=a556e8daf6c6759af30b1ae60a7108dd57e27c9db386c57bc4790953f013f7a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/db/10/b3b26caa63c5da86ea3a25043cc4379a66bb3dd30d6f060a37\n",
            "Successfully built neologdn\n",
            "Installing collected packages: neologdn\n",
            "Successfully installed neologdn-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mC0_DhUy_IJS"
      },
      "outputs": [],
      "source": [
        "# 単語分割\n",
        "import neologdn\n",
        "\n",
        "train_tokenize = [] \n",
        "dev_tokenize = []\n",
        "test_tokenize = []\n",
        "\n",
        "def tokenize(infile, outfile):\n",
        "    for i in range(len(infile)):\n",
        "        outfile.append(sudachi(neologdn.normalize(infile[i])))    #正規化あり\n",
        "\n",
        "tokenize(train_text_demoji, train_tokenize)\n",
        "tokenize(dev_text_demoji, dev_tokenize)\n",
        "tokenize(test_text_demoji, test_tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeS-tQNrczqB"
      },
      "outputs": [],
      "source": [
        "def writefile(infile, outfile):\n",
        "    with open(outfile, 'w') as f:\n",
        "        for i, wordlist in enumerate(infile):\n",
        "            f.write(\" \".join([str(word) for word in wordlist]) + '\\n')\n",
        "\n",
        "writefile(train_tokenize, \"train.txt\")\n",
        "writefile(dev_tokenize, \"dev.txt\")\n",
        "writefile(test_tokenize, \"test.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxaDUTN7HWA4"
      },
      "outputs": [],
      "source": [
        "# Tokenizeしたデータを読み込み\n",
        "with open(\"train.txt\", 'r') as f:\n",
        "    traintext = f.read().split(\"\\n\")\n",
        "    traintext = traintext[:-1]\n",
        "with open(\"test.txt\", 'r') as f:\n",
        "    testtext = f.read().split(\"\\n\")\n",
        "    testtext = testtext[:-1]\n",
        "with open(\"dev.txt\", 'r') as f:\n",
        "    devtext = f.read().split(\"\\n\")\n",
        "    devtext = devtext[:-1]\n",
        "\n",
        "vectorizer = TfidfVectorizer(smooth_idf=True, analyzer='char', norm='l1') \n",
        "\n",
        "# tfidfでベクトル化\n",
        "x_train = vectorizer.fit_transform(traintext)\n",
        "x_test = vectorizer.transform(testtext)\n",
        "x_dev = vectorizer.transform(devtext)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D10qIcWDJf05",
        "outputId": "90dd5395-94b6-46cc-ae9a-f2d2c8492704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_trainの形状： (30000, 3231)\n",
            "x_devの形状： (2500, 3231)\n",
            "x_testの形状： (2500, 3231)\n",
            "y_trainの形状： (30000,)\n",
            "y_devの形状： (2500,)\n"
          ]
        }
      ],
      "source": [
        "print(\"x_trainの形状：\", x_train.shape)\n",
        "print(\"x_devの形状：\", x_dev.shape)\n",
        "print(\"x_testの形状：\", x_test.shape)\n",
        "\n",
        "y_train =  np.array(list(map (int, train_label)))\n",
        "y_dev =  np.array(list(map (int, dev_label)))\n",
        "print(\"y_trainの形状：\", y_train.shape)    \n",
        "print(\"y_devの形状：\", y_dev.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIDR-txsAsrq"
      },
      "source": [
        "#LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uSW_X70o_4o"
      },
      "outputs": [],
      "source": [
        "def lgb_custom_metric_qwk_regression(preds, data):\n",
        "    # 正解ラベル\n",
        "    y_true = data.get_label()\n",
        "    # 予測ラベル\n",
        "    y_pred = preds\n",
        "    return 'qwk', cohen_kappa_score(y_true, reval(y_pred), weights='quadratic'), True\n",
        "\n",
        "# https://blog.amedama.jp/entry/optuna-qwk-optimization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reval(somearray):\n",
        "    l = []\n",
        "    for x in somearray:\n",
        "        if x > 0.54:\n",
        "            l.append(2)\n",
        "        elif x > 0.3:\n",
        "            l.append(1)\n",
        "        elif x > -0.1:\n",
        "            l.append(0)\n",
        "        elif x > -0.55:\n",
        "            l.append(-1)\n",
        "        else:\n",
        "            l.append(-2)\n",
        "    return np.array(l)"
      ],
      "metadata": {
        "id": "t7ZncziUUmmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LightGBM\n",
        "dtrain = lgb.Dataset(x_train, label=y_train)\n",
        "ddev = lgb.Dataset(x_dev,label= y_dev)\n",
        "\n",
        "# 使用するパラメータ\n",
        "params = {'objective': 'regression',  # loss\n",
        "        'metric': 'lgb_custom_metric_qwk_regression',  # 評価指標\n",
        "        'random_state': 42, \n",
        "        'boosting_type': 'gbdt',\n",
        "        'learning_rate': 0.05,\n",
        "        'verbose': -1\n",
        "        }\n",
        "verbose_eval = 0\n",
        "\n",
        "# 学習\n",
        "gbm = lgb.train(params, dtrain,\n",
        "                valid_sets=[ddev],  # 評価用データ\n",
        "                feval=lgb_custom_metric_qwk_regression,\n",
        "                num_boost_round=10000,\n",
        "                callbacks=[lgb.early_stopping(stopping_rounds=32, verbose=True)] # early_stopping用コールバック関数\n",
        "                )\n",
        "# https://qiita.com/c60evaporator/items/2b7a2820d575e212bcf4"
      ],
      "metadata": {
        "id": "IYFiW7dkMfyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08edc450-bebf-4960-e7bc-f3be10371fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\tvalid_0's qwk: 0\n",
            "Training until validation scores don't improve for 32 rounds.\n",
            "[2]\tvalid_0's qwk: 0\n",
            "[3]\tvalid_0's qwk: 0\n",
            "[4]\tvalid_0's qwk: 0.00386781\n",
            "[5]\tvalid_0's qwk: 0.00899339\n",
            "[6]\tvalid_0's qwk: 0.0373382\n",
            "[7]\tvalid_0's qwk: 0.0751661\n",
            "[8]\tvalid_0's qwk: 0.111016\n",
            "[9]\tvalid_0's qwk: 0.134515\n",
            "[10]\tvalid_0's qwk: 0.1418\n",
            "[11]\tvalid_0's qwk: 0.162063\n",
            "[12]\tvalid_0's qwk: 0.170557\n",
            "[13]\tvalid_0's qwk: 0.178438\n",
            "[14]\tvalid_0's qwk: 0.195752\n",
            "[15]\tvalid_0's qwk: 0.212951\n",
            "[16]\tvalid_0's qwk: 0.215474\n",
            "[17]\tvalid_0's qwk: 0.235187\n",
            "[18]\tvalid_0's qwk: 0.24651\n",
            "[19]\tvalid_0's qwk: 0.252412\n",
            "[20]\tvalid_0's qwk: 0.26201\n",
            "[21]\tvalid_0's qwk: 0.272935\n",
            "[22]\tvalid_0's qwk: 0.282903\n",
            "[23]\tvalid_0's qwk: 0.283002\n",
            "[24]\tvalid_0's qwk: 0.290406\n",
            "[25]\tvalid_0's qwk: 0.299732\n",
            "[26]\tvalid_0's qwk: 0.313316\n",
            "[27]\tvalid_0's qwk: 0.318093\n",
            "[28]\tvalid_0's qwk: 0.324893\n",
            "[29]\tvalid_0's qwk: 0.32972\n",
            "[30]\tvalid_0's qwk: 0.336592\n",
            "[31]\tvalid_0's qwk: 0.345287\n",
            "[32]\tvalid_0's qwk: 0.348425\n",
            "[33]\tvalid_0's qwk: 0.356799\n",
            "[34]\tvalid_0's qwk: 0.360787\n",
            "[35]\tvalid_0's qwk: 0.358301\n",
            "[36]\tvalid_0's qwk: 0.358396\n",
            "[37]\tvalid_0's qwk: 0.361688\n",
            "[38]\tvalid_0's qwk: 0.363079\n",
            "[39]\tvalid_0's qwk: 0.367897\n",
            "[40]\tvalid_0's qwk: 0.367859\n",
            "[41]\tvalid_0's qwk: 0.368005\n",
            "[42]\tvalid_0's qwk: 0.373436\n",
            "[43]\tvalid_0's qwk: 0.373759\n",
            "[44]\tvalid_0's qwk: 0.373442\n",
            "[45]\tvalid_0's qwk: 0.373258\n",
            "[46]\tvalid_0's qwk: 0.376888\n",
            "[47]\tvalid_0's qwk: 0.381833\n",
            "[48]\tvalid_0's qwk: 0.385229\n",
            "[49]\tvalid_0's qwk: 0.382443\n",
            "[50]\tvalid_0's qwk: 0.38667\n",
            "[51]\tvalid_0's qwk: 0.389984\n",
            "[52]\tvalid_0's qwk: 0.388475\n",
            "[53]\tvalid_0's qwk: 0.388859\n",
            "[54]\tvalid_0's qwk: 0.395325\n",
            "[55]\tvalid_0's qwk: 0.394296\n",
            "[56]\tvalid_0's qwk: 0.39697\n",
            "[57]\tvalid_0's qwk: 0.396731\n",
            "[58]\tvalid_0's qwk: 0.395892\n",
            "[59]\tvalid_0's qwk: 0.395708\n",
            "[60]\tvalid_0's qwk: 0.398019\n",
            "[61]\tvalid_0's qwk: 0.39988\n",
            "[62]\tvalid_0's qwk: 0.401581\n",
            "[63]\tvalid_0's qwk: 0.403365\n",
            "[64]\tvalid_0's qwk: 0.402612\n",
            "[65]\tvalid_0's qwk: 0.402744\n",
            "[66]\tvalid_0's qwk: 0.403787\n",
            "[67]\tvalid_0's qwk: 0.406416\n",
            "[68]\tvalid_0's qwk: 0.407424\n",
            "[69]\tvalid_0's qwk: 0.406932\n",
            "[70]\tvalid_0's qwk: 0.411402\n",
            "[71]\tvalid_0's qwk: 0.413914\n",
            "[72]\tvalid_0's qwk: 0.412664\n",
            "[73]\tvalid_0's qwk: 0.414766\n",
            "[74]\tvalid_0's qwk: 0.413329\n",
            "[75]\tvalid_0's qwk: 0.416677\n",
            "[76]\tvalid_0's qwk: 0.416562\n",
            "[77]\tvalid_0's qwk: 0.417988\n",
            "[78]\tvalid_0's qwk: 0.421307\n",
            "[79]\tvalid_0's qwk: 0.420824\n",
            "[80]\tvalid_0's qwk: 0.422184\n",
            "[81]\tvalid_0's qwk: 0.423176\n",
            "[82]\tvalid_0's qwk: 0.423725\n",
            "[83]\tvalid_0's qwk: 0.422677\n",
            "[84]\tvalid_0's qwk: 0.423987\n",
            "[85]\tvalid_0's qwk: 0.422584\n",
            "[86]\tvalid_0's qwk: 0.422965\n",
            "[87]\tvalid_0's qwk: 0.425551\n",
            "[88]\tvalid_0's qwk: 0.423398\n",
            "[89]\tvalid_0's qwk: 0.424116\n",
            "[90]\tvalid_0's qwk: 0.426258\n",
            "[91]\tvalid_0's qwk: 0.4223\n",
            "[92]\tvalid_0's qwk: 0.423086\n",
            "[93]\tvalid_0's qwk: 0.424384\n",
            "[94]\tvalid_0's qwk: 0.42524\n",
            "[95]\tvalid_0's qwk: 0.429134\n",
            "[96]\tvalid_0's qwk: 0.428046\n",
            "[97]\tvalid_0's qwk: 0.427635\n",
            "[98]\tvalid_0's qwk: 0.428019\n",
            "[99]\tvalid_0's qwk: 0.429822\n",
            "[100]\tvalid_0's qwk: 0.431962\n",
            "[101]\tvalid_0's qwk: 0.432957\n",
            "[102]\tvalid_0's qwk: 0.435364\n",
            "[103]\tvalid_0's qwk: 0.435036\n",
            "[104]\tvalid_0's qwk: 0.435124\n",
            "[105]\tvalid_0's qwk: 0.434084\n",
            "[106]\tvalid_0's qwk: 0.435963\n",
            "[107]\tvalid_0's qwk: 0.438276\n",
            "[108]\tvalid_0's qwk: 0.438288\n",
            "[109]\tvalid_0's qwk: 0.438573\n",
            "[110]\tvalid_0's qwk: 0.44205\n",
            "[111]\tvalid_0's qwk: 0.440235\n",
            "[112]\tvalid_0's qwk: 0.442133\n",
            "[113]\tvalid_0's qwk: 0.441738\n",
            "[114]\tvalid_0's qwk: 0.441448\n",
            "[115]\tvalid_0's qwk: 0.444744\n",
            "[116]\tvalid_0's qwk: 0.445738\n",
            "[117]\tvalid_0's qwk: 0.445977\n",
            "[118]\tvalid_0's qwk: 0.445337\n",
            "[119]\tvalid_0's qwk: 0.446685\n",
            "[120]\tvalid_0's qwk: 0.446414\n",
            "[121]\tvalid_0's qwk: 0.446697\n",
            "[122]\tvalid_0's qwk: 0.445133\n",
            "[123]\tvalid_0's qwk: 0.447381\n",
            "[124]\tvalid_0's qwk: 0.447889\n",
            "[125]\tvalid_0's qwk: 0.447046\n",
            "[126]\tvalid_0's qwk: 0.446078\n",
            "[127]\tvalid_0's qwk: 0.446632\n",
            "[128]\tvalid_0's qwk: 0.447176\n",
            "[129]\tvalid_0's qwk: 0.446812\n",
            "[130]\tvalid_0's qwk: 0.45006\n",
            "[131]\tvalid_0's qwk: 0.450948\n",
            "[132]\tvalid_0's qwk: 0.450179\n",
            "[133]\tvalid_0's qwk: 0.451275\n",
            "[134]\tvalid_0's qwk: 0.454289\n",
            "[135]\tvalid_0's qwk: 0.455532\n",
            "[136]\tvalid_0's qwk: 0.454743\n",
            "[137]\tvalid_0's qwk: 0.456915\n",
            "[138]\tvalid_0's qwk: 0.45551\n",
            "[139]\tvalid_0's qwk: 0.455107\n",
            "[140]\tvalid_0's qwk: 0.456016\n",
            "[141]\tvalid_0's qwk: 0.457211\n",
            "[142]\tvalid_0's qwk: 0.457797\n",
            "[143]\tvalid_0's qwk: 0.458168\n",
            "[144]\tvalid_0's qwk: 0.459202\n",
            "[145]\tvalid_0's qwk: 0.457321\n",
            "[146]\tvalid_0's qwk: 0.456105\n",
            "[147]\tvalid_0's qwk: 0.456413\n",
            "[148]\tvalid_0's qwk: 0.45502\n",
            "[149]\tvalid_0's qwk: 0.455341\n",
            "[150]\tvalid_0's qwk: 0.45443\n",
            "[151]\tvalid_0's qwk: 0.455243\n",
            "[152]\tvalid_0's qwk: 0.455102\n",
            "[153]\tvalid_0's qwk: 0.45427\n",
            "[154]\tvalid_0's qwk: 0.45627\n",
            "[155]\tvalid_0's qwk: 0.457129\n",
            "[156]\tvalid_0's qwk: 0.45664\n",
            "[157]\tvalid_0's qwk: 0.456476\n",
            "[158]\tvalid_0's qwk: 0.45637\n",
            "[159]\tvalid_0's qwk: 0.456137\n",
            "[160]\tvalid_0's qwk: 0.456121\n",
            "[161]\tvalid_0's qwk: 0.456002\n",
            "[162]\tvalid_0's qwk: 0.456381\n",
            "[163]\tvalid_0's qwk: 0.457081\n",
            "[164]\tvalid_0's qwk: 0.455987\n",
            "[165]\tvalid_0's qwk: 0.456349\n",
            "[166]\tvalid_0's qwk: 0.456482\n",
            "[167]\tvalid_0's qwk: 0.457196\n",
            "[168]\tvalid_0's qwk: 0.457117\n",
            "[169]\tvalid_0's qwk: 0.456571\n",
            "[170]\tvalid_0's qwk: 0.456431\n",
            "[171]\tvalid_0's qwk: 0.457507\n",
            "[172]\tvalid_0's qwk: 0.457786\n",
            "[173]\tvalid_0's qwk: 0.457809\n",
            "[174]\tvalid_0's qwk: 0.458104\n",
            "[175]\tvalid_0's qwk: 0.459505\n",
            "[176]\tvalid_0's qwk: 0.457514\n",
            "[177]\tvalid_0's qwk: 0.458558\n",
            "[178]\tvalid_0's qwk: 0.458621\n",
            "[179]\tvalid_0's qwk: 0.460153\n",
            "[180]\tvalid_0's qwk: 0.459511\n",
            "[181]\tvalid_0's qwk: 0.459504\n",
            "[182]\tvalid_0's qwk: 0.460595\n",
            "[183]\tvalid_0's qwk: 0.46001\n",
            "[184]\tvalid_0's qwk: 0.459308\n",
            "[185]\tvalid_0's qwk: 0.458732\n",
            "[186]\tvalid_0's qwk: 0.459314\n",
            "[187]\tvalid_0's qwk: 0.458116\n",
            "[188]\tvalid_0's qwk: 0.45819\n",
            "[189]\tvalid_0's qwk: 0.458866\n",
            "[190]\tvalid_0's qwk: 0.460316\n",
            "[191]\tvalid_0's qwk: 0.459425\n",
            "[192]\tvalid_0's qwk: 0.459429\n",
            "[193]\tvalid_0's qwk: 0.4604\n",
            "[194]\tvalid_0's qwk: 0.459529\n",
            "[195]\tvalid_0's qwk: 0.459557\n",
            "[196]\tvalid_0's qwk: 0.459725\n",
            "[197]\tvalid_0's qwk: 0.460302\n",
            "[198]\tvalid_0's qwk: 0.461935\n",
            "[199]\tvalid_0's qwk: 0.461926\n",
            "[200]\tvalid_0's qwk: 0.463045\n",
            "[201]\tvalid_0's qwk: 0.463041\n",
            "[202]\tvalid_0's qwk: 0.463225\n",
            "[203]\tvalid_0's qwk: 0.463045\n",
            "[204]\tvalid_0's qwk: 0.463748\n",
            "[205]\tvalid_0's qwk: 0.463419\n",
            "[206]\tvalid_0's qwk: 0.465189\n",
            "[207]\tvalid_0's qwk: 0.464289\n",
            "[208]\tvalid_0's qwk: 0.462574\n",
            "[209]\tvalid_0's qwk: 0.462286\n",
            "[210]\tvalid_0's qwk: 0.462286\n",
            "[211]\tvalid_0's qwk: 0.462927\n",
            "[212]\tvalid_0's qwk: 0.463091\n",
            "[213]\tvalid_0's qwk: 0.464225\n",
            "[214]\tvalid_0's qwk: 0.465339\n",
            "[215]\tvalid_0's qwk: 0.465317\n",
            "[216]\tvalid_0's qwk: 0.465336\n",
            "[217]\tvalid_0's qwk: 0.467907\n",
            "[218]\tvalid_0's qwk: 0.468052\n",
            "[219]\tvalid_0's qwk: 0.466364\n",
            "[220]\tvalid_0's qwk: 0.466364\n",
            "[221]\tvalid_0's qwk: 0.465464\n",
            "[222]\tvalid_0's qwk: 0.464813\n",
            "[223]\tvalid_0's qwk: 0.465405\n",
            "[224]\tvalid_0's qwk: 0.464642\n",
            "[225]\tvalid_0's qwk: 0.464435\n",
            "[226]\tvalid_0's qwk: 0.463715\n",
            "[227]\tvalid_0's qwk: 0.463393\n",
            "[228]\tvalid_0's qwk: 0.463229\n",
            "[229]\tvalid_0's qwk: 0.463328\n",
            "[230]\tvalid_0's qwk: 0.462983\n",
            "[231]\tvalid_0's qwk: 0.462991\n",
            "[232]\tvalid_0's qwk: 0.462784\n",
            "[233]\tvalid_0's qwk: 0.462848\n",
            "[234]\tvalid_0's qwk: 0.463626\n",
            "[235]\tvalid_0's qwk: 0.463256\n",
            "[236]\tvalid_0's qwk: 0.463157\n",
            "[237]\tvalid_0's qwk: 0.46426\n",
            "[238]\tvalid_0's qwk: 0.465749\n",
            "[239]\tvalid_0's qwk: 0.466647\n",
            "[240]\tvalid_0's qwk: 0.467057\n",
            "[241]\tvalid_0's qwk: 0.466163\n",
            "[242]\tvalid_0's qwk: 0.466414\n",
            "[243]\tvalid_0's qwk: 0.465945\n",
            "[244]\tvalid_0's qwk: 0.466782\n",
            "[245]\tvalid_0's qwk: 0.467552\n",
            "[246]\tvalid_0's qwk: 0.468086\n",
            "[247]\tvalid_0's qwk: 0.468637\n",
            "[248]\tvalid_0's qwk: 0.468426\n",
            "[249]\tvalid_0's qwk: 0.467939\n",
            "[250]\tvalid_0's qwk: 0.467333\n",
            "[251]\tvalid_0's qwk: 0.467171\n",
            "[252]\tvalid_0's qwk: 0.466618\n",
            "[253]\tvalid_0's qwk: 0.466896\n",
            "[254]\tvalid_0's qwk: 0.466419\n",
            "[255]\tvalid_0's qwk: 0.465706\n",
            "[256]\tvalid_0's qwk: 0.466096\n",
            "[257]\tvalid_0's qwk: 0.466096\n",
            "[258]\tvalid_0's qwk: 0.466276\n",
            "[259]\tvalid_0's qwk: 0.465763\n",
            "[260]\tvalid_0's qwk: 0.465705\n",
            "[261]\tvalid_0's qwk: 0.464326\n",
            "[262]\tvalid_0's qwk: 0.463965\n",
            "[263]\tvalid_0's qwk: 0.464388\n",
            "[264]\tvalid_0's qwk: 0.46439\n",
            "[265]\tvalid_0's qwk: 0.463966\n",
            "[266]\tvalid_0's qwk: 0.463781\n",
            "[267]\tvalid_0's qwk: 0.463977\n",
            "[268]\tvalid_0's qwk: 0.464075\n",
            "[269]\tvalid_0's qwk: 0.464964\n",
            "[270]\tvalid_0's qwk: 0.464249\n",
            "[271]\tvalid_0's qwk: 0.465864\n",
            "[272]\tvalid_0's qwk: 0.465561\n",
            "[273]\tvalid_0's qwk: 0.465384\n",
            "[274]\tvalid_0's qwk: 0.46572\n",
            "[275]\tvalid_0's qwk: 0.465936\n",
            "[276]\tvalid_0's qwk: 0.466012\n",
            "[277]\tvalid_0's qwk: 0.466795\n",
            "[278]\tvalid_0's qwk: 0.465684\n",
            "[279]\tvalid_0's qwk: 0.466587\n",
            "Early stopping, best iteration is:\n",
            "[247]\tvalid_0's qwk: 0.468637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# devに対するスコア算出\n",
        "y_pred = gbm.predict(x_dev)\n",
        "qwk = cohen_kappa_score(y_dev, reval(y_pred), weights='quadratic')\n",
        "rmse = mean_squared_error(y_true=y_dev, y_pred=y_pred, squared=False)\n",
        "print('QWK=', qwk)\n",
        "print('RMSE=', rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTiY7jifTHMG",
        "outputId": "dbcda402-ebda-431e-cbbd-e8859cc6a974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QWK= 0.46863744726737844\n",
            "RMSE= 1.055380223555826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testに対するスコア算出\n",
        "y_pred = gbm.predict(x_test)\n",
        "y_pred = reval(y_pred)\n",
        "\n",
        "# 書き込み\n",
        "f = open(\"LightGBM_顔文字あり_num_lr0.05_c_small_0.499.txt\", \"w\")\n",
        "for labeldata in y_pred:\n",
        "    f.write(str(labeldata))\n",
        "    f.write(\"\\n\")\n",
        "f.close()"
      ],
      "metadata": {
        "id": "GE4dArWBw6Lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CatBoost"
      ],
      "metadata": {
        "id": "W7hc6rp71qU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sudachiによる正規化を行う関数を定義\n",
        "from sudachipy import Dictionary\n",
        "from sudachipy import SplitMode\n",
        "tokenizer = Dictionary(dict=\"full\").create()\n",
        "\n",
        "def sudachi(text):\n",
        "    after = list()\n",
        "    for token in tokenizer.tokenize(text, SplitMode.C):\n",
        "        word = token.normalized_form() # 正規化あり\n",
        "        pos = \" \".join(token.part_of_speech())\n",
        "        \n",
        "        if word.isnumeric():\n",
        "            word = '0'\n",
        "\n",
        "        after.append(word)\n",
        "        \n",
        "    return after"
      ],
      "metadata": {
        "id": "4lAJ4PTv7FkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokenize_cat = [] \n",
        "dev_tokenize_cat = []\n",
        "test_tokenize_cat = []"
      ],
      "metadata": {
        "id": "UXv8hOo_F5JZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(infile, outfile):\n",
        "    for i in range(len(infile)):\n",
        "        outfile.append(sudachi(neologdn.normalize(infile[i])))    #正規化あり\n",
        "\n",
        "tokenize(train_text_demoji, train_tokenize_cat)\n",
        "tokenize(dev_text_demoji, dev_tokenize_cat)\n",
        "tokenize(test_text_demoji, test_tokenize_cat)"
      ],
      "metadata": {
        "id": "9HcolzpT7MAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writefile(train_tokenize_cat, \"train.txt\")\n",
        "writefile(dev_tokenize_cat, \"dev.txt\")\n",
        "writefile(test_tokenize_cat, \"test.txt\")"
      ],
      "metadata": {
        "id": "D8ClV4Bs7N6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"train.txt\", 'r') as f:\n",
        "    traintext = f.read().split(\"\\n\")\n",
        "    traintext = traintext[:-1]\n",
        "with open(\"test.txt\", 'r') as f:\n",
        "    testtext = f.read().split(\"\\n\")\n",
        "    testtext = testtext[:-1]\n",
        "with open(\"dev.txt\", 'r') as f:\n",
        "    devtext = f.read().split(\"\\n\")\n",
        "    devtext = devtext[:-1]\n",
        "\n",
        "vectorizer = TfidfVectorizer(smooth_idf=True, analyzer='char')\n",
        "\n",
        "x_train_cat = vectorizer.fit_transform(traintext)\n",
        "x_test_cat = vectorizer.transform(testtext)\n",
        "x_dev_cat = vectorizer.transform(devtext)"
      ],
      "metadata": {
        "id": "B7jTqd9s7SAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"x_trainの形状：\", x_train_cat.shape)\n",
        "print(\"x_devの形状：\", x_dev_cat.shape)\n",
        "print(\"x_testの形状：\", x_test_cat.shape)\n",
        "\n",
        "# y_train =  np.array(list(map (int, train_label)))\n",
        "# y_dev =  np.array(list(map (int, dev_label)))\n",
        "print(\"y_trainの形状：\", y_train.shape)    \n",
        "print(\"y_devの形状：\", y_dev.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA3dBnd917Yb",
        "outputId": "b90a0f11-b560-4f8d-b44d-843697c04d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_trainの形状： (30000, 3246)\n",
            "x_devの形状： (2500, 3246)\n",
            "x_testの形状： (2500, 3246)\n",
            "y_trainの形状： (30000,)\n",
            "y_devの形状： (2500,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reval(somearray):\n",
        "    l = []\n",
        "    for x in somearray:\n",
        "        if x > 0.6:\n",
        "            l.append(2)\n",
        "        elif x > 0.35:\n",
        "            l.append(1)\n",
        "        elif x > 0:\n",
        "            l.append(0)\n",
        "        elif x > -0.50:\n",
        "            l.append(-1)\n",
        "        else:\n",
        "            l.append(-2)\n",
        "    return np.array(l)"
      ],
      "metadata": {
        "id": "OsJ8VRZm2YJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk6XWv3s2Ktc",
        "outputId": "2424f7f0-6582-4e99-f12f-29d2e0e1e596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.1.1-cp38-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from catboost) (1.7.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2022.7)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly->catboost) (8.1.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import catboost as  cb\n",
        "from catboost import CatBoost, Pool\n",
        "\n",
        "# CatBoostを利用するのに必要なフォーマットに変換\n",
        "cb_train = Pool(x_train, y_train)\n",
        "cb_eval = Pool(x_dev, y_dev)\n",
        "cb_test = Pool(x_test)"
      ],
      "metadata": {
        "id": "Mjvvhqxe2MhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# パラメータ設定\n",
        "params = {\n",
        "    'num_boost_round': 1000,\n",
        "    'early_stopping_rounds': 32,\n",
        "}\n",
        "\n",
        "# 学習\n",
        "model = CatBoost(params)\n",
        "model.fit(cb_train, eval_set=[cb_eval], verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXEytBoF2d8p",
        "outputId": "27374181-03ff-47cc-e749-19d462882389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.086857\n",
            "0:\tlearn: 1.1875561\ttest: 1.1945366\tbest: 1.1945366 (0)\ttotal: 214ms\tremaining: 3m 34s\n",
            "1:\tlearn: 1.1821393\ttest: 1.1891702\tbest: 1.1891702 (1)\ttotal: 348ms\tremaining: 2m 53s\n",
            "2:\tlearn: 1.1767019\ttest: 1.1843562\tbest: 1.1843562 (2)\ttotal: 493ms\tremaining: 2m 43s\n",
            "3:\tlearn: 1.1722048\ttest: 1.1808996\tbest: 1.1808996 (3)\ttotal: 646ms\tremaining: 2m 40s\n",
            "4:\tlearn: 1.1675495\ttest: 1.1777665\tbest: 1.1777665 (4)\ttotal: 779ms\tremaining: 2m 35s\n",
            "5:\tlearn: 1.1635396\ttest: 1.1737401\tbest: 1.1737401 (5)\ttotal: 910ms\tremaining: 2m 30s\n",
            "6:\tlearn: 1.1598027\ttest: 1.1708826\tbest: 1.1708826 (6)\ttotal: 1.04s\tremaining: 2m 28s\n",
            "7:\tlearn: 1.1562295\ttest: 1.1679287\tbest: 1.1679287 (7)\ttotal: 1.18s\tremaining: 2m 26s\n",
            "8:\tlearn: 1.1534412\ttest: 1.1649651\tbest: 1.1649651 (8)\ttotal: 1.32s\tremaining: 2m 25s\n",
            "9:\tlearn: 1.1502121\ttest: 1.1625431\tbest: 1.1625431 (9)\ttotal: 1.46s\tremaining: 2m 24s\n",
            "10:\tlearn: 1.1471875\ttest: 1.1606263\tbest: 1.1606263 (10)\ttotal: 1.6s\tremaining: 2m 23s\n",
            "11:\tlearn: 1.1448056\ttest: 1.1583175\tbest: 1.1583175 (11)\ttotal: 1.73s\tremaining: 2m 22s\n",
            "12:\tlearn: 1.1425208\ttest: 1.1565923\tbest: 1.1565923 (12)\ttotal: 1.86s\tremaining: 2m 21s\n",
            "13:\tlearn: 1.1404399\ttest: 1.1546386\tbest: 1.1546386 (13)\ttotal: 2s\tremaining: 2m 21s\n",
            "14:\tlearn: 1.1382726\ttest: 1.1529954\tbest: 1.1529954 (14)\ttotal: 2.14s\tremaining: 2m 20s\n",
            "15:\tlearn: 1.1362779\ttest: 1.1507991\tbest: 1.1507991 (15)\ttotal: 2.27s\tremaining: 2m 19s\n",
            "16:\tlearn: 1.1342271\ttest: 1.1485906\tbest: 1.1485906 (16)\ttotal: 2.4s\tremaining: 2m 19s\n",
            "17:\tlearn: 1.1321783\ttest: 1.1467068\tbest: 1.1467068 (17)\ttotal: 2.55s\tremaining: 2m 18s\n",
            "18:\tlearn: 1.1303469\ttest: 1.1444626\tbest: 1.1444626 (18)\ttotal: 2.68s\tremaining: 2m 18s\n",
            "19:\tlearn: 1.1287097\ttest: 1.1433382\tbest: 1.1433382 (19)\ttotal: 2.83s\tremaining: 2m 18s\n",
            "20:\tlearn: 1.1270470\ttest: 1.1416649\tbest: 1.1416649 (20)\ttotal: 2.96s\tremaining: 2m 18s\n",
            "21:\tlearn: 1.1252982\ttest: 1.1404077\tbest: 1.1404077 (21)\ttotal: 3.09s\tremaining: 2m 17s\n",
            "22:\tlearn: 1.1238422\ttest: 1.1387124\tbest: 1.1387124 (22)\ttotal: 3.22s\tremaining: 2m 16s\n",
            "23:\tlearn: 1.1223354\ttest: 1.1374623\tbest: 1.1374623 (23)\ttotal: 3.35s\tremaining: 2m 16s\n",
            "24:\tlearn: 1.1207873\ttest: 1.1364387\tbest: 1.1364387 (24)\ttotal: 3.48s\tremaining: 2m 15s\n",
            "25:\tlearn: 1.1194934\ttest: 1.1360252\tbest: 1.1360252 (25)\ttotal: 3.62s\tremaining: 2m 15s\n",
            "26:\tlearn: 1.1182369\ttest: 1.1350113\tbest: 1.1350113 (26)\ttotal: 3.75s\tremaining: 2m 15s\n",
            "27:\tlearn: 1.1166124\ttest: 1.1343267\tbest: 1.1343267 (27)\ttotal: 3.88s\tremaining: 2m 14s\n",
            "28:\tlearn: 1.1154343\ttest: 1.1334828\tbest: 1.1334828 (28)\ttotal: 4.01s\tremaining: 2m 14s\n",
            "29:\tlearn: 1.1144796\ttest: 1.1327486\tbest: 1.1327486 (29)\ttotal: 4.15s\tremaining: 2m 14s\n",
            "30:\tlearn: 1.1132723\ttest: 1.1321733\tbest: 1.1321733 (30)\ttotal: 4.28s\tremaining: 2m 13s\n",
            "31:\tlearn: 1.1120670\ttest: 1.1308057\tbest: 1.1308057 (31)\ttotal: 4.41s\tremaining: 2m 13s\n",
            "32:\tlearn: 1.1108532\ttest: 1.1298761\tbest: 1.1298761 (32)\ttotal: 4.56s\tremaining: 2m 13s\n",
            "33:\tlearn: 1.1097674\ttest: 1.1292508\tbest: 1.1292508 (33)\ttotal: 4.73s\tremaining: 2m 14s\n",
            "34:\tlearn: 1.1086450\ttest: 1.1284496\tbest: 1.1284496 (34)\ttotal: 4.95s\tremaining: 2m 16s\n",
            "35:\tlearn: 1.1076232\ttest: 1.1277032\tbest: 1.1277032 (35)\ttotal: 5.16s\tremaining: 2m 18s\n",
            "36:\tlearn: 1.1066084\ttest: 1.1271826\tbest: 1.1271826 (36)\ttotal: 5.43s\tremaining: 2m 21s\n",
            "37:\tlearn: 1.1055353\ttest: 1.1265386\tbest: 1.1265386 (37)\ttotal: 5.74s\tremaining: 2m 25s\n",
            "38:\tlearn: 1.1044419\ttest: 1.1257981\tbest: 1.1257981 (38)\ttotal: 5.99s\tremaining: 2m 27s\n",
            "39:\tlearn: 1.1034003\ttest: 1.1255070\tbest: 1.1255070 (39)\ttotal: 6.2s\tremaining: 2m 28s\n",
            "40:\tlearn: 1.1024984\ttest: 1.1248596\tbest: 1.1248596 (40)\ttotal: 6.47s\tremaining: 2m 31s\n",
            "41:\tlearn: 1.1016273\ttest: 1.1239422\tbest: 1.1239422 (41)\ttotal: 6.73s\tremaining: 2m 33s\n",
            "42:\tlearn: 1.1008135\ttest: 1.1232176\tbest: 1.1232176 (42)\ttotal: 6.98s\tremaining: 2m 35s\n",
            "43:\tlearn: 1.0998385\ttest: 1.1220648\tbest: 1.1220648 (43)\ttotal: 7.25s\tremaining: 2m 37s\n",
            "44:\tlearn: 1.0992661\ttest: 1.1215640\tbest: 1.1215640 (44)\ttotal: 7.55s\tremaining: 2m 40s\n",
            "45:\tlearn: 1.0984522\ttest: 1.1210414\tbest: 1.1210414 (45)\ttotal: 7.8s\tremaining: 2m 41s\n",
            "46:\tlearn: 1.0976801\ttest: 1.1202395\tbest: 1.1202395 (46)\ttotal: 7.99s\tremaining: 2m 42s\n",
            "47:\tlearn: 1.0968391\ttest: 1.1197192\tbest: 1.1197192 (47)\ttotal: 8.18s\tremaining: 2m 42s\n",
            "48:\tlearn: 1.0959019\ttest: 1.1187461\tbest: 1.1187461 (48)\ttotal: 8.36s\tremaining: 2m 42s\n",
            "49:\tlearn: 1.0951692\ttest: 1.1181696\tbest: 1.1181696 (49)\ttotal: 8.49s\tremaining: 2m 41s\n",
            "50:\tlearn: 1.0943393\ttest: 1.1177145\tbest: 1.1177145 (50)\ttotal: 8.64s\tremaining: 2m 40s\n",
            "51:\tlearn: 1.0935090\ttest: 1.1167099\tbest: 1.1167099 (51)\ttotal: 8.83s\tremaining: 2m 40s\n",
            "52:\tlearn: 1.0927568\ttest: 1.1159488\tbest: 1.1159488 (52)\ttotal: 9.01s\tremaining: 2m 41s\n",
            "53:\tlearn: 1.0920196\ttest: 1.1153360\tbest: 1.1153360 (53)\ttotal: 9.19s\tremaining: 2m 41s\n",
            "54:\tlearn: 1.0910871\ttest: 1.1144808\tbest: 1.1144808 (54)\ttotal: 9.34s\tremaining: 2m 40s\n",
            "55:\tlearn: 1.0905946\ttest: 1.1140961\tbest: 1.1140961 (55)\ttotal: 9.54s\tremaining: 2m 40s\n",
            "56:\tlearn: 1.0900626\ttest: 1.1134790\tbest: 1.1134790 (56)\ttotal: 9.72s\tremaining: 2m 40s\n",
            "57:\tlearn: 1.0894972\ttest: 1.1130581\tbest: 1.1130581 (57)\ttotal: 9.88s\tremaining: 2m 40s\n",
            "58:\tlearn: 1.0888465\ttest: 1.1125912\tbest: 1.1125912 (58)\ttotal: 10s\tremaining: 2m 39s\n",
            "59:\tlearn: 1.0880944\ttest: 1.1121677\tbest: 1.1121677 (59)\ttotal: 10.2s\tremaining: 2m 39s\n",
            "60:\tlearn: 1.0874249\ttest: 1.1118813\tbest: 1.1118813 (60)\ttotal: 10.3s\tremaining: 2m 38s\n",
            "61:\tlearn: 1.0867788\ttest: 1.1112313\tbest: 1.1112313 (61)\ttotal: 10.4s\tremaining: 2m 37s\n",
            "62:\tlearn: 1.0861246\ttest: 1.1105315\tbest: 1.1105315 (62)\ttotal: 10.5s\tremaining: 2m 36s\n",
            "63:\tlearn: 1.0853858\ttest: 1.1101133\tbest: 1.1101133 (63)\ttotal: 10.7s\tremaining: 2m 36s\n",
            "64:\tlearn: 1.0847682\ttest: 1.1096785\tbest: 1.1096785 (64)\ttotal: 10.8s\tremaining: 2m 35s\n",
            "65:\tlearn: 1.0841734\ttest: 1.1091134\tbest: 1.1091134 (65)\ttotal: 10.9s\tremaining: 2m 34s\n",
            "66:\tlearn: 1.0836912\ttest: 1.1089588\tbest: 1.1089588 (66)\ttotal: 11.1s\tremaining: 2m 34s\n",
            "67:\tlearn: 1.0831768\ttest: 1.1087689\tbest: 1.1087689 (67)\ttotal: 11.2s\tremaining: 2m 33s\n",
            "68:\tlearn: 1.0825995\ttest: 1.1083621\tbest: 1.1083621 (68)\ttotal: 11.3s\tremaining: 2m 33s\n",
            "69:\tlearn: 1.0820184\ttest: 1.1083493\tbest: 1.1083493 (69)\ttotal: 11.5s\tremaining: 2m 32s\n",
            "70:\tlearn: 1.0815523\ttest: 1.1079506\tbest: 1.1079506 (70)\ttotal: 11.6s\tremaining: 2m 31s\n",
            "71:\tlearn: 1.0809629\ttest: 1.1071065\tbest: 1.1071065 (71)\ttotal: 11.7s\tremaining: 2m 31s\n",
            "72:\tlearn: 1.0803634\ttest: 1.1067762\tbest: 1.1067762 (72)\ttotal: 11.9s\tremaining: 2m 30s\n",
            "73:\tlearn: 1.0799265\ttest: 1.1067901\tbest: 1.1067762 (72)\ttotal: 12s\tremaining: 2m 30s\n",
            "74:\tlearn: 1.0794679\ttest: 1.1063281\tbest: 1.1063281 (74)\ttotal: 12.1s\tremaining: 2m 29s\n",
            "75:\tlearn: 1.0789901\ttest: 1.1060384\tbest: 1.1060384 (75)\ttotal: 12.3s\tremaining: 2m 28s\n",
            "76:\tlearn: 1.0784979\ttest: 1.1056799\tbest: 1.1056799 (76)\ttotal: 12.4s\tremaining: 2m 28s\n",
            "77:\tlearn: 1.0777509\ttest: 1.1050665\tbest: 1.1050665 (77)\ttotal: 12.5s\tremaining: 2m 27s\n",
            "78:\tlearn: 1.0773172\ttest: 1.1048894\tbest: 1.1048894 (78)\ttotal: 12.6s\tremaining: 2m 27s\n",
            "79:\tlearn: 1.0766707\ttest: 1.1045302\tbest: 1.1045302 (79)\ttotal: 12.8s\tremaining: 2m 27s\n",
            "80:\tlearn: 1.0761651\ttest: 1.1041713\tbest: 1.1041713 (80)\ttotal: 12.9s\tremaining: 2m 26s\n",
            "81:\tlearn: 1.0757145\ttest: 1.1038242\tbest: 1.1038242 (81)\ttotal: 13s\tremaining: 2m 26s\n",
            "82:\tlearn: 1.0752218\ttest: 1.1038512\tbest: 1.1038242 (81)\ttotal: 13.2s\tremaining: 2m 25s\n",
            "83:\tlearn: 1.0747440\ttest: 1.1037259\tbest: 1.1037259 (83)\ttotal: 13.3s\tremaining: 2m 25s\n",
            "84:\tlearn: 1.0741389\ttest: 1.1028174\tbest: 1.1028174 (84)\ttotal: 13.4s\tremaining: 2m 24s\n",
            "85:\tlearn: 1.0736821\ttest: 1.1026317\tbest: 1.1026317 (85)\ttotal: 13.6s\tremaining: 2m 24s\n",
            "86:\tlearn: 1.0731671\ttest: 1.1022992\tbest: 1.1022992 (86)\ttotal: 13.7s\tremaining: 2m 23s\n",
            "87:\tlearn: 1.0727000\ttest: 1.1018642\tbest: 1.1018642 (87)\ttotal: 13.8s\tremaining: 2m 23s\n",
            "88:\tlearn: 1.0722603\ttest: 1.1014049\tbest: 1.1014049 (88)\ttotal: 14s\tremaining: 2m 22s\n",
            "89:\tlearn: 1.0718546\ttest: 1.1010825\tbest: 1.1010825 (89)\ttotal: 14.1s\tremaining: 2m 22s\n",
            "90:\tlearn: 1.0714266\ttest: 1.1008448\tbest: 1.1008448 (90)\ttotal: 14.2s\tremaining: 2m 22s\n",
            "91:\tlearn: 1.0708989\ttest: 1.1005917\tbest: 1.1005917 (91)\ttotal: 14.4s\tremaining: 2m 21s\n",
            "92:\tlearn: 1.0704971\ttest: 1.1002151\tbest: 1.1002151 (92)\ttotal: 14.5s\tremaining: 2m 21s\n",
            "93:\tlearn: 1.0700857\ttest: 1.0997103\tbest: 1.0997103 (93)\ttotal: 14.6s\tremaining: 2m 20s\n",
            "94:\tlearn: 1.0696461\ttest: 1.0992429\tbest: 1.0992429 (94)\ttotal: 14.7s\tremaining: 2m 20s\n",
            "95:\tlearn: 1.0692147\ttest: 1.0988002\tbest: 1.0988002 (95)\ttotal: 14.9s\tremaining: 2m 20s\n",
            "96:\tlearn: 1.0687823\ttest: 1.0983866\tbest: 1.0983866 (96)\ttotal: 15s\tremaining: 2m 19s\n",
            "97:\tlearn: 1.0682672\ttest: 1.0979798\tbest: 1.0979798 (97)\ttotal: 15.1s\tremaining: 2m 19s\n",
            "98:\tlearn: 1.0677886\ttest: 1.0973201\tbest: 1.0973201 (98)\ttotal: 15.3s\tremaining: 2m 18s\n",
            "99:\tlearn: 1.0674373\ttest: 1.0970143\tbest: 1.0970143 (99)\ttotal: 15.4s\tremaining: 2m 18s\n",
            "100:\tlearn: 1.0668613\ttest: 1.0964616\tbest: 1.0964616 (100)\ttotal: 15.5s\tremaining: 2m 18s\n",
            "101:\tlearn: 1.0662788\ttest: 1.0962160\tbest: 1.0962160 (101)\ttotal: 15.7s\tremaining: 2m 17s\n",
            "102:\tlearn: 1.0658626\ttest: 1.0958768\tbest: 1.0958768 (102)\ttotal: 15.8s\tremaining: 2m 17s\n",
            "103:\tlearn: 1.0651921\ttest: 1.0954978\tbest: 1.0954978 (103)\ttotal: 15.9s\tremaining: 2m 17s\n",
            "104:\tlearn: 1.0647279\ttest: 1.0953788\tbest: 1.0953788 (104)\ttotal: 16.1s\tremaining: 2m 16s\n",
            "105:\tlearn: 1.0643674\ttest: 1.0952604\tbest: 1.0952604 (105)\ttotal: 16.2s\tremaining: 2m 16s\n",
            "106:\tlearn: 1.0639565\ttest: 1.0951616\tbest: 1.0951616 (106)\ttotal: 16.3s\tremaining: 2m 16s\n",
            "107:\tlearn: 1.0635212\ttest: 1.0948610\tbest: 1.0948610 (107)\ttotal: 16.5s\tremaining: 2m 15s\n",
            "108:\tlearn: 1.0630960\ttest: 1.0946223\tbest: 1.0946223 (108)\ttotal: 16.6s\tremaining: 2m 15s\n",
            "109:\tlearn: 1.0626672\ttest: 1.0946502\tbest: 1.0946223 (108)\ttotal: 16.7s\tremaining: 2m 15s\n",
            "110:\tlearn: 1.0622472\ttest: 1.0944487\tbest: 1.0944487 (110)\ttotal: 16.9s\tremaining: 2m 15s\n",
            "111:\tlearn: 1.0618813\ttest: 1.0942910\tbest: 1.0942910 (111)\ttotal: 17s\tremaining: 2m 14s\n",
            "112:\tlearn: 1.0615349\ttest: 1.0940800\tbest: 1.0940800 (112)\ttotal: 17.1s\tremaining: 2m 14s\n",
            "113:\tlearn: 1.0611408\ttest: 1.0937173\tbest: 1.0937173 (113)\ttotal: 17.2s\tremaining: 2m 14s\n",
            "114:\tlearn: 1.0607034\ttest: 1.0935903\tbest: 1.0935903 (114)\ttotal: 17.4s\tremaining: 2m 13s\n",
            "115:\tlearn: 1.0603505\ttest: 1.0932216\tbest: 1.0932216 (115)\ttotal: 17.5s\tremaining: 2m 13s\n",
            "116:\tlearn: 1.0599383\ttest: 1.0927573\tbest: 1.0927573 (116)\ttotal: 17.6s\tremaining: 2m 13s\n",
            "117:\tlearn: 1.0594885\ttest: 1.0922257\tbest: 1.0922257 (117)\ttotal: 17.8s\tremaining: 2m 12s\n",
            "118:\tlearn: 1.0589970\ttest: 1.0921334\tbest: 1.0921334 (118)\ttotal: 17.9s\tremaining: 2m 12s\n",
            "119:\tlearn: 1.0586554\ttest: 1.0919991\tbest: 1.0919991 (119)\ttotal: 18s\tremaining: 2m 12s\n",
            "120:\tlearn: 1.0581816\ttest: 1.0916992\tbest: 1.0916992 (120)\ttotal: 18.2s\tremaining: 2m 11s\n",
            "121:\tlearn: 1.0577451\ttest: 1.0911551\tbest: 1.0911551 (121)\ttotal: 18.3s\tremaining: 2m 11s\n",
            "122:\tlearn: 1.0572642\ttest: 1.0908624\tbest: 1.0908624 (122)\ttotal: 18.4s\tremaining: 2m 11s\n",
            "123:\tlearn: 1.0568994\ttest: 1.0903338\tbest: 1.0903338 (123)\ttotal: 18.6s\tremaining: 2m 11s\n",
            "124:\tlearn: 1.0565187\ttest: 1.0901974\tbest: 1.0901974 (124)\ttotal: 18.7s\tremaining: 2m 10s\n",
            "125:\tlearn: 1.0560759\ttest: 1.0899960\tbest: 1.0899960 (125)\ttotal: 18.8s\tremaining: 2m 10s\n",
            "126:\tlearn: 1.0556472\ttest: 1.0898574\tbest: 1.0898574 (126)\ttotal: 18.9s\tremaining: 2m 10s\n",
            "127:\tlearn: 1.0552352\ttest: 1.0898488\tbest: 1.0898488 (127)\ttotal: 19.1s\tremaining: 2m 9s\n",
            "128:\tlearn: 1.0547780\ttest: 1.0896047\tbest: 1.0896047 (128)\ttotal: 19.2s\tremaining: 2m 9s\n",
            "129:\tlearn: 1.0543736\ttest: 1.0892918\tbest: 1.0892918 (129)\ttotal: 19.3s\tremaining: 2m 9s\n",
            "130:\tlearn: 1.0540117\ttest: 1.0890714\tbest: 1.0890714 (130)\ttotal: 19.5s\tremaining: 2m 9s\n",
            "131:\tlearn: 1.0535309\ttest: 1.0889539\tbest: 1.0889539 (131)\ttotal: 19.6s\tremaining: 2m 8s\n",
            "132:\tlearn: 1.0531351\ttest: 1.0887665\tbest: 1.0887665 (132)\ttotal: 19.7s\tremaining: 2m 8s\n",
            "133:\tlearn: 1.0527795\ttest: 1.0887100\tbest: 1.0887100 (133)\ttotal: 19.9s\tremaining: 2m 8s\n",
            "134:\tlearn: 1.0523199\ttest: 1.0886244\tbest: 1.0886244 (134)\ttotal: 20s\tremaining: 2m 8s\n",
            "135:\tlearn: 1.0519349\ttest: 1.0882077\tbest: 1.0882077 (135)\ttotal: 20.1s\tremaining: 2m 7s\n",
            "136:\tlearn: 1.0515291\ttest: 1.0879427\tbest: 1.0879427 (136)\ttotal: 20.3s\tremaining: 2m 7s\n",
            "137:\tlearn: 1.0510492\ttest: 1.0876854\tbest: 1.0876854 (137)\ttotal: 20.4s\tremaining: 2m 7s\n",
            "138:\tlearn: 1.0505887\ttest: 1.0876174\tbest: 1.0876174 (138)\ttotal: 20.5s\tremaining: 2m 7s\n",
            "139:\tlearn: 1.0501641\ttest: 1.0874785\tbest: 1.0874785 (139)\ttotal: 20.6s\tremaining: 2m 6s\n",
            "140:\tlearn: 1.0497571\ttest: 1.0872211\tbest: 1.0872211 (140)\ttotal: 20.8s\tremaining: 2m 6s\n",
            "141:\tlearn: 1.0492913\ttest: 1.0868007\tbest: 1.0868007 (141)\ttotal: 20.9s\tremaining: 2m 6s\n",
            "142:\tlearn: 1.0488682\ttest: 1.0865933\tbest: 1.0865933 (142)\ttotal: 21s\tremaining: 2m 6s\n",
            "143:\tlearn: 1.0484399\ttest: 1.0863841\tbest: 1.0863841 (143)\ttotal: 21.2s\tremaining: 2m 5s\n",
            "144:\tlearn: 1.0480150\ttest: 1.0863888\tbest: 1.0863841 (143)\ttotal: 21.3s\tremaining: 2m 5s\n",
            "145:\tlearn: 1.0476747\ttest: 1.0860722\tbest: 1.0860722 (145)\ttotal: 21.4s\tremaining: 2m 5s\n",
            "146:\tlearn: 1.0472712\ttest: 1.0858253\tbest: 1.0858253 (146)\ttotal: 21.6s\tremaining: 2m 5s\n",
            "147:\tlearn: 1.0468788\ttest: 1.0855132\tbest: 1.0855132 (147)\ttotal: 21.7s\tremaining: 2m 4s\n",
            "148:\tlearn: 1.0465471\ttest: 1.0853060\tbest: 1.0853060 (148)\ttotal: 21.8s\tremaining: 2m 4s\n",
            "149:\tlearn: 1.0461137\ttest: 1.0852851\tbest: 1.0852851 (149)\ttotal: 22s\tremaining: 2m 4s\n",
            "150:\tlearn: 1.0457182\ttest: 1.0848562\tbest: 1.0848562 (150)\ttotal: 22.1s\tremaining: 2m 4s\n",
            "151:\tlearn: 1.0452984\ttest: 1.0845782\tbest: 1.0845782 (151)\ttotal: 22.2s\tremaining: 2m 3s\n",
            "152:\tlearn: 1.0448210\ttest: 1.0844521\tbest: 1.0844521 (152)\ttotal: 22.4s\tremaining: 2m 3s\n",
            "153:\tlearn: 1.0443360\ttest: 1.0844858\tbest: 1.0844521 (152)\ttotal: 22.5s\tremaining: 2m 3s\n",
            "154:\tlearn: 1.0439507\ttest: 1.0842276\tbest: 1.0842276 (154)\ttotal: 22.6s\tremaining: 2m 3s\n",
            "155:\tlearn: 1.0435172\ttest: 1.0840129\tbest: 1.0840129 (155)\ttotal: 22.7s\tremaining: 2m 3s\n",
            "156:\tlearn: 1.0432005\ttest: 1.0838320\tbest: 1.0838320 (156)\ttotal: 22.9s\tremaining: 2m 2s\n",
            "157:\tlearn: 1.0428366\ttest: 1.0838296\tbest: 1.0838296 (157)\ttotal: 23s\tremaining: 2m 2s\n",
            "158:\tlearn: 1.0423696\ttest: 1.0836494\tbest: 1.0836494 (158)\ttotal: 23.1s\tremaining: 2m 2s\n",
            "159:\tlearn: 1.0418986\ttest: 1.0834417\tbest: 1.0834417 (159)\ttotal: 23.3s\tremaining: 2m 2s\n",
            "160:\tlearn: 1.0415295\ttest: 1.0829728\tbest: 1.0829728 (160)\ttotal: 23.4s\tremaining: 2m 1s\n",
            "161:\tlearn: 1.0411947\ttest: 1.0829609\tbest: 1.0829609 (161)\ttotal: 23.5s\tremaining: 2m 1s\n",
            "162:\tlearn: 1.0407716\ttest: 1.0826914\tbest: 1.0826914 (162)\ttotal: 23.7s\tremaining: 2m 1s\n",
            "163:\tlearn: 1.0403169\ttest: 1.0825957\tbest: 1.0825957 (163)\ttotal: 23.8s\tremaining: 2m 1s\n",
            "164:\tlearn: 1.0399754\ttest: 1.0825222\tbest: 1.0825222 (164)\ttotal: 23.9s\tremaining: 2m 1s\n",
            "165:\tlearn: 1.0395431\ttest: 1.0823699\tbest: 1.0823699 (165)\ttotal: 24.1s\tremaining: 2m\n",
            "166:\tlearn: 1.0391960\ttest: 1.0822777\tbest: 1.0822777 (166)\ttotal: 24.2s\tremaining: 2m\n",
            "167:\tlearn: 1.0388007\ttest: 1.0820955\tbest: 1.0820955 (167)\ttotal: 24.3s\tremaining: 2m\n",
            "168:\tlearn: 1.0384203\ttest: 1.0819241\tbest: 1.0819241 (168)\ttotal: 24.5s\tremaining: 2m\n",
            "169:\tlearn: 1.0379537\ttest: 1.0816012\tbest: 1.0816012 (169)\ttotal: 24.6s\tremaining: 2m\n",
            "170:\tlearn: 1.0375731\ttest: 1.0813673\tbest: 1.0813673 (170)\ttotal: 24.7s\tremaining: 1m 59s\n",
            "171:\tlearn: 1.0372124\ttest: 1.0811504\tbest: 1.0811504 (171)\ttotal: 24.8s\tremaining: 1m 59s\n",
            "172:\tlearn: 1.0366968\ttest: 1.0809765\tbest: 1.0809765 (172)\ttotal: 25s\tremaining: 1m 59s\n",
            "173:\tlearn: 1.0362950\ttest: 1.0805922\tbest: 1.0805922 (173)\ttotal: 25.1s\tremaining: 1m 59s\n",
            "174:\tlearn: 1.0359111\ttest: 1.0803365\tbest: 1.0803365 (174)\ttotal: 25.3s\tremaining: 1m 59s\n",
            "175:\tlearn: 1.0355690\ttest: 1.0800486\tbest: 1.0800486 (175)\ttotal: 25.4s\tremaining: 1m 58s\n",
            "176:\tlearn: 1.0353320\ttest: 1.0800365\tbest: 1.0800365 (176)\ttotal: 25.5s\tremaining: 1m 58s\n",
            "177:\tlearn: 1.0349696\ttest: 1.0801427\tbest: 1.0800365 (176)\ttotal: 25.6s\tremaining: 1m 58s\n",
            "178:\tlearn: 1.0345917\ttest: 1.0798813\tbest: 1.0798813 (178)\ttotal: 25.8s\tremaining: 1m 58s\n",
            "179:\tlearn: 1.0342166\ttest: 1.0798979\tbest: 1.0798813 (178)\ttotal: 25.9s\tremaining: 1m 57s\n",
            "180:\tlearn: 1.0338569\ttest: 1.0797857\tbest: 1.0797857 (180)\ttotal: 26s\tremaining: 1m 57s\n",
            "181:\tlearn: 1.0334724\ttest: 1.0796623\tbest: 1.0796623 (181)\ttotal: 26.2s\tremaining: 1m 57s\n",
            "182:\tlearn: 1.0330389\ttest: 1.0791724\tbest: 1.0791724 (182)\ttotal: 26.3s\tremaining: 1m 57s\n",
            "183:\tlearn: 1.0327094\ttest: 1.0791694\tbest: 1.0791694 (183)\ttotal: 26.4s\tremaining: 1m 57s\n",
            "184:\tlearn: 1.0324293\ttest: 1.0788369\tbest: 1.0788369 (184)\ttotal: 26.5s\tremaining: 1m 56s\n",
            "185:\tlearn: 1.0320650\ttest: 1.0789783\tbest: 1.0788369 (184)\ttotal: 26.7s\tremaining: 1m 56s\n",
            "186:\tlearn: 1.0316560\ttest: 1.0787275\tbest: 1.0787275 (186)\ttotal: 26.8s\tremaining: 1m 56s\n",
            "187:\tlearn: 1.0314412\ttest: 1.0787174\tbest: 1.0787174 (187)\ttotal: 26.9s\tremaining: 1m 56s\n",
            "188:\tlearn: 1.0310256\ttest: 1.0784154\tbest: 1.0784154 (188)\ttotal: 27.1s\tremaining: 1m 56s\n",
            "189:\tlearn: 1.0307280\ttest: 1.0784827\tbest: 1.0784154 (188)\ttotal: 27.2s\tremaining: 1m 55s\n",
            "190:\tlearn: 1.0304270\ttest: 1.0783162\tbest: 1.0783162 (190)\ttotal: 27.3s\tremaining: 1m 55s\n",
            "191:\tlearn: 1.0300691\ttest: 1.0784337\tbest: 1.0783162 (190)\ttotal: 27.4s\tremaining: 1m 55s\n",
            "192:\tlearn: 1.0297318\ttest: 1.0784792\tbest: 1.0783162 (190)\ttotal: 27.6s\tremaining: 1m 55s\n",
            "193:\tlearn: 1.0294757\ttest: 1.0783005\tbest: 1.0783005 (193)\ttotal: 27.7s\tremaining: 1m 55s\n",
            "194:\tlearn: 1.0290519\ttest: 1.0780506\tbest: 1.0780506 (194)\ttotal: 27.8s\tremaining: 1m 54s\n",
            "195:\tlearn: 1.0287174\ttest: 1.0776344\tbest: 1.0776344 (195)\ttotal: 28s\tremaining: 1m 54s\n",
            "196:\tlearn: 1.0284076\ttest: 1.0775433\tbest: 1.0775433 (196)\ttotal: 28.1s\tremaining: 1m 54s\n",
            "197:\tlearn: 1.0280524\ttest: 1.0773670\tbest: 1.0773670 (197)\ttotal: 28.2s\tremaining: 1m 54s\n",
            "198:\tlearn: 1.0277447\ttest: 1.0771771\tbest: 1.0771771 (198)\ttotal: 28.3s\tremaining: 1m 54s\n",
            "199:\tlearn: 1.0273757\ttest: 1.0768123\tbest: 1.0768123 (199)\ttotal: 28.5s\tremaining: 1m 53s\n",
            "200:\tlearn: 1.0270151\ttest: 1.0768696\tbest: 1.0768123 (199)\ttotal: 28.6s\tremaining: 1m 53s\n",
            "201:\tlearn: 1.0267405\ttest: 1.0768122\tbest: 1.0768122 (201)\ttotal: 28.7s\tremaining: 1m 53s\n",
            "202:\tlearn: 1.0264677\ttest: 1.0767024\tbest: 1.0767024 (202)\ttotal: 28.9s\tremaining: 1m 53s\n",
            "203:\tlearn: 1.0261282\ttest: 1.0766186\tbest: 1.0766186 (203)\ttotal: 29s\tremaining: 1m 53s\n",
            "204:\tlearn: 1.0257922\ttest: 1.0763190\tbest: 1.0763190 (204)\ttotal: 29.1s\tremaining: 1m 52s\n",
            "205:\tlearn: 1.0254236\ttest: 1.0761926\tbest: 1.0761926 (205)\ttotal: 29.3s\tremaining: 1m 52s\n",
            "206:\tlearn: 1.0250859\ttest: 1.0759511\tbest: 1.0759511 (206)\ttotal: 29.4s\tremaining: 1m 52s\n",
            "207:\tlearn: 1.0247781\ttest: 1.0758366\tbest: 1.0758366 (207)\ttotal: 29.5s\tremaining: 1m 52s\n",
            "208:\tlearn: 1.0244396\ttest: 1.0758491\tbest: 1.0758366 (207)\ttotal: 29.6s\tremaining: 1m 52s\n",
            "209:\tlearn: 1.0240936\ttest: 1.0756729\tbest: 1.0756729 (209)\ttotal: 29.8s\tremaining: 1m 52s\n",
            "210:\tlearn: 1.0237759\ttest: 1.0756412\tbest: 1.0756412 (210)\ttotal: 29.9s\tremaining: 1m 51s\n",
            "211:\tlearn: 1.0235119\ttest: 1.0755640\tbest: 1.0755640 (211)\ttotal: 30s\tremaining: 1m 51s\n",
            "212:\tlearn: 1.0231434\ttest: 1.0754903\tbest: 1.0754903 (212)\ttotal: 30.2s\tremaining: 1m 51s\n",
            "213:\tlearn: 1.0228552\ttest: 1.0754708\tbest: 1.0754708 (213)\ttotal: 30.3s\tremaining: 1m 51s\n",
            "214:\tlearn: 1.0226547\ttest: 1.0754931\tbest: 1.0754708 (213)\ttotal: 30.4s\tremaining: 1m 51s\n",
            "215:\tlearn: 1.0224129\ttest: 1.0754664\tbest: 1.0754664 (215)\ttotal: 30.6s\tremaining: 1m 50s\n",
            "216:\tlearn: 1.0221404\ttest: 1.0753814\tbest: 1.0753814 (216)\ttotal: 30.7s\tremaining: 1m 50s\n",
            "217:\tlearn: 1.0217665\ttest: 1.0753767\tbest: 1.0753767 (217)\ttotal: 30.8s\tremaining: 1m 50s\n",
            "218:\tlearn: 1.0214642\ttest: 1.0751569\tbest: 1.0751569 (218)\ttotal: 30.9s\tremaining: 1m 50s\n",
            "219:\tlearn: 1.0211054\ttest: 1.0750731\tbest: 1.0750731 (219)\ttotal: 31.1s\tremaining: 1m 50s\n",
            "220:\tlearn: 1.0207771\ttest: 1.0748936\tbest: 1.0748936 (220)\ttotal: 31.2s\tremaining: 1m 50s\n",
            "221:\tlearn: 1.0204888\ttest: 1.0750472\tbest: 1.0748936 (220)\ttotal: 31.4s\tremaining: 1m 49s\n",
            "222:\tlearn: 1.0202640\ttest: 1.0749285\tbest: 1.0748936 (220)\ttotal: 31.5s\tremaining: 1m 49s\n",
            "223:\tlearn: 1.0199266\ttest: 1.0746298\tbest: 1.0746298 (223)\ttotal: 31.6s\tremaining: 1m 49s\n",
            "224:\tlearn: 1.0196584\ttest: 1.0747053\tbest: 1.0746298 (223)\ttotal: 31.7s\tremaining: 1m 49s\n",
            "225:\tlearn: 1.0193622\ttest: 1.0745290\tbest: 1.0745290 (225)\ttotal: 31.9s\tremaining: 1m 49s\n",
            "226:\tlearn: 1.0190503\ttest: 1.0741915\tbest: 1.0741915 (226)\ttotal: 32s\tremaining: 1m 48s\n",
            "227:\tlearn: 1.0187242\ttest: 1.0740880\tbest: 1.0740880 (227)\ttotal: 32.1s\tremaining: 1m 48s\n",
            "228:\tlearn: 1.0183286\ttest: 1.0740597\tbest: 1.0740597 (228)\ttotal: 32.3s\tremaining: 1m 48s\n",
            "229:\tlearn: 1.0180642\ttest: 1.0740861\tbest: 1.0740597 (228)\ttotal: 32.4s\tremaining: 1m 48s\n",
            "230:\tlearn: 1.0177584\ttest: 1.0741038\tbest: 1.0740597 (228)\ttotal: 32.5s\tremaining: 1m 48s\n",
            "231:\tlearn: 1.0175336\ttest: 1.0740013\tbest: 1.0740013 (231)\ttotal: 32.7s\tremaining: 1m 48s\n",
            "232:\tlearn: 1.0173705\ttest: 1.0741911\tbest: 1.0740013 (231)\ttotal: 32.8s\tremaining: 1m 47s\n",
            "233:\tlearn: 1.0170950\ttest: 1.0739988\tbest: 1.0739988 (233)\ttotal: 32.9s\tremaining: 1m 47s\n",
            "234:\tlearn: 1.0168391\ttest: 1.0739688\tbest: 1.0739688 (234)\ttotal: 33s\tremaining: 1m 47s\n",
            "235:\tlearn: 1.0165688\ttest: 1.0740197\tbest: 1.0739688 (234)\ttotal: 33.2s\tremaining: 1m 47s\n",
            "236:\tlearn: 1.0162834\ttest: 1.0739567\tbest: 1.0739567 (236)\ttotal: 33.3s\tremaining: 1m 47s\n",
            "237:\tlearn: 1.0160691\ttest: 1.0739241\tbest: 1.0739241 (237)\ttotal: 33.4s\tremaining: 1m 47s\n",
            "238:\tlearn: 1.0157619\ttest: 1.0737646\tbest: 1.0737646 (238)\ttotal: 33.6s\tremaining: 1m 46s\n",
            "239:\tlearn: 1.0153887\ttest: 1.0737371\tbest: 1.0737371 (239)\ttotal: 33.7s\tremaining: 1m 46s\n",
            "240:\tlearn: 1.0152076\ttest: 1.0737939\tbest: 1.0737371 (239)\ttotal: 33.8s\tremaining: 1m 46s\n",
            "241:\tlearn: 1.0149320\ttest: 1.0736538\tbest: 1.0736538 (241)\ttotal: 34s\tremaining: 1m 46s\n",
            "242:\tlearn: 1.0146594\ttest: 1.0734023\tbest: 1.0734023 (242)\ttotal: 34.1s\tremaining: 1m 46s\n",
            "243:\tlearn: 1.0143313\ttest: 1.0731844\tbest: 1.0731844 (243)\ttotal: 34.2s\tremaining: 1m 45s\n",
            "244:\tlearn: 1.0139902\ttest: 1.0730810\tbest: 1.0730810 (244)\ttotal: 34.3s\tremaining: 1m 45s\n",
            "245:\tlearn: 1.0137588\ttest: 1.0728899\tbest: 1.0728899 (245)\ttotal: 34.5s\tremaining: 1m 45s\n",
            "246:\tlearn: 1.0135273\ttest: 1.0726865\tbest: 1.0726865 (246)\ttotal: 34.6s\tremaining: 1m 45s\n",
            "247:\tlearn: 1.0132763\ttest: 1.0726082\tbest: 1.0726082 (247)\ttotal: 34.7s\tremaining: 1m 45s\n",
            "248:\tlearn: 1.0129891\ttest: 1.0724930\tbest: 1.0724930 (248)\ttotal: 34.9s\tremaining: 1m 45s\n",
            "249:\tlearn: 1.0127190\ttest: 1.0721883\tbest: 1.0721883 (249)\ttotal: 35s\tremaining: 1m 44s\n",
            "250:\tlearn: 1.0124957\ttest: 1.0721047\tbest: 1.0721047 (250)\ttotal: 35.1s\tremaining: 1m 44s\n",
            "251:\tlearn: 1.0121788\ttest: 1.0721561\tbest: 1.0721047 (250)\ttotal: 35.2s\tremaining: 1m 44s\n",
            "252:\tlearn: 1.0119510\ttest: 1.0720823\tbest: 1.0720823 (252)\ttotal: 35.4s\tremaining: 1m 44s\n",
            "253:\tlearn: 1.0117176\ttest: 1.0719223\tbest: 1.0719223 (253)\ttotal: 35.5s\tremaining: 1m 44s\n",
            "254:\tlearn: 1.0114048\ttest: 1.0718364\tbest: 1.0718364 (254)\ttotal: 35.6s\tremaining: 1m 44s\n",
            "255:\tlearn: 1.0109934\ttest: 1.0717298\tbest: 1.0717298 (255)\ttotal: 35.8s\tremaining: 1m 43s\n",
            "256:\tlearn: 1.0107248\ttest: 1.0717196\tbest: 1.0717196 (256)\ttotal: 35.9s\tremaining: 1m 43s\n",
            "257:\tlearn: 1.0103947\ttest: 1.0715341\tbest: 1.0715341 (257)\ttotal: 36s\tremaining: 1m 43s\n",
            "258:\tlearn: 1.0101411\ttest: 1.0712961\tbest: 1.0712961 (258)\ttotal: 36.2s\tremaining: 1m 43s\n",
            "259:\tlearn: 1.0098738\ttest: 1.0711939\tbest: 1.0711939 (259)\ttotal: 36.3s\tremaining: 1m 43s\n",
            "260:\tlearn: 1.0095726\ttest: 1.0711819\tbest: 1.0711819 (260)\ttotal: 36.4s\tremaining: 1m 43s\n",
            "261:\tlearn: 1.0093914\ttest: 1.0711650\tbest: 1.0711650 (261)\ttotal: 36.6s\tremaining: 1m 42s\n",
            "262:\tlearn: 1.0092542\ttest: 1.0711595\tbest: 1.0711595 (262)\ttotal: 36.7s\tremaining: 1m 42s\n",
            "263:\tlearn: 1.0089748\ttest: 1.0712457\tbest: 1.0711595 (262)\ttotal: 36.8s\tremaining: 1m 42s\n",
            "264:\tlearn: 1.0087353\ttest: 1.0712583\tbest: 1.0711595 (262)\ttotal: 36.9s\tremaining: 1m 42s\n",
            "265:\tlearn: 1.0084457\ttest: 1.0712461\tbest: 1.0711595 (262)\ttotal: 37.1s\tremaining: 1m 42s\n",
            "266:\tlearn: 1.0081963\ttest: 1.0709698\tbest: 1.0709698 (266)\ttotal: 37.2s\tremaining: 1m 42s\n",
            "267:\tlearn: 1.0078824\ttest: 1.0709452\tbest: 1.0709452 (267)\ttotal: 37.3s\tremaining: 1m 41s\n",
            "268:\tlearn: 1.0076268\ttest: 1.0708286\tbest: 1.0708286 (268)\ttotal: 37.5s\tremaining: 1m 41s\n",
            "269:\tlearn: 1.0074106\ttest: 1.0707693\tbest: 1.0707693 (269)\ttotal: 37.6s\tremaining: 1m 41s\n",
            "270:\tlearn: 1.0071254\ttest: 1.0708728\tbest: 1.0707693 (269)\ttotal: 37.7s\tremaining: 1m 41s\n",
            "271:\tlearn: 1.0069824\ttest: 1.0708700\tbest: 1.0707693 (269)\ttotal: 37.8s\tremaining: 1m 41s\n",
            "272:\tlearn: 1.0066305\ttest: 1.0708822\tbest: 1.0707693 (269)\ttotal: 38s\tremaining: 1m 41s\n",
            "273:\tlearn: 1.0064154\ttest: 1.0708366\tbest: 1.0707693 (269)\ttotal: 38.1s\tremaining: 1m 40s\n",
            "274:\tlearn: 1.0061072\ttest: 1.0706422\tbest: 1.0706422 (274)\ttotal: 38.2s\tremaining: 1m 40s\n",
            "275:\tlearn: 1.0058855\ttest: 1.0703310\tbest: 1.0703310 (275)\ttotal: 38.4s\tremaining: 1m 40s\n",
            "276:\tlearn: 1.0055406\ttest: 1.0703772\tbest: 1.0703310 (275)\ttotal: 38.5s\tremaining: 1m 40s\n",
            "277:\tlearn: 1.0053575\ttest: 1.0703386\tbest: 1.0703310 (275)\ttotal: 38.6s\tremaining: 1m 40s\n",
            "278:\tlearn: 1.0051316\ttest: 1.0702039\tbest: 1.0702039 (278)\ttotal: 38.8s\tremaining: 1m 40s\n",
            "279:\tlearn: 1.0048642\ttest: 1.0702003\tbest: 1.0702003 (279)\ttotal: 38.9s\tremaining: 1m 40s\n",
            "280:\tlearn: 1.0045876\ttest: 1.0701772\tbest: 1.0701772 (280)\ttotal: 39s\tremaining: 1m 39s\n",
            "281:\tlearn: 1.0043218\ttest: 1.0701921\tbest: 1.0701772 (280)\ttotal: 39.2s\tremaining: 1m 39s\n",
            "282:\tlearn: 1.0041379\ttest: 1.0700312\tbest: 1.0700312 (282)\ttotal: 39.3s\tremaining: 1m 39s\n",
            "283:\tlearn: 1.0039602\ttest: 1.0701452\tbest: 1.0700312 (282)\ttotal: 39.4s\tremaining: 1m 39s\n",
            "284:\tlearn: 1.0038217\ttest: 1.0703306\tbest: 1.0700312 (282)\ttotal: 39.5s\tremaining: 1m 39s\n",
            "285:\tlearn: 1.0035710\ttest: 1.0702956\tbest: 1.0700312 (282)\ttotal: 39.7s\tremaining: 1m 39s\n",
            "286:\tlearn: 1.0032900\ttest: 1.0701977\tbest: 1.0700312 (282)\ttotal: 39.8s\tremaining: 1m 38s\n",
            "287:\tlearn: 1.0030366\ttest: 1.0699786\tbest: 1.0699786 (287)\ttotal: 39.9s\tremaining: 1m 38s\n",
            "288:\tlearn: 1.0028499\ttest: 1.0700864\tbest: 1.0699786 (287)\ttotal: 40.1s\tremaining: 1m 38s\n",
            "289:\tlearn: 1.0025739\ttest: 1.0700191\tbest: 1.0699786 (287)\ttotal: 40.2s\tremaining: 1m 38s\n",
            "290:\tlearn: 1.0024284\ttest: 1.0700067\tbest: 1.0699786 (287)\ttotal: 40.3s\tremaining: 1m 38s\n",
            "291:\tlearn: 1.0023191\ttest: 1.0699982\tbest: 1.0699786 (287)\ttotal: 40.5s\tremaining: 1m 38s\n",
            "292:\tlearn: 1.0020921\ttest: 1.0700978\tbest: 1.0699786 (287)\ttotal: 40.6s\tremaining: 1m 37s\n",
            "293:\tlearn: 1.0018252\ttest: 1.0699407\tbest: 1.0699407 (293)\ttotal: 40.7s\tremaining: 1m 37s\n",
            "294:\tlearn: 1.0015644\ttest: 1.0698850\tbest: 1.0698850 (294)\ttotal: 40.8s\tremaining: 1m 37s\n",
            "295:\tlearn: 1.0013183\ttest: 1.0696258\tbest: 1.0696258 (295)\ttotal: 41s\tremaining: 1m 37s\n",
            "296:\tlearn: 1.0011074\ttest: 1.0695932\tbest: 1.0695932 (296)\ttotal: 41.1s\tremaining: 1m 37s\n",
            "297:\tlearn: 1.0008581\ttest: 1.0695380\tbest: 1.0695380 (297)\ttotal: 41.2s\tremaining: 1m 37s\n",
            "298:\tlearn: 1.0005579\ttest: 1.0695547\tbest: 1.0695380 (297)\ttotal: 41.4s\tremaining: 1m 36s\n",
            "299:\tlearn: 1.0003055\ttest: 1.0692543\tbest: 1.0692543 (299)\ttotal: 41.5s\tremaining: 1m 36s\n",
            "300:\tlearn: 1.0000427\ttest: 1.0687960\tbest: 1.0687960 (300)\ttotal: 41.6s\tremaining: 1m 36s\n",
            "301:\tlearn: 0.9998339\ttest: 1.0688434\tbest: 1.0687960 (300)\ttotal: 41.8s\tremaining: 1m 36s\n",
            "302:\tlearn: 0.9995459\ttest: 1.0688617\tbest: 1.0687960 (300)\ttotal: 41.9s\tremaining: 1m 36s\n",
            "303:\tlearn: 0.9992863\ttest: 1.0688845\tbest: 1.0687960 (300)\ttotal: 42s\tremaining: 1m 36s\n",
            "304:\tlearn: 0.9989804\ttest: 1.0687535\tbest: 1.0687535 (304)\ttotal: 42.1s\tremaining: 1m 36s\n",
            "305:\tlearn: 0.9987268\ttest: 1.0686649\tbest: 1.0686649 (305)\ttotal: 42.3s\tremaining: 1m 35s\n",
            "306:\tlearn: 0.9984356\ttest: 1.0685574\tbest: 1.0685574 (306)\ttotal: 42.4s\tremaining: 1m 35s\n",
            "307:\tlearn: 0.9982260\ttest: 1.0685846\tbest: 1.0685574 (306)\ttotal: 42.5s\tremaining: 1m 35s\n",
            "308:\tlearn: 0.9980570\ttest: 1.0684544\tbest: 1.0684544 (308)\ttotal: 42.7s\tremaining: 1m 35s\n",
            "309:\tlearn: 0.9978564\ttest: 1.0684817\tbest: 1.0684544 (308)\ttotal: 42.8s\tremaining: 1m 35s\n",
            "310:\tlearn: 0.9975365\ttest: 1.0685563\tbest: 1.0684544 (308)\ttotal: 42.9s\tremaining: 1m 35s\n",
            "311:\tlearn: 0.9973192\ttest: 1.0683348\tbest: 1.0683348 (311)\ttotal: 43.1s\tremaining: 1m 34s\n",
            "312:\tlearn: 0.9970969\ttest: 1.0683368\tbest: 1.0683348 (311)\ttotal: 43.2s\tremaining: 1m 34s\n",
            "313:\tlearn: 0.9968072\ttest: 1.0683102\tbest: 1.0683102 (313)\ttotal: 43.3s\tremaining: 1m 34s\n",
            "314:\tlearn: 0.9966488\ttest: 1.0682797\tbest: 1.0682797 (314)\ttotal: 43.4s\tremaining: 1m 34s\n",
            "315:\tlearn: 0.9965375\ttest: 1.0682663\tbest: 1.0682663 (315)\ttotal: 43.6s\tremaining: 1m 34s\n",
            "316:\tlearn: 0.9963425\ttest: 1.0681838\tbest: 1.0681838 (316)\ttotal: 43.7s\tremaining: 1m 34s\n",
            "317:\tlearn: 0.9961746\ttest: 1.0681821\tbest: 1.0681821 (317)\ttotal: 43.8s\tremaining: 1m 34s\n",
            "318:\tlearn: 0.9959177\ttest: 1.0681482\tbest: 1.0681482 (318)\ttotal: 44s\tremaining: 1m 33s\n",
            "319:\tlearn: 0.9956923\ttest: 1.0680751\tbest: 1.0680751 (319)\ttotal: 44.1s\tremaining: 1m 33s\n",
            "320:\tlearn: 0.9954411\ttest: 1.0680468\tbest: 1.0680468 (320)\ttotal: 44.2s\tremaining: 1m 33s\n",
            "321:\tlearn: 0.9951960\ttest: 1.0679882\tbest: 1.0679882 (321)\ttotal: 44.3s\tremaining: 1m 33s\n",
            "322:\tlearn: 0.9950265\ttest: 1.0680481\tbest: 1.0679882 (321)\ttotal: 44.5s\tremaining: 1m 33s\n",
            "323:\tlearn: 0.9947998\ttest: 1.0679513\tbest: 1.0679513 (323)\ttotal: 44.6s\tremaining: 1m 33s\n",
            "324:\tlearn: 0.9945594\ttest: 1.0677181\tbest: 1.0677181 (324)\ttotal: 44.7s\tremaining: 1m 32s\n",
            "325:\tlearn: 0.9942996\ttest: 1.0677621\tbest: 1.0677181 (324)\ttotal: 44.9s\tremaining: 1m 32s\n",
            "326:\tlearn: 0.9941894\ttest: 1.0679996\tbest: 1.0677181 (324)\ttotal: 45s\tremaining: 1m 32s\n",
            "327:\tlearn: 0.9939861\ttest: 1.0678580\tbest: 1.0677181 (324)\ttotal: 45.1s\tremaining: 1m 32s\n",
            "328:\tlearn: 0.9937901\ttest: 1.0677302\tbest: 1.0677181 (324)\ttotal: 45.3s\tremaining: 1m 32s\n",
            "329:\tlearn: 0.9935726\ttest: 1.0675402\tbest: 1.0675402 (329)\ttotal: 45.4s\tremaining: 1m 32s\n",
            "330:\tlearn: 0.9934385\ttest: 1.0674093\tbest: 1.0674093 (330)\ttotal: 45.5s\tremaining: 1m 31s\n",
            "331:\tlearn: 0.9931282\ttest: 1.0673975\tbest: 1.0673975 (331)\ttotal: 45.7s\tremaining: 1m 31s\n",
            "332:\tlearn: 0.9929105\ttest: 1.0673051\tbest: 1.0673051 (332)\ttotal: 45.8s\tremaining: 1m 31s\n",
            "333:\tlearn: 0.9927393\ttest: 1.0671805\tbest: 1.0671805 (333)\ttotal: 45.9s\tremaining: 1m 31s\n",
            "334:\tlearn: 0.9924874\ttest: 1.0671086\tbest: 1.0671086 (334)\ttotal: 46s\tremaining: 1m 31s\n",
            "335:\tlearn: 0.9921516\ttest: 1.0671364\tbest: 1.0671086 (334)\ttotal: 46.2s\tremaining: 1m 31s\n",
            "336:\tlearn: 0.9918053\ttest: 1.0671139\tbest: 1.0671086 (334)\ttotal: 46.3s\tremaining: 1m 31s\n",
            "337:\tlearn: 0.9914895\ttest: 1.0670662\tbest: 1.0670662 (337)\ttotal: 46.4s\tremaining: 1m 30s\n",
            "338:\tlearn: 0.9912643\ttest: 1.0669834\tbest: 1.0669834 (338)\ttotal: 46.6s\tremaining: 1m 30s\n",
            "339:\tlearn: 0.9909458\ttest: 1.0669848\tbest: 1.0669834 (338)\ttotal: 46.7s\tremaining: 1m 30s\n",
            "340:\tlearn: 0.9906945\ttest: 1.0667604\tbest: 1.0667604 (340)\ttotal: 46.8s\tremaining: 1m 30s\n",
            "341:\tlearn: 0.9904528\ttest: 1.0666521\tbest: 1.0666521 (341)\ttotal: 47s\tremaining: 1m 30s\n",
            "342:\tlearn: 0.9901427\ttest: 1.0664366\tbest: 1.0664366 (342)\ttotal: 47.1s\tremaining: 1m 30s\n",
            "343:\tlearn: 0.9897908\ttest: 1.0663773\tbest: 1.0663773 (343)\ttotal: 47.2s\tremaining: 1m 30s\n",
            "344:\tlearn: 0.9895535\ttest: 1.0664174\tbest: 1.0663773 (343)\ttotal: 47.3s\tremaining: 1m 29s\n",
            "345:\tlearn: 0.9893798\ttest: 1.0664042\tbest: 1.0663773 (343)\ttotal: 47.5s\tremaining: 1m 29s\n",
            "346:\tlearn: 0.9891316\ttest: 1.0664133\tbest: 1.0663773 (343)\ttotal: 47.6s\tremaining: 1m 29s\n",
            "347:\tlearn: 0.9888404\ttest: 1.0664432\tbest: 1.0663773 (343)\ttotal: 47.7s\tremaining: 1m 29s\n",
            "348:\tlearn: 0.9886048\ttest: 1.0665104\tbest: 1.0663773 (343)\ttotal: 47.9s\tremaining: 1m 29s\n",
            "349:\tlearn: 0.9883581\ttest: 1.0665262\tbest: 1.0663773 (343)\ttotal: 48s\tremaining: 1m 29s\n",
            "350:\tlearn: 0.9881029\ttest: 1.0665900\tbest: 1.0663773 (343)\ttotal: 48.1s\tremaining: 1m 28s\n",
            "351:\tlearn: 0.9879132\ttest: 1.0664086\tbest: 1.0663773 (343)\ttotal: 48.3s\tremaining: 1m 28s\n",
            "352:\tlearn: 0.9877749\ttest: 1.0664270\tbest: 1.0663773 (343)\ttotal: 48.4s\tremaining: 1m 28s\n",
            "353:\tlearn: 0.9875276\ttest: 1.0662896\tbest: 1.0662896 (353)\ttotal: 48.5s\tremaining: 1m 28s\n",
            "354:\tlearn: 0.9872195\ttest: 1.0662787\tbest: 1.0662787 (354)\ttotal: 48.6s\tremaining: 1m 28s\n",
            "355:\tlearn: 0.9869961\ttest: 1.0663171\tbest: 1.0662787 (354)\ttotal: 48.8s\tremaining: 1m 28s\n",
            "356:\tlearn: 0.9868802\ttest: 1.0662983\tbest: 1.0662787 (354)\ttotal: 48.9s\tremaining: 1m 28s\n",
            "357:\tlearn: 0.9867162\ttest: 1.0663094\tbest: 1.0662787 (354)\ttotal: 49s\tremaining: 1m 27s\n",
            "358:\tlearn: 0.9864831\ttest: 1.0662671\tbest: 1.0662671 (358)\ttotal: 49.2s\tremaining: 1m 27s\n",
            "359:\tlearn: 0.9862233\ttest: 1.0661536\tbest: 1.0661536 (359)\ttotal: 49.3s\tremaining: 1m 27s\n",
            "360:\tlearn: 0.9861379\ttest: 1.0661474\tbest: 1.0661474 (360)\ttotal: 49.4s\tremaining: 1m 27s\n",
            "361:\tlearn: 0.9858342\ttest: 1.0659341\tbest: 1.0659341 (361)\ttotal: 49.6s\tremaining: 1m 27s\n",
            "362:\tlearn: 0.9856727\ttest: 1.0659459\tbest: 1.0659341 (361)\ttotal: 49.7s\tremaining: 1m 27s\n",
            "363:\tlearn: 0.9854343\ttest: 1.0658283\tbest: 1.0658283 (363)\ttotal: 49.8s\tremaining: 1m 27s\n",
            "364:\tlearn: 0.9851977\ttest: 1.0658842\tbest: 1.0658283 (363)\ttotal: 49.9s\tremaining: 1m 26s\n",
            "365:\tlearn: 0.9849928\ttest: 1.0657940\tbest: 1.0657940 (365)\ttotal: 50.1s\tremaining: 1m 26s\n",
            "366:\tlearn: 0.9847640\ttest: 1.0656963\tbest: 1.0656963 (366)\ttotal: 50.2s\tremaining: 1m 26s\n",
            "367:\tlearn: 0.9845787\ttest: 1.0656635\tbest: 1.0656635 (367)\ttotal: 50.3s\tremaining: 1m 26s\n",
            "368:\tlearn: 0.9843139\ttest: 1.0653552\tbest: 1.0653552 (368)\ttotal: 50.5s\tremaining: 1m 26s\n",
            "369:\tlearn: 0.9842207\ttest: 1.0653790\tbest: 1.0653552 (368)\ttotal: 50.6s\tremaining: 1m 26s\n",
            "370:\tlearn: 0.9841016\ttest: 1.0653803\tbest: 1.0653552 (368)\ttotal: 50.7s\tremaining: 1m 26s\n",
            "371:\tlearn: 0.9838903\ttest: 1.0654243\tbest: 1.0653552 (368)\ttotal: 50.9s\tremaining: 1m 25s\n",
            "372:\tlearn: 0.9836180\ttest: 1.0654374\tbest: 1.0653552 (368)\ttotal: 51s\tremaining: 1m 25s\n",
            "373:\tlearn: 0.9833969\ttest: 1.0654484\tbest: 1.0653552 (368)\ttotal: 51.1s\tremaining: 1m 25s\n",
            "374:\tlearn: 0.9832263\ttest: 1.0652812\tbest: 1.0652812 (374)\ttotal: 51.2s\tremaining: 1m 25s\n",
            "375:\tlearn: 0.9830198\ttest: 1.0652921\tbest: 1.0652812 (374)\ttotal: 51.4s\tremaining: 1m 25s\n",
            "376:\tlearn: 0.9828099\ttest: 1.0651952\tbest: 1.0651952 (376)\ttotal: 51.5s\tremaining: 1m 25s\n",
            "377:\tlearn: 0.9825796\ttest: 1.0651605\tbest: 1.0651605 (377)\ttotal: 51.6s\tremaining: 1m 24s\n",
            "378:\tlearn: 0.9824463\ttest: 1.0650138\tbest: 1.0650138 (378)\ttotal: 51.8s\tremaining: 1m 24s\n",
            "379:\tlearn: 0.9823201\ttest: 1.0651262\tbest: 1.0650138 (378)\ttotal: 51.9s\tremaining: 1m 24s\n",
            "380:\tlearn: 0.9821537\ttest: 1.0650570\tbest: 1.0650138 (378)\ttotal: 52s\tremaining: 1m 24s\n",
            "381:\tlearn: 0.9819447\ttest: 1.0651566\tbest: 1.0650138 (378)\ttotal: 52.2s\tremaining: 1m 24s\n",
            "382:\tlearn: 0.9816286\ttest: 1.0651681\tbest: 1.0650138 (378)\ttotal: 52.3s\tremaining: 1m 24s\n",
            "383:\tlearn: 0.9814110\ttest: 1.0650330\tbest: 1.0650138 (378)\ttotal: 52.4s\tremaining: 1m 24s\n",
            "384:\tlearn: 0.9811976\ttest: 1.0650896\tbest: 1.0650138 (378)\ttotal: 52.5s\tremaining: 1m 23s\n",
            "385:\tlearn: 0.9809793\ttest: 1.0650021\tbest: 1.0650021 (385)\ttotal: 52.7s\tremaining: 1m 23s\n",
            "386:\tlearn: 0.9808141\ttest: 1.0649913\tbest: 1.0649913 (386)\ttotal: 52.8s\tremaining: 1m 23s\n",
            "387:\tlearn: 0.9806142\ttest: 1.0648957\tbest: 1.0648957 (387)\ttotal: 52.9s\tremaining: 1m 23s\n",
            "388:\tlearn: 0.9804304\ttest: 1.0650252\tbest: 1.0648957 (387)\ttotal: 53.1s\tremaining: 1m 23s\n",
            "389:\tlearn: 0.9802249\ttest: 1.0650701\tbest: 1.0648957 (387)\ttotal: 53.2s\tremaining: 1m 23s\n",
            "390:\tlearn: 0.9799729\ttest: 1.0648972\tbest: 1.0648957 (387)\ttotal: 53.3s\tremaining: 1m 23s\n",
            "391:\tlearn: 0.9796884\ttest: 1.0647556\tbest: 1.0647556 (391)\ttotal: 53.5s\tremaining: 1m 22s\n",
            "392:\tlearn: 0.9794559\ttest: 1.0644852\tbest: 1.0644852 (392)\ttotal: 53.6s\tremaining: 1m 22s\n",
            "393:\tlearn: 0.9792184\ttest: 1.0646794\tbest: 1.0644852 (392)\ttotal: 53.7s\tremaining: 1m 22s\n",
            "394:\tlearn: 0.9790122\ttest: 1.0646597\tbest: 1.0644852 (392)\ttotal: 53.9s\tremaining: 1m 22s\n",
            "395:\tlearn: 0.9788151\ttest: 1.0645971\tbest: 1.0644852 (392)\ttotal: 54s\tremaining: 1m 22s\n",
            "396:\tlearn: 0.9786136\ttest: 1.0645049\tbest: 1.0644852 (392)\ttotal: 54.1s\tremaining: 1m 22s\n",
            "397:\tlearn: 0.9783982\ttest: 1.0642612\tbest: 1.0642612 (397)\ttotal: 54.3s\tremaining: 1m 22s\n",
            "398:\tlearn: 0.9781521\ttest: 1.0642707\tbest: 1.0642612 (397)\ttotal: 54.4s\tremaining: 1m 21s\n",
            "399:\tlearn: 0.9780533\ttest: 1.0642689\tbest: 1.0642612 (397)\ttotal: 54.5s\tremaining: 1m 21s\n",
            "400:\tlearn: 0.9779705\ttest: 1.0642669\tbest: 1.0642612 (397)\ttotal: 54.6s\tremaining: 1m 21s\n",
            "401:\tlearn: 0.9778536\ttest: 1.0642102\tbest: 1.0642102 (401)\ttotal: 54.8s\tremaining: 1m 21s\n",
            "402:\tlearn: 0.9776896\ttest: 1.0642974\tbest: 1.0642102 (401)\ttotal: 54.9s\tremaining: 1m 21s\n",
            "403:\tlearn: 0.9775547\ttest: 1.0644142\tbest: 1.0642102 (401)\ttotal: 55s\tremaining: 1m 21s\n",
            "404:\tlearn: 0.9774271\ttest: 1.0643500\tbest: 1.0642102 (401)\ttotal: 55.2s\tremaining: 1m 21s\n",
            "405:\tlearn: 0.9772473\ttest: 1.0644229\tbest: 1.0642102 (401)\ttotal: 55.3s\tremaining: 1m 20s\n",
            "406:\tlearn: 0.9770249\ttest: 1.0643406\tbest: 1.0642102 (401)\ttotal: 55.4s\tremaining: 1m 20s\n",
            "407:\tlearn: 0.9767781\ttest: 1.0641760\tbest: 1.0641760 (407)\ttotal: 55.5s\tremaining: 1m 20s\n",
            "408:\tlearn: 0.9765654\ttest: 1.0642015\tbest: 1.0641760 (407)\ttotal: 55.7s\tremaining: 1m 20s\n",
            "409:\tlearn: 0.9763502\ttest: 1.0642350\tbest: 1.0641760 (407)\ttotal: 55.8s\tremaining: 1m 20s\n",
            "410:\tlearn: 0.9761444\ttest: 1.0640941\tbest: 1.0640941 (410)\ttotal: 55.9s\tremaining: 1m 20s\n",
            "411:\tlearn: 0.9759569\ttest: 1.0640762\tbest: 1.0640762 (411)\ttotal: 56.1s\tremaining: 1m 20s\n",
            "412:\tlearn: 0.9757843\ttest: 1.0639865\tbest: 1.0639865 (412)\ttotal: 56.2s\tremaining: 1m 19s\n",
            "413:\tlearn: 0.9756612\ttest: 1.0641266\tbest: 1.0639865 (412)\ttotal: 56.3s\tremaining: 1m 19s\n",
            "414:\tlearn: 0.9754025\ttest: 1.0641598\tbest: 1.0639865 (412)\ttotal: 56.5s\tremaining: 1m 19s\n",
            "415:\tlearn: 0.9751776\ttest: 1.0640839\tbest: 1.0639865 (412)\ttotal: 56.6s\tremaining: 1m 19s\n",
            "416:\tlearn: 0.9749954\ttest: 1.0641453\tbest: 1.0639865 (412)\ttotal: 56.7s\tremaining: 1m 19s\n",
            "417:\tlearn: 0.9747590\ttest: 1.0638825\tbest: 1.0638825 (417)\ttotal: 56.9s\tremaining: 1m 19s\n",
            "418:\tlearn: 0.9745624\ttest: 1.0637666\tbest: 1.0637666 (418)\ttotal: 57s\tremaining: 1m 19s\n",
            "419:\tlearn: 0.9743784\ttest: 1.0638962\tbest: 1.0637666 (418)\ttotal: 57.1s\tremaining: 1m 18s\n",
            "420:\tlearn: 0.9741114\ttest: 1.0641032\tbest: 1.0637666 (418)\ttotal: 57.2s\tremaining: 1m 18s\n",
            "421:\tlearn: 0.9739297\ttest: 1.0640333\tbest: 1.0637666 (418)\ttotal: 57.4s\tremaining: 1m 18s\n",
            "422:\tlearn: 0.9738355\ttest: 1.0639886\tbest: 1.0637666 (418)\ttotal: 57.5s\tremaining: 1m 18s\n",
            "423:\tlearn: 0.9736609\ttest: 1.0639725\tbest: 1.0637666 (418)\ttotal: 57.6s\tremaining: 1m 18s\n",
            "424:\tlearn: 0.9734301\ttest: 1.0640858\tbest: 1.0637666 (418)\ttotal: 57.8s\tremaining: 1m 18s\n",
            "425:\tlearn: 0.9732220\ttest: 1.0640952\tbest: 1.0637666 (418)\ttotal: 57.9s\tremaining: 1m 18s\n",
            "426:\tlearn: 0.9730519\ttest: 1.0640732\tbest: 1.0637666 (418)\ttotal: 58s\tremaining: 1m 17s\n",
            "427:\tlearn: 0.9727922\ttest: 1.0640078\tbest: 1.0637666 (418)\ttotal: 58.2s\tremaining: 1m 17s\n",
            "428:\tlearn: 0.9727018\ttest: 1.0640263\tbest: 1.0637666 (418)\ttotal: 58.3s\tremaining: 1m 17s\n",
            "429:\tlearn: 0.9724804\ttest: 1.0639119\tbest: 1.0637666 (418)\ttotal: 58.4s\tremaining: 1m 17s\n",
            "430:\tlearn: 0.9722724\ttest: 1.0637331\tbest: 1.0637331 (430)\ttotal: 58.6s\tremaining: 1m 17s\n",
            "431:\tlearn: 0.9720597\ttest: 1.0636865\tbest: 1.0636865 (431)\ttotal: 58.7s\tremaining: 1m 17s\n",
            "432:\tlearn: 0.9719145\ttest: 1.0636897\tbest: 1.0636865 (431)\ttotal: 58.8s\tremaining: 1m 17s\n",
            "433:\tlearn: 0.9716896\ttest: 1.0636273\tbest: 1.0636273 (433)\ttotal: 59s\tremaining: 1m 16s\n",
            "434:\tlearn: 0.9714299\ttest: 1.0635488\tbest: 1.0635488 (434)\ttotal: 59.1s\tremaining: 1m 16s\n",
            "435:\tlearn: 0.9712668\ttest: 1.0633380\tbest: 1.0633380 (435)\ttotal: 59.2s\tremaining: 1m 16s\n",
            "436:\tlearn: 0.9710077\ttest: 1.0632773\tbest: 1.0632773 (436)\ttotal: 59.3s\tremaining: 1m 16s\n",
            "437:\tlearn: 0.9708448\ttest: 1.0632335\tbest: 1.0632335 (437)\ttotal: 59.5s\tremaining: 1m 16s\n",
            "438:\tlearn: 0.9707246\ttest: 1.0632036\tbest: 1.0632036 (438)\ttotal: 59.6s\tremaining: 1m 16s\n",
            "439:\tlearn: 0.9706081\ttest: 1.0631901\tbest: 1.0631901 (439)\ttotal: 59.7s\tremaining: 1m 16s\n",
            "440:\tlearn: 0.9704516\ttest: 1.0631381\tbest: 1.0631381 (440)\ttotal: 59.9s\tremaining: 1m 15s\n",
            "441:\tlearn: 0.9702428\ttest: 1.0632109\tbest: 1.0631381 (440)\ttotal: 60s\tremaining: 1m 15s\n",
            "442:\tlearn: 0.9699339\ttest: 1.0631967\tbest: 1.0631381 (440)\ttotal: 1m\tremaining: 1m 15s\n",
            "443:\tlearn: 0.9698524\ttest: 1.0632168\tbest: 1.0631381 (440)\ttotal: 1m\tremaining: 1m 15s\n",
            "444:\tlearn: 0.9696714\ttest: 1.0631125\tbest: 1.0631125 (444)\ttotal: 1m\tremaining: 1m 15s\n",
            "445:\tlearn: 0.9695684\ttest: 1.0631086\tbest: 1.0631086 (445)\ttotal: 1m\tremaining: 1m 15s\n",
            "446:\tlearn: 0.9693592\ttest: 1.0628353\tbest: 1.0628353 (446)\ttotal: 1m\tremaining: 1m 15s\n",
            "447:\tlearn: 0.9691423\ttest: 1.0628194\tbest: 1.0628194 (447)\ttotal: 1m\tremaining: 1m 14s\n",
            "448:\tlearn: 0.9688988\ttest: 1.0626763\tbest: 1.0626763 (448)\ttotal: 1m\tremaining: 1m 14s\n",
            "449:\tlearn: 0.9687136\ttest: 1.0627080\tbest: 1.0626763 (448)\ttotal: 1m 1s\tremaining: 1m 14s\n",
            "450:\tlearn: 0.9685193\ttest: 1.0625949\tbest: 1.0625949 (450)\ttotal: 1m 1s\tremaining: 1m 14s\n",
            "451:\tlearn: 0.9682892\ttest: 1.0623961\tbest: 1.0623961 (451)\ttotal: 1m 1s\tremaining: 1m 14s\n",
            "452:\tlearn: 0.9682111\ttest: 1.0623923\tbest: 1.0623923 (452)\ttotal: 1m 1s\tremaining: 1m 14s\n",
            "453:\tlearn: 0.9680194\ttest: 1.0623535\tbest: 1.0623535 (453)\ttotal: 1m 1s\tremaining: 1m 14s\n",
            "454:\tlearn: 0.9678375\ttest: 1.0623639\tbest: 1.0623535 (453)\ttotal: 1m 1s\tremaining: 1m 13s\n",
            "455:\tlearn: 0.9676451\ttest: 1.0623113\tbest: 1.0623113 (455)\ttotal: 1m 1s\tremaining: 1m 13s\n",
            "456:\tlearn: 0.9674936\ttest: 1.0622526\tbest: 1.0622526 (456)\ttotal: 1m 1s\tremaining: 1m 13s\n",
            "457:\tlearn: 0.9672709\ttest: 1.0623150\tbest: 1.0622526 (456)\ttotal: 1m 2s\tremaining: 1m 13s\n",
            "458:\tlearn: 0.9671208\ttest: 1.0622304\tbest: 1.0622304 (458)\ttotal: 1m 2s\tremaining: 1m 13s\n",
            "459:\tlearn: 0.9669348\ttest: 1.0622671\tbest: 1.0622304 (458)\ttotal: 1m 2s\tremaining: 1m 13s\n",
            "460:\tlearn: 0.9667732\ttest: 1.0623570\tbest: 1.0622304 (458)\ttotal: 1m 2s\tremaining: 1m 13s\n",
            "461:\tlearn: 0.9666735\ttest: 1.0622911\tbest: 1.0622304 (458)\ttotal: 1m 2s\tremaining: 1m 12s\n",
            "462:\tlearn: 0.9665226\ttest: 1.0622100\tbest: 1.0622100 (462)\ttotal: 1m 2s\tremaining: 1m 12s\n",
            "463:\tlearn: 0.9662554\ttest: 1.0622418\tbest: 1.0622100 (462)\ttotal: 1m 2s\tremaining: 1m 12s\n",
            "464:\tlearn: 0.9661555\ttest: 1.0622201\tbest: 1.0622100 (462)\ttotal: 1m 3s\tremaining: 1m 12s\n",
            "465:\tlearn: 0.9659920\ttest: 1.0621870\tbest: 1.0621870 (465)\ttotal: 1m 3s\tremaining: 1m 12s\n",
            "466:\tlearn: 0.9657839\ttest: 1.0619811\tbest: 1.0619811 (466)\ttotal: 1m 3s\tremaining: 1m 12s\n",
            "467:\tlearn: 0.9655146\ttest: 1.0618499\tbest: 1.0618499 (467)\ttotal: 1m 3s\tremaining: 1m 12s\n",
            "468:\tlearn: 0.9654113\ttest: 1.0618272\tbest: 1.0618272 (468)\ttotal: 1m 3s\tremaining: 1m 11s\n",
            "469:\tlearn: 0.9651763\ttest: 1.0618662\tbest: 1.0618272 (468)\ttotal: 1m 3s\tremaining: 1m 11s\n",
            "470:\tlearn: 0.9649652\ttest: 1.0616814\tbest: 1.0616814 (470)\ttotal: 1m 3s\tremaining: 1m 11s\n",
            "471:\tlearn: 0.9647534\ttest: 1.0618779\tbest: 1.0616814 (470)\ttotal: 1m 3s\tremaining: 1m 11s\n",
            "472:\tlearn: 0.9646667\ttest: 1.0619221\tbest: 1.0616814 (470)\ttotal: 1m 4s\tremaining: 1m 11s\n",
            "473:\tlearn: 0.9644584\ttest: 1.0617649\tbest: 1.0616814 (470)\ttotal: 1m 4s\tremaining: 1m 11s\n",
            "474:\tlearn: 0.9642086\ttest: 1.0617041\tbest: 1.0616814 (470)\ttotal: 1m 4s\tremaining: 1m 11s\n",
            "475:\tlearn: 0.9639950\ttest: 1.0617451\tbest: 1.0616814 (470)\ttotal: 1m 4s\tremaining: 1m 10s\n",
            "476:\tlearn: 0.9637630\ttest: 1.0616888\tbest: 1.0616814 (470)\ttotal: 1m 4s\tremaining: 1m 10s\n",
            "477:\tlearn: 0.9635259\ttest: 1.0616368\tbest: 1.0616368 (477)\ttotal: 1m 4s\tremaining: 1m 10s\n",
            "478:\tlearn: 0.9633750\ttest: 1.0616100\tbest: 1.0616100 (478)\ttotal: 1m 4s\tremaining: 1m 10s\n",
            "479:\tlearn: 0.9632476\ttest: 1.0616698\tbest: 1.0616100 (478)\ttotal: 1m 5s\tremaining: 1m 10s\n",
            "480:\tlearn: 0.9629288\ttest: 1.0615717\tbest: 1.0615717 (480)\ttotal: 1m 5s\tremaining: 1m 10s\n",
            "481:\tlearn: 0.9627382\ttest: 1.0615999\tbest: 1.0615717 (480)\ttotal: 1m 5s\tremaining: 1m 10s\n",
            "482:\tlearn: 0.9625092\ttest: 1.0615723\tbest: 1.0615717 (480)\ttotal: 1m 5s\tremaining: 1m 10s\n",
            "483:\tlearn: 0.9622445\ttest: 1.0614791\tbest: 1.0614791 (483)\ttotal: 1m 5s\tremaining: 1m 10s\n",
            "484:\tlearn: 0.9620401\ttest: 1.0615142\tbest: 1.0614791 (483)\ttotal: 1m 5s\tremaining: 1m 10s\n",
            "485:\tlearn: 0.9618954\ttest: 1.0615038\tbest: 1.0614791 (483)\ttotal: 1m 6s\tremaining: 1m 9s\n",
            "486:\tlearn: 0.9618162\ttest: 1.0615005\tbest: 1.0614791 (483)\ttotal: 1m 6s\tremaining: 1m 9s\n",
            "487:\tlearn: 0.9616141\ttest: 1.0613907\tbest: 1.0613907 (487)\ttotal: 1m 6s\tremaining: 1m 9s\n",
            "488:\tlearn: 0.9614920\ttest: 1.0613481\tbest: 1.0613481 (488)\ttotal: 1m 6s\tremaining: 1m 9s\n",
            "489:\tlearn: 0.9613625\ttest: 1.0613287\tbest: 1.0613287 (489)\ttotal: 1m 6s\tremaining: 1m 9s\n",
            "490:\tlearn: 0.9611522\ttest: 1.0611327\tbest: 1.0611327 (490)\ttotal: 1m 6s\tremaining: 1m 9s\n",
            "491:\tlearn: 0.9608701\ttest: 1.0610796\tbest: 1.0610796 (491)\ttotal: 1m 7s\tremaining: 1m 9s\n",
            "492:\tlearn: 0.9606715\ttest: 1.0610372\tbest: 1.0610372 (492)\ttotal: 1m 7s\tremaining: 1m 9s\n",
            "493:\tlearn: 0.9605737\ttest: 1.0610345\tbest: 1.0610345 (493)\ttotal: 1m 7s\tremaining: 1m 8s\n",
            "494:\tlearn: 0.9604209\ttest: 1.0610274\tbest: 1.0610274 (494)\ttotal: 1m 7s\tremaining: 1m 8s\n",
            "495:\tlearn: 0.9603113\ttest: 1.0609375\tbest: 1.0609375 (495)\ttotal: 1m 7s\tremaining: 1m 8s\n",
            "496:\tlearn: 0.9601611\ttest: 1.0608767\tbest: 1.0608767 (496)\ttotal: 1m 7s\tremaining: 1m 8s\n",
            "497:\tlearn: 0.9599474\ttest: 1.0607984\tbest: 1.0607984 (497)\ttotal: 1m 7s\tremaining: 1m 8s\n",
            "498:\tlearn: 0.9597226\ttest: 1.0609051\tbest: 1.0607984 (497)\ttotal: 1m 7s\tremaining: 1m 8s\n",
            "499:\tlearn: 0.9595849\ttest: 1.0608226\tbest: 1.0607984 (497)\ttotal: 1m 8s\tremaining: 1m 8s\n",
            "500:\tlearn: 0.9594083\ttest: 1.0607185\tbest: 1.0607185 (500)\ttotal: 1m 8s\tremaining: 1m 7s\n",
            "501:\tlearn: 0.9592308\ttest: 1.0607241\tbest: 1.0607185 (500)\ttotal: 1m 8s\tremaining: 1m 7s\n",
            "502:\tlearn: 0.9589733\ttest: 1.0606794\tbest: 1.0606794 (502)\ttotal: 1m 8s\tremaining: 1m 7s\n",
            "503:\tlearn: 0.9588881\ttest: 1.0606752\tbest: 1.0606752 (503)\ttotal: 1m 8s\tremaining: 1m 7s\n",
            "504:\tlearn: 0.9587190\ttest: 1.0606109\tbest: 1.0606109 (504)\ttotal: 1m 8s\tremaining: 1m 7s\n",
            "505:\tlearn: 0.9585039\ttest: 1.0605760\tbest: 1.0605760 (505)\ttotal: 1m 8s\tremaining: 1m 7s\n",
            "506:\tlearn: 0.9582609\ttest: 1.0606170\tbest: 1.0605760 (505)\ttotal: 1m 9s\tremaining: 1m 7s\n",
            "507:\tlearn: 0.9581377\ttest: 1.0605812\tbest: 1.0605760 (505)\ttotal: 1m 9s\tremaining: 1m 6s\n",
            "508:\tlearn: 0.9579370\ttest: 1.0606996\tbest: 1.0605760 (505)\ttotal: 1m 9s\tremaining: 1m 6s\n",
            "509:\tlearn: 0.9578355\ttest: 1.0609819\tbest: 1.0605760 (505)\ttotal: 1m 9s\tremaining: 1m 6s\n",
            "510:\tlearn: 0.9576789\ttest: 1.0609863\tbest: 1.0605760 (505)\ttotal: 1m 9s\tremaining: 1m 6s\n",
            "511:\tlearn: 0.9575588\ttest: 1.0609925\tbest: 1.0605760 (505)\ttotal: 1m 9s\tremaining: 1m 6s\n",
            "512:\tlearn: 0.9573617\ttest: 1.0609461\tbest: 1.0605760 (505)\ttotal: 1m 9s\tremaining: 1m 6s\n",
            "513:\tlearn: 0.9572682\ttest: 1.0609008\tbest: 1.0605760 (505)\ttotal: 1m 9s\tremaining: 1m 6s\n",
            "514:\tlearn: 0.9570278\ttest: 1.0607889\tbest: 1.0605760 (505)\ttotal: 1m 10s\tremaining: 1m 5s\n",
            "515:\tlearn: 0.9567728\ttest: 1.0606268\tbest: 1.0605760 (505)\ttotal: 1m 10s\tremaining: 1m 5s\n",
            "516:\tlearn: 0.9566798\ttest: 1.0606345\tbest: 1.0605760 (505)\ttotal: 1m 10s\tremaining: 1m 5s\n",
            "517:\tlearn: 0.9564551\ttest: 1.0605345\tbest: 1.0605345 (517)\ttotal: 1m 10s\tremaining: 1m 5s\n",
            "518:\tlearn: 0.9563790\ttest: 1.0605306\tbest: 1.0605306 (518)\ttotal: 1m 10s\tremaining: 1m 5s\n",
            "519:\tlearn: 0.9562276\ttest: 1.0606074\tbest: 1.0605306 (518)\ttotal: 1m 10s\tremaining: 1m 5s\n",
            "520:\tlearn: 0.9560316\ttest: 1.0605870\tbest: 1.0605306 (518)\ttotal: 1m 10s\tremaining: 1m 5s\n",
            "521:\tlearn: 0.9558298\ttest: 1.0604335\tbest: 1.0604335 (521)\ttotal: 1m 10s\tremaining: 1m 4s\n",
            "522:\tlearn: 0.9557319\ttest: 1.0604661\tbest: 1.0604335 (521)\ttotal: 1m 11s\tremaining: 1m 4s\n",
            "523:\tlearn: 0.9555082\ttest: 1.0604445\tbest: 1.0604335 (521)\ttotal: 1m 11s\tremaining: 1m 4s\n",
            "524:\tlearn: 0.9554241\ttest: 1.0604478\tbest: 1.0604335 (521)\ttotal: 1m 11s\tremaining: 1m 4s\n",
            "525:\tlearn: 0.9552320\ttest: 1.0604492\tbest: 1.0604335 (521)\ttotal: 1m 11s\tremaining: 1m 4s\n",
            "526:\tlearn: 0.9550294\ttest: 1.0604413\tbest: 1.0604335 (521)\ttotal: 1m 11s\tremaining: 1m 4s\n",
            "527:\tlearn: 0.9548183\ttest: 1.0602704\tbest: 1.0602704 (527)\ttotal: 1m 11s\tremaining: 1m 4s\n",
            "528:\tlearn: 0.9546483\ttest: 1.0602523\tbest: 1.0602523 (528)\ttotal: 1m 11s\tremaining: 1m 3s\n",
            "529:\tlearn: 0.9544685\ttest: 1.0601476\tbest: 1.0601476 (529)\ttotal: 1m 12s\tremaining: 1m 3s\n",
            "530:\tlearn: 0.9542950\ttest: 1.0600334\tbest: 1.0600334 (530)\ttotal: 1m 12s\tremaining: 1m 3s\n",
            "531:\tlearn: 0.9541040\ttest: 1.0599876\tbest: 1.0599876 (531)\ttotal: 1m 12s\tremaining: 1m 3s\n",
            "532:\tlearn: 0.9539193\ttest: 1.0599060\tbest: 1.0599060 (532)\ttotal: 1m 12s\tremaining: 1m 3s\n",
            "533:\tlearn: 0.9537461\ttest: 1.0599142\tbest: 1.0599060 (532)\ttotal: 1m 12s\tremaining: 1m 3s\n",
            "534:\tlearn: 0.9534868\ttest: 1.0598924\tbest: 1.0598924 (534)\ttotal: 1m 12s\tremaining: 1m 3s\n",
            "535:\tlearn: 0.9534013\ttest: 1.0598654\tbest: 1.0598654 (535)\ttotal: 1m 12s\tremaining: 1m 3s\n",
            "536:\tlearn: 0.9533250\ttest: 1.0599079\tbest: 1.0598654 (535)\ttotal: 1m 12s\tremaining: 1m 2s\n",
            "537:\tlearn: 0.9531445\ttest: 1.0598186\tbest: 1.0598186 (537)\ttotal: 1m 13s\tremaining: 1m 2s\n",
            "538:\tlearn: 0.9529648\ttest: 1.0598494\tbest: 1.0598186 (537)\ttotal: 1m 13s\tremaining: 1m 2s\n",
            "539:\tlearn: 0.9527967\ttest: 1.0598001\tbest: 1.0598001 (539)\ttotal: 1m 13s\tremaining: 1m 2s\n",
            "540:\tlearn: 0.9526292\ttest: 1.0597741\tbest: 1.0597741 (540)\ttotal: 1m 13s\tremaining: 1m 2s\n",
            "541:\tlearn: 0.9524329\ttest: 1.0596909\tbest: 1.0596909 (541)\ttotal: 1m 13s\tremaining: 1m 2s\n",
            "542:\tlearn: 0.9522627\ttest: 1.0596344\tbest: 1.0596344 (542)\ttotal: 1m 13s\tremaining: 1m 2s\n",
            "543:\tlearn: 0.9521683\ttest: 1.0595233\tbest: 1.0595233 (543)\ttotal: 1m 13s\tremaining: 1m 1s\n",
            "544:\tlearn: 0.9519615\ttest: 1.0594643\tbest: 1.0594643 (544)\ttotal: 1m 13s\tremaining: 1m 1s\n",
            "545:\tlearn: 0.9517811\ttest: 1.0596518\tbest: 1.0594643 (544)\ttotal: 1m 14s\tremaining: 1m 1s\n",
            "546:\tlearn: 0.9516408\ttest: 1.0596077\tbest: 1.0594643 (544)\ttotal: 1m 14s\tremaining: 1m 1s\n",
            "547:\tlearn: 0.9514104\ttest: 1.0597103\tbest: 1.0594643 (544)\ttotal: 1m 14s\tremaining: 1m 1s\n",
            "548:\tlearn: 0.9512682\ttest: 1.0596492\tbest: 1.0594643 (544)\ttotal: 1m 14s\tremaining: 1m 1s\n",
            "549:\tlearn: 0.9510527\ttest: 1.0597286\tbest: 1.0594643 (544)\ttotal: 1m 14s\tremaining: 1m 1s\n",
            "550:\tlearn: 0.9509697\ttest: 1.0597743\tbest: 1.0594643 (544)\ttotal: 1m 14s\tremaining: 1m\n",
            "551:\tlearn: 0.9508356\ttest: 1.0598280\tbest: 1.0594643 (544)\ttotal: 1m 14s\tremaining: 1m\n",
            "552:\tlearn: 0.9506879\ttest: 1.0598352\tbest: 1.0594643 (544)\ttotal: 1m 15s\tremaining: 1m\n",
            "553:\tlearn: 0.9504326\ttest: 1.0597462\tbest: 1.0594643 (544)\ttotal: 1m 15s\tremaining: 1m\n",
            "554:\tlearn: 0.9503193\ttest: 1.0597068\tbest: 1.0594643 (544)\ttotal: 1m 15s\tremaining: 1m\n",
            "555:\tlearn: 0.9501117\ttest: 1.0596433\tbest: 1.0594643 (544)\ttotal: 1m 15s\tremaining: 1m\n",
            "556:\tlearn: 0.9499467\ttest: 1.0595495\tbest: 1.0594643 (544)\ttotal: 1m 15s\tremaining: 1m\n",
            "557:\tlearn: 0.9497211\ttest: 1.0593723\tbest: 1.0593723 (557)\ttotal: 1m 15s\tremaining: 59.9s\n",
            "558:\tlearn: 0.9495150\ttest: 1.0591848\tbest: 1.0591848 (558)\ttotal: 1m 15s\tremaining: 59.8s\n",
            "559:\tlearn: 0.9493532\ttest: 1.0590701\tbest: 1.0590701 (559)\ttotal: 1m 15s\tremaining: 59.7s\n",
            "560:\tlearn: 0.9491627\ttest: 1.0590618\tbest: 1.0590618 (560)\ttotal: 1m 16s\tremaining: 59.5s\n",
            "561:\tlearn: 0.9490793\ttest: 1.0590896\tbest: 1.0590618 (560)\ttotal: 1m 16s\tremaining: 59.4s\n",
            "562:\tlearn: 0.9489657\ttest: 1.0590233\tbest: 1.0590233 (562)\ttotal: 1m 16s\tremaining: 59.2s\n",
            "563:\tlearn: 0.9487805\ttest: 1.0590635\tbest: 1.0590233 (562)\ttotal: 1m 16s\tremaining: 59.1s\n",
            "564:\tlearn: 0.9485670\ttest: 1.0590313\tbest: 1.0590233 (562)\ttotal: 1m 16s\tremaining: 59s\n",
            "565:\tlearn: 0.9483957\ttest: 1.0589955\tbest: 1.0589955 (565)\ttotal: 1m 16s\tremaining: 58.8s\n",
            "566:\tlearn: 0.9482132\ttest: 1.0589551\tbest: 1.0589551 (566)\ttotal: 1m 16s\tremaining: 58.7s\n",
            "567:\tlearn: 0.9481274\ttest: 1.0589530\tbest: 1.0589530 (567)\ttotal: 1m 16s\tremaining: 58.5s\n",
            "568:\tlearn: 0.9479481\ttest: 1.0588994\tbest: 1.0588994 (568)\ttotal: 1m 17s\tremaining: 58.4s\n",
            "569:\tlearn: 0.9478580\ttest: 1.0589166\tbest: 1.0588994 (568)\ttotal: 1m 17s\tremaining: 58.3s\n",
            "570:\tlearn: 0.9477425\ttest: 1.0588057\tbest: 1.0588057 (570)\ttotal: 1m 17s\tremaining: 58.1s\n",
            "571:\tlearn: 0.9474770\ttest: 1.0588997\tbest: 1.0588057 (570)\ttotal: 1m 17s\tremaining: 58s\n",
            "572:\tlearn: 0.9473384\ttest: 1.0588992\tbest: 1.0588057 (570)\ttotal: 1m 17s\tremaining: 57.8s\n",
            "573:\tlearn: 0.9471410\ttest: 1.0589057\tbest: 1.0588057 (570)\ttotal: 1m 17s\tremaining: 57.7s\n",
            "574:\tlearn: 0.9470610\ttest: 1.0588928\tbest: 1.0588057 (570)\ttotal: 1m 17s\tremaining: 57.6s\n",
            "575:\tlearn: 0.9468900\ttest: 1.0588333\tbest: 1.0588057 (570)\ttotal: 1m 18s\tremaining: 57.4s\n",
            "576:\tlearn: 0.9468156\ttest: 1.0588593\tbest: 1.0588057 (570)\ttotal: 1m 18s\tremaining: 57.3s\n",
            "577:\tlearn: 0.9465646\ttest: 1.0588390\tbest: 1.0588057 (570)\ttotal: 1m 18s\tremaining: 57.1s\n",
            "578:\tlearn: 0.9463182\ttest: 1.0588674\tbest: 1.0588057 (570)\ttotal: 1m 18s\tremaining: 57s\n",
            "579:\tlearn: 0.9462533\ttest: 1.0588691\tbest: 1.0588057 (570)\ttotal: 1m 18s\tremaining: 56.9s\n",
            "580:\tlearn: 0.9460863\ttest: 1.0588513\tbest: 1.0588057 (570)\ttotal: 1m 18s\tremaining: 56.7s\n",
            "581:\tlearn: 0.9458724\ttest: 1.0588187\tbest: 1.0588057 (570)\ttotal: 1m 18s\tremaining: 56.6s\n",
            "582:\tlearn: 0.9456439\ttest: 1.0587635\tbest: 1.0587635 (582)\ttotal: 1m 18s\tremaining: 56.5s\n",
            "583:\tlearn: 0.9454195\ttest: 1.0588126\tbest: 1.0587635 (582)\ttotal: 1m 19s\tremaining: 56.3s\n",
            "584:\tlearn: 0.9452826\ttest: 1.0587605\tbest: 1.0587605 (584)\ttotal: 1m 19s\tremaining: 56.2s\n",
            "585:\tlearn: 0.9451198\ttest: 1.0587827\tbest: 1.0587605 (584)\ttotal: 1m 19s\tremaining: 56s\n",
            "586:\tlearn: 0.9449039\ttest: 1.0588238\tbest: 1.0587605 (584)\ttotal: 1m 19s\tremaining: 55.9s\n",
            "587:\tlearn: 0.9448300\ttest: 1.0588186\tbest: 1.0587605 (584)\ttotal: 1m 19s\tremaining: 55.8s\n",
            "588:\tlearn: 0.9446073\ttest: 1.0587887\tbest: 1.0587605 (584)\ttotal: 1m 19s\tremaining: 55.6s\n",
            "589:\tlearn: 0.9445272\ttest: 1.0587831\tbest: 1.0587605 (584)\ttotal: 1m 19s\tremaining: 55.5s\n",
            "590:\tlearn: 0.9443163\ttest: 1.0587789\tbest: 1.0587605 (584)\ttotal: 1m 19s\tremaining: 55.3s\n",
            "591:\tlearn: 0.9441156\ttest: 1.0586375\tbest: 1.0586375 (591)\ttotal: 1m 20s\tremaining: 55.2s\n",
            "592:\tlearn: 0.9439404\ttest: 1.0586237\tbest: 1.0586237 (592)\ttotal: 1m 20s\tremaining: 55.1s\n",
            "593:\tlearn: 0.9437819\ttest: 1.0586057\tbest: 1.0586057 (593)\ttotal: 1m 20s\tremaining: 54.9s\n",
            "594:\tlearn: 0.9435684\ttest: 1.0587665\tbest: 1.0586057 (593)\ttotal: 1m 20s\tremaining: 54.8s\n",
            "595:\tlearn: 0.9433625\ttest: 1.0588717\tbest: 1.0586057 (593)\ttotal: 1m 20s\tremaining: 54.7s\n",
            "596:\tlearn: 0.9431658\ttest: 1.0588033\tbest: 1.0586057 (593)\ttotal: 1m 20s\tremaining: 54.5s\n",
            "597:\tlearn: 0.9429998\ttest: 1.0588496\tbest: 1.0586057 (593)\ttotal: 1m 20s\tremaining: 54.4s\n",
            "598:\tlearn: 0.9428604\ttest: 1.0587659\tbest: 1.0586057 (593)\ttotal: 1m 21s\tremaining: 54.2s\n",
            "599:\tlearn: 0.9427050\ttest: 1.0587790\tbest: 1.0586057 (593)\ttotal: 1m 21s\tremaining: 54.1s\n",
            "600:\tlearn: 0.9424666\ttest: 1.0588153\tbest: 1.0586057 (593)\ttotal: 1m 21s\tremaining: 54s\n",
            "601:\tlearn: 0.9421774\ttest: 1.0587912\tbest: 1.0586057 (593)\ttotal: 1m 21s\tremaining: 53.8s\n",
            "602:\tlearn: 0.9420368\ttest: 1.0588056\tbest: 1.0586057 (593)\ttotal: 1m 21s\tremaining: 53.7s\n",
            "603:\tlearn: 0.9419605\ttest: 1.0588077\tbest: 1.0586057 (593)\ttotal: 1m 21s\tremaining: 53.5s\n",
            "604:\tlearn: 0.9417994\ttest: 1.0588604\tbest: 1.0586057 (593)\ttotal: 1m 21s\tremaining: 53.4s\n",
            "605:\tlearn: 0.9416038\ttest: 1.0588886\tbest: 1.0586057 (593)\ttotal: 1m 21s\tremaining: 53.3s\n",
            "606:\tlearn: 0.9415372\ttest: 1.0589158\tbest: 1.0586057 (593)\ttotal: 1m 22s\tremaining: 53.1s\n",
            "607:\tlearn: 0.9413369\ttest: 1.0586665\tbest: 1.0586057 (593)\ttotal: 1m 22s\tremaining: 53s\n",
            "608:\tlearn: 0.9411760\ttest: 1.0585962\tbest: 1.0585962 (608)\ttotal: 1m 22s\tremaining: 52.9s\n",
            "609:\tlearn: 0.9410020\ttest: 1.0585030\tbest: 1.0585030 (609)\ttotal: 1m 22s\tremaining: 52.7s\n",
            "610:\tlearn: 0.9408013\ttest: 1.0585405\tbest: 1.0585030 (609)\ttotal: 1m 22s\tremaining: 52.6s\n",
            "611:\tlearn: 0.9406782\ttest: 1.0585127\tbest: 1.0585030 (609)\ttotal: 1m 22s\tremaining: 52.4s\n",
            "612:\tlearn: 0.9405097\ttest: 1.0585302\tbest: 1.0585030 (609)\ttotal: 1m 22s\tremaining: 52.3s\n",
            "613:\tlearn: 0.9404309\ttest: 1.0587957\tbest: 1.0585030 (609)\ttotal: 1m 22s\tremaining: 52.2s\n",
            "614:\tlearn: 0.9402234\ttest: 1.0586869\tbest: 1.0585030 (609)\ttotal: 1m 23s\tremaining: 52s\n",
            "615:\tlearn: 0.9400405\ttest: 1.0586335\tbest: 1.0585030 (609)\ttotal: 1m 23s\tremaining: 51.9s\n",
            "616:\tlearn: 0.9398873\ttest: 1.0585176\tbest: 1.0585030 (609)\ttotal: 1m 23s\tremaining: 51.8s\n",
            "617:\tlearn: 0.9397549\ttest: 1.0585080\tbest: 1.0585030 (609)\ttotal: 1m 23s\tremaining: 51.6s\n",
            "618:\tlearn: 0.9396164\ttest: 1.0584661\tbest: 1.0584661 (618)\ttotal: 1m 23s\tremaining: 51.5s\n",
            "619:\tlearn: 0.9393964\ttest: 1.0583674\tbest: 1.0583674 (619)\ttotal: 1m 23s\tremaining: 51.3s\n",
            "620:\tlearn: 0.9393221\ttest: 1.0583680\tbest: 1.0583674 (619)\ttotal: 1m 23s\tremaining: 51.2s\n",
            "621:\tlearn: 0.9391168\ttest: 1.0583488\tbest: 1.0583488 (621)\ttotal: 1m 24s\tremaining: 51.1s\n",
            "622:\tlearn: 0.9389009\ttest: 1.0583741\tbest: 1.0583488 (621)\ttotal: 1m 24s\tremaining: 50.9s\n",
            "623:\tlearn: 0.9387128\ttest: 1.0583671\tbest: 1.0583488 (621)\ttotal: 1m 24s\tremaining: 50.8s\n",
            "624:\tlearn: 0.9386562\ttest: 1.0583433\tbest: 1.0583433 (624)\ttotal: 1m 24s\tremaining: 50.7s\n",
            "625:\tlearn: 0.9384632\ttest: 1.0581600\tbest: 1.0581600 (625)\ttotal: 1m 24s\tremaining: 50.5s\n",
            "626:\tlearn: 0.9382051\ttest: 1.0582245\tbest: 1.0581600 (625)\ttotal: 1m 24s\tremaining: 50.4s\n",
            "627:\tlearn: 0.9381420\ttest: 1.0582436\tbest: 1.0581600 (625)\ttotal: 1m 24s\tremaining: 50.3s\n",
            "628:\tlearn: 0.9379774\ttest: 1.0582795\tbest: 1.0581600 (625)\ttotal: 1m 24s\tremaining: 50.1s\n",
            "629:\tlearn: 0.9379250\ttest: 1.0583302\tbest: 1.0581600 (625)\ttotal: 1m 25s\tremaining: 50s\n",
            "630:\tlearn: 0.9377981\ttest: 1.0583692\tbest: 1.0581600 (625)\ttotal: 1m 25s\tremaining: 49.8s\n",
            "631:\tlearn: 0.9376563\ttest: 1.0583443\tbest: 1.0581600 (625)\ttotal: 1m 25s\tremaining: 49.7s\n",
            "632:\tlearn: 0.9375890\ttest: 1.0583049\tbest: 1.0581600 (625)\ttotal: 1m 25s\tremaining: 49.6s\n",
            "633:\tlearn: 0.9373955\ttest: 1.0582361\tbest: 1.0581600 (625)\ttotal: 1m 25s\tremaining: 49.4s\n",
            "634:\tlearn: 0.9371668\ttest: 1.0580313\tbest: 1.0580313 (634)\ttotal: 1m 25s\tremaining: 49.3s\n",
            "635:\tlearn: 0.9369817\ttest: 1.0580154\tbest: 1.0580154 (635)\ttotal: 1m 25s\tremaining: 49.1s\n",
            "636:\tlearn: 0.9368303\ttest: 1.0580760\tbest: 1.0580154 (635)\ttotal: 1m 25s\tremaining: 49s\n",
            "637:\tlearn: 0.9366741\ttest: 1.0582794\tbest: 1.0580154 (635)\ttotal: 1m 26s\tremaining: 48.9s\n",
            "638:\tlearn: 0.9365064\ttest: 1.0582993\tbest: 1.0580154 (635)\ttotal: 1m 26s\tremaining: 48.7s\n",
            "639:\tlearn: 0.9363926\ttest: 1.0583436\tbest: 1.0580154 (635)\ttotal: 1m 26s\tremaining: 48.6s\n",
            "640:\tlearn: 0.9361858\ttest: 1.0583746\tbest: 1.0580154 (635)\ttotal: 1m 26s\tremaining: 48.5s\n",
            "641:\tlearn: 0.9359927\ttest: 1.0584011\tbest: 1.0580154 (635)\ttotal: 1m 26s\tremaining: 48.3s\n",
            "642:\tlearn: 0.9358225\ttest: 1.0583984\tbest: 1.0580154 (635)\ttotal: 1m 26s\tremaining: 48.2s\n",
            "643:\tlearn: 0.9357511\ttest: 1.0584499\tbest: 1.0580154 (635)\ttotal: 1m 26s\tremaining: 48s\n",
            "644:\tlearn: 0.9355429\ttest: 1.0583752\tbest: 1.0580154 (635)\ttotal: 1m 27s\tremaining: 47.9s\n",
            "645:\tlearn: 0.9353932\ttest: 1.0583012\tbest: 1.0580154 (635)\ttotal: 1m 27s\tremaining: 47.8s\n",
            "646:\tlearn: 0.9352268\ttest: 1.0581718\tbest: 1.0580154 (635)\ttotal: 1m 27s\tremaining: 47.6s\n",
            "647:\tlearn: 0.9350331\ttest: 1.0581484\tbest: 1.0580154 (635)\ttotal: 1m 27s\tremaining: 47.5s\n",
            "648:\tlearn: 0.9349057\ttest: 1.0580845\tbest: 1.0580154 (635)\ttotal: 1m 27s\tremaining: 47.4s\n",
            "649:\tlearn: 0.9347923\ttest: 1.0581098\tbest: 1.0580154 (635)\ttotal: 1m 27s\tremaining: 47.2s\n",
            "650:\tlearn: 0.9346551\ttest: 1.0580205\tbest: 1.0580154 (635)\ttotal: 1m 27s\tremaining: 47.1s\n",
            "651:\tlearn: 0.9344851\ttest: 1.0580194\tbest: 1.0580154 (635)\ttotal: 1m 27s\tremaining: 47s\n",
            "652:\tlearn: 0.9343246\ttest: 1.0579225\tbest: 1.0579225 (652)\ttotal: 1m 28s\tremaining: 46.8s\n",
            "653:\tlearn: 0.9341449\ttest: 1.0578467\tbest: 1.0578467 (653)\ttotal: 1m 28s\tremaining: 46.7s\n",
            "654:\tlearn: 0.9339476\ttest: 1.0578294\tbest: 1.0578294 (654)\ttotal: 1m 28s\tremaining: 46.5s\n",
            "655:\tlearn: 0.9337677\ttest: 1.0578068\tbest: 1.0578068 (655)\ttotal: 1m 28s\tremaining: 46.4s\n",
            "656:\tlearn: 0.9336226\ttest: 1.0577441\tbest: 1.0577441 (656)\ttotal: 1m 28s\tremaining: 46.3s\n",
            "657:\tlearn: 0.9335303\ttest: 1.0577534\tbest: 1.0577441 (656)\ttotal: 1m 28s\tremaining: 46.1s\n",
            "658:\tlearn: 0.9333444\ttest: 1.0576337\tbest: 1.0576337 (658)\ttotal: 1m 28s\tremaining: 46s\n",
            "659:\tlearn: 0.9332293\ttest: 1.0576619\tbest: 1.0576337 (658)\ttotal: 1m 29s\tremaining: 45.9s\n",
            "660:\tlearn: 0.9331514\ttest: 1.0576217\tbest: 1.0576217 (660)\ttotal: 1m 29s\tremaining: 45.7s\n",
            "661:\tlearn: 0.9330331\ttest: 1.0576829\tbest: 1.0576217 (660)\ttotal: 1m 29s\tremaining: 45.6s\n",
            "662:\tlearn: 0.9328201\ttest: 1.0577016\tbest: 1.0576217 (660)\ttotal: 1m 29s\tremaining: 45.4s\n",
            "663:\tlearn: 0.9326279\ttest: 1.0576372\tbest: 1.0576217 (660)\ttotal: 1m 29s\tremaining: 45.3s\n",
            "664:\tlearn: 0.9324716\ttest: 1.0575671\tbest: 1.0575671 (664)\ttotal: 1m 29s\tremaining: 45.2s\n",
            "665:\tlearn: 0.9323205\ttest: 1.0575701\tbest: 1.0575671 (664)\ttotal: 1m 29s\tremaining: 45s\n",
            "666:\tlearn: 0.9321324\ttest: 1.0575168\tbest: 1.0575168 (666)\ttotal: 1m 29s\tremaining: 44.9s\n",
            "667:\tlearn: 0.9319508\ttest: 1.0574720\tbest: 1.0574720 (667)\ttotal: 1m 30s\tremaining: 44.8s\n",
            "668:\tlearn: 0.9318684\ttest: 1.0574608\tbest: 1.0574608 (668)\ttotal: 1m 30s\tremaining: 44.6s\n",
            "669:\tlearn: 0.9317103\ttest: 1.0573973\tbest: 1.0573973 (669)\ttotal: 1m 30s\tremaining: 44.5s\n",
            "670:\tlearn: 0.9315149\ttest: 1.0572858\tbest: 1.0572858 (670)\ttotal: 1m 30s\tremaining: 44.4s\n",
            "671:\tlearn: 0.9313156\ttest: 1.0573051\tbest: 1.0572858 (670)\ttotal: 1m 30s\tremaining: 44.2s\n",
            "672:\tlearn: 0.9311688\ttest: 1.0572410\tbest: 1.0572410 (672)\ttotal: 1m 30s\tremaining: 44.1s\n",
            "673:\tlearn: 0.9310107\ttest: 1.0573370\tbest: 1.0572410 (672)\ttotal: 1m 30s\tremaining: 43.9s\n",
            "674:\tlearn: 0.9308286\ttest: 1.0572569\tbest: 1.0572410 (672)\ttotal: 1m 30s\tremaining: 43.8s\n",
            "675:\tlearn: 0.9306722\ttest: 1.0572566\tbest: 1.0572410 (672)\ttotal: 1m 31s\tremaining: 43.7s\n",
            "676:\tlearn: 0.9304881\ttest: 1.0572799\tbest: 1.0572410 (672)\ttotal: 1m 31s\tremaining: 43.5s\n",
            "677:\tlearn: 0.9303133\ttest: 1.0573175\tbest: 1.0572410 (672)\ttotal: 1m 31s\tremaining: 43.4s\n",
            "678:\tlearn: 0.9301289\ttest: 1.0572287\tbest: 1.0572287 (678)\ttotal: 1m 31s\tremaining: 43.3s\n",
            "679:\tlearn: 0.9300212\ttest: 1.0571640\tbest: 1.0571640 (679)\ttotal: 1m 31s\tremaining: 43.1s\n",
            "680:\tlearn: 0.9299602\ttest: 1.0571605\tbest: 1.0571605 (680)\ttotal: 1m 31s\tremaining: 43s\n",
            "681:\tlearn: 0.9298097\ttest: 1.0571583\tbest: 1.0571583 (681)\ttotal: 1m 31s\tremaining: 42.9s\n",
            "682:\tlearn: 0.9296188\ttest: 1.0571552\tbest: 1.0571552 (682)\ttotal: 1m 32s\tremaining: 42.7s\n",
            "683:\tlearn: 0.9294604\ttest: 1.0570906\tbest: 1.0570906 (683)\ttotal: 1m 32s\tremaining: 42.6s\n",
            "684:\tlearn: 0.9293479\ttest: 1.0570738\tbest: 1.0570738 (684)\ttotal: 1m 32s\tremaining: 42.4s\n",
            "685:\tlearn: 0.9292110\ttest: 1.0570873\tbest: 1.0570738 (684)\ttotal: 1m 32s\tremaining: 42.3s\n",
            "686:\tlearn: 0.9291468\ttest: 1.0571055\tbest: 1.0570738 (684)\ttotal: 1m 32s\tremaining: 42.2s\n",
            "687:\tlearn: 0.9289963\ttest: 1.0569869\tbest: 1.0569869 (687)\ttotal: 1m 32s\tremaining: 42s\n",
            "688:\tlearn: 0.9288460\ttest: 1.0570179\tbest: 1.0569869 (687)\ttotal: 1m 32s\tremaining: 41.9s\n",
            "689:\tlearn: 0.9286904\ttest: 1.0571175\tbest: 1.0569869 (687)\ttotal: 1m 32s\tremaining: 41.8s\n",
            "690:\tlearn: 0.9285197\ttest: 1.0570294\tbest: 1.0569869 (687)\ttotal: 1m 33s\tremaining: 41.6s\n",
            "691:\tlearn: 0.9282636\ttest: 1.0569735\tbest: 1.0569735 (691)\ttotal: 1m 33s\tremaining: 41.5s\n",
            "692:\tlearn: 0.9281826\ttest: 1.0569528\tbest: 1.0569528 (692)\ttotal: 1m 33s\tremaining: 41.4s\n",
            "693:\tlearn: 0.9279558\ttest: 1.0570540\tbest: 1.0569528 (692)\ttotal: 1m 33s\tremaining: 41.2s\n",
            "694:\tlearn: 0.9277764\ttest: 1.0571256\tbest: 1.0569528 (692)\ttotal: 1m 33s\tremaining: 41.1s\n",
            "695:\tlearn: 0.9275906\ttest: 1.0569773\tbest: 1.0569528 (692)\ttotal: 1m 33s\tremaining: 41s\n",
            "696:\tlearn: 0.9274335\ttest: 1.0569640\tbest: 1.0569528 (692)\ttotal: 1m 33s\tremaining: 40.8s\n",
            "697:\tlearn: 0.9271795\ttest: 1.0572268\tbest: 1.0569528 (692)\ttotal: 1m 34s\tremaining: 40.7s\n",
            "698:\tlearn: 0.9271273\ttest: 1.0572492\tbest: 1.0569528 (692)\ttotal: 1m 34s\tremaining: 40.5s\n",
            "699:\tlearn: 0.9270737\ttest: 1.0573068\tbest: 1.0569528 (692)\ttotal: 1m 34s\tremaining: 40.4s\n",
            "700:\tlearn: 0.9269434\ttest: 1.0572952\tbest: 1.0569528 (692)\ttotal: 1m 34s\tremaining: 40.3s\n",
            "701:\tlearn: 0.9268069\ttest: 1.0572490\tbest: 1.0569528 (692)\ttotal: 1m 34s\tremaining: 40.1s\n",
            "702:\tlearn: 0.9266339\ttest: 1.0571790\tbest: 1.0569528 (692)\ttotal: 1m 34s\tremaining: 40s\n",
            "703:\tlearn: 0.9264784\ttest: 1.0572075\tbest: 1.0569528 (692)\ttotal: 1m 34s\tremaining: 39.9s\n",
            "704:\tlearn: 0.9262945\ttest: 1.0571270\tbest: 1.0569528 (692)\ttotal: 1m 34s\tremaining: 39.7s\n",
            "705:\tlearn: 0.9261633\ttest: 1.0571511\tbest: 1.0569528 (692)\ttotal: 1m 35s\tremaining: 39.6s\n",
            "706:\tlearn: 0.9259582\ttest: 1.0572107\tbest: 1.0569528 (692)\ttotal: 1m 35s\tremaining: 39.5s\n",
            "707:\tlearn: 0.9258238\ttest: 1.0571721\tbest: 1.0569528 (692)\ttotal: 1m 35s\tremaining: 39.3s\n",
            "708:\tlearn: 0.9256763\ttest: 1.0573774\tbest: 1.0569528 (692)\ttotal: 1m 35s\tremaining: 39.2s\n",
            "709:\tlearn: 0.9255354\ttest: 1.0573970\tbest: 1.0569528 (692)\ttotal: 1m 35s\tremaining: 39.1s\n",
            "710:\tlearn: 0.9253163\ttest: 1.0575078\tbest: 1.0569528 (692)\ttotal: 1m 35s\tremaining: 38.9s\n",
            "711:\tlearn: 0.9252435\ttest: 1.0575053\tbest: 1.0569528 (692)\ttotal: 1m 35s\tremaining: 38.8s\n",
            "712:\tlearn: 0.9250891\ttest: 1.0573993\tbest: 1.0569528 (692)\ttotal: 1m 36s\tremaining: 38.6s\n",
            "713:\tlearn: 0.9249250\ttest: 1.0574500\tbest: 1.0569528 (692)\ttotal: 1m 36s\tremaining: 38.5s\n",
            "714:\tlearn: 0.9248462\ttest: 1.0574242\tbest: 1.0569528 (692)\ttotal: 1m 36s\tremaining: 38.4s\n",
            "715:\tlearn: 0.9247160\ttest: 1.0574259\tbest: 1.0569528 (692)\ttotal: 1m 36s\tremaining: 38.2s\n",
            "716:\tlearn: 0.9245269\ttest: 1.0574704\tbest: 1.0569528 (692)\ttotal: 1m 36s\tremaining: 38.1s\n",
            "717:\tlearn: 0.9243867\ttest: 1.0572816\tbest: 1.0569528 (692)\ttotal: 1m 36s\tremaining: 38s\n",
            "718:\tlearn: 0.9242427\ttest: 1.0572941\tbest: 1.0569528 (692)\ttotal: 1m 36s\tremaining: 37.8s\n",
            "719:\tlearn: 0.9240449\ttest: 1.0573985\tbest: 1.0569528 (692)\ttotal: 1m 36s\tremaining: 37.7s\n",
            "720:\tlearn: 0.9239761\ttest: 1.0573953\tbest: 1.0569528 (692)\ttotal: 1m 37s\tremaining: 37.6s\n",
            "721:\tlearn: 0.9237787\ttest: 1.0574880\tbest: 1.0569528 (692)\ttotal: 1m 37s\tremaining: 37.4s\n",
            "722:\tlearn: 0.9237336\ttest: 1.0574882\tbest: 1.0569528 (692)\ttotal: 1m 37s\tremaining: 37.3s\n",
            "723:\tlearn: 0.9236549\ttest: 1.0575337\tbest: 1.0569528 (692)\ttotal: 1m 37s\tremaining: 37.1s\n",
            "724:\tlearn: 0.9234925\ttest: 1.0575668\tbest: 1.0569528 (692)\ttotal: 1m 37s\tremaining: 37s\n",
            "Stopped by overfitting detector  (32 iterations wait)\n",
            "\n",
            "bestTest = 1.056952842\n",
            "bestIteration = 692\n",
            "\n",
            "Shrink model to first 693 iterations.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoost at 0x7f7a2488e820>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.get_all_params())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX-Ej6htjXm0",
        "outputId": "4795b2d1-c7a8-4b40-a779-d26af7189cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'nan_mode': 'Min', 'eval_metric': 'RMSE', 'iterations': 1000, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'od_pval': 0, 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 3, 'random_strength': 1, 'od_type': 'Iter', 'rsm': 1, 'boost_from_average': True, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': True, 'od_wait': 32, 'random_seed': 0, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'RMSE', 'learning_rate': 0.08685699850320816, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 1, 'bootstrap_type': 'MVS', 'max_leaves': 64}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CatBoost推論\n",
        "y_pred = model.predict(cb_test)\n",
        "y_pred = reval(y_pred)"
      ],
      "metadata": {
        "id": "2MfK-6E23JMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 書き込み\n",
        "f = open(\"CatBoost_顔文字あり_0.487.txt\", \"w\")\n",
        "for labeldata in y_pred:\n",
        "    f.write(str(labeldata))\n",
        "    f.write(\"\\n\")\n",
        "f.close()"
      ],
      "metadata": {
        "id": "llSLZM6g3OpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVR"
      ],
      "metadata": {
        "id": "u8n3CbgwzxjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sudachiによる正規化を行う関数を定義\n",
        "from sudachipy import Dictionary\n",
        "from sudachipy import SplitMode\n",
        "tokenizer = Dictionary(dict=\"full\").create()\n",
        "\n",
        "def sudachi(text):\n",
        "    after = list()\n",
        "    for token in tokenizer.tokenize(text, SplitMode.C):\n",
        "        word = token.normalized_form() # 正規化あり\n",
        "        pos = \" \".join(token.part_of_speech())\n",
        "        \n",
        "        if word.isnumeric():\n",
        "            word = '0'\n",
        "            \n",
        "        after.append(word)\n",
        "    return after"
      ],
      "metadata": {
        "id": "ksu4zTY20c2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 単語分割\n",
        "train_tokenize_svr = [] \n",
        "dev_tokenize_svr = []\n",
        "test_tokenize_svr = []\n",
        "\n",
        "tokenize(train_text_demoji, train_tokenize_svr)\n",
        "tokenize(dev_text_demoji, dev_tokenize_svr)\n",
        "tokenize(test_text_demoji, test_tokenize_svr)"
      ],
      "metadata": {
        "id": "GMHknbqS0hEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writefile(train_tokenize_svr, \"train.txt\")\n",
        "writefile(dev_tokenize_svr, \"dev.txt\")\n",
        "writefile(test_tokenize_svr, \"test.txt\")"
      ],
      "metadata": {
        "id": "oBk3vO4v0nFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"train.txt\", 'r') as f:\n",
        "    traintext = f.read().split(\"\\n\")\n",
        "    traintext = traintext[:-1]\n",
        "with open(\"test.txt\", 'r') as f:\n",
        "    testtext = f.read().split(\"\\n\")\n",
        "    testtext = testtext[:-1]\n",
        "with open(\"dev.txt\", 'r') as f:\n",
        "    devtext = f.read().split(\"\\n\")\n",
        "    devtext = devtext[:-1]\n",
        "\n",
        "vectorizer = TfidfVectorizer(smooth_idf=True, analyzer='char', norm='l1') \n",
        "\n",
        "x_train = vectorizer.fit_transform(traintext)\n",
        "x_test = vectorizer.transform(testtext)\n",
        "x_dev = vectorizer.transform(devtext)"
      ],
      "metadata": {
        "id": "lDq-35-n0zyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reval(somearray):\n",
        "    l = []\n",
        "    for x in somearray:\n",
        "        if x > 0.5:\n",
        "            l.append(2)\n",
        "        elif x > 0.2:\n",
        "            l.append(1)\n",
        "        elif x > -0.1:\n",
        "            l.append(0)\n",
        "        elif x > -0.5:\n",
        "            l.append(-1)\n",
        "        else:\n",
        "            l.append(-2)\n",
        "    return np.array(l)"
      ],
      "metadata": {
        "id": "s9qujtufz6jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "best_qwk = 0\n",
        "best_c = 1\n",
        "for c in [1]:\n",
        "    model = SVR(C=c, kernel='rbf')\n",
        "    model.fit(x_train, y_train)\n",
        "    y_pred = model.predict(x_dev)\n",
        "    y_pred = reval(y_pred)\n",
        "\n",
        "    qwk = cohen_kappa_score(y_dev, reval(y_pred), weights='quadratic')\n",
        "    if qwk > best_qwk:\n",
        "        best_qwk = qwk\n",
        "        best_c = c\n",
        "    print(\"QWK = %f  C = %s\" % (qwk, str(c)))\n",
        "print(\"最適なハイパーパラメタは C = %s\" % str(best_c))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faM1EsCV0Cdy",
        "outputId": "db13d917-a6b5-45b2-c63c-a31a45991f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QWK = 0.423606  C = 1\n",
            "最適なハイパーパラメタは C = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "vectorizer = TfidfVectorizer()かつsudachi full (C)\n",
        "正解率 = 0.396689  C = 0.1\n",
        "正解率 = 0.424051  C = 0.3\n",
        "正解率 = 0.427765  C = 0.35\n",
        "正解率 = 0.429773  C = 0.39\n",
        "正解率 = 0.432389  C = 0.4\n",
        "正解率 = 0.431393  C = 0.41\n",
        "正解率 = 0.428794  C = 0.45\n",
        "正解率 = 0.427562  C = 0.5\n",
        "正解率 = 0.426206  C = 0.55\n",
        "正解率 = 0.421077  C = 0.8\n",
        "正解率 = 0.423606  C = 1\n",
        "正解率 = 0.411558  C = 3\n",
        "正解率 = 0.406475  C = 5\n",
        "正解率 = 0.404217  C = 8\n",
        "正解率 = 0.399755  C = 10\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "4m7ftzPq08TU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SVR(C=best_c, kernel='rbf')\n",
        "model.fit(x_train, y_train)\n",
        "y_pred = model.predict(x_test)"
      ],
      "metadata": {
        "id": "foZKrXw00_I8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reval2(somearray):\n",
        "    l = []\n",
        "    for x in somearray:\n",
        "        if x > 0.8:\n",
        "            l.append(2)\n",
        "        elif x > 0.4:\n",
        "            l.append(1)\n",
        "        elif x > -0.15:\n",
        "            l.append(0)\n",
        "        elif x > -0.52:  #or 0.56\n",
        "            l.append(-1)\n",
        "        else:\n",
        "            l.append(-2)\n",
        "    return np.array(l)"
      ],
      "metadata": {
        "id": "Bm-kZMf-1BDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evalpath = \"SVR_c0.4_0.490.txt\"\n",
        "#回帰\n",
        "y_pred_ = reval2(y_pred)\n",
        "# 書き込み\n",
        "f = open(evalpath, \"w\")\n",
        "for labeldata in y_pred_:\n",
        "    f.write(str(labeldata))\n",
        "    f.write(\"\\n\")\n",
        "f.close()"
      ],
      "metadata": {
        "id": "IxKma3DE1Hzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#アンサンブル"
      ],
      "metadata": {
        "id": "MpPWNwGsvMJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = load_data(\"SVR_c0.4_0.490.txt\")\n",
        "y2 = load_data(\"CatBoost_顔文字あり_0.487.txt\")\n",
        "y3 = load_data(\"LightGBM_顔文字あり_num_lr0.05_c_small_0.499.txt\")"
      ],
      "metadata": {
        "id": "G6GXJXnExWF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ensreval(x):\n",
        "    if x >= 1.78:\n",
        "        num = 2\n",
        "    elif x >= 0.6: \n",
        "        num = 1\n",
        "    elif x >= -0.44:\n",
        "        num = 0\n",
        "    elif x >= -1:\n",
        "        num = -1\n",
        "    else:\n",
        "        num = -2\n",
        "    return num"
      ],
      "metadata": {
        "id": "1Tqc6gNIxr0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = [int(x) for x in y1]\n",
        "y2 = [int(x) for x in y2]\n",
        "y3 = [int(x) for x in y3]\n",
        "\n",
        "ens = []\n",
        "for i in range(len(y1)):\n",
        "    label = y1[i]*0.22 + y2[i]*0.27 + y3[i]*0.51\n",
        "    print(label)\n",
        "    ens.append(ensreval(label))\n",
        "\n",
        "# アンサンブル結果 書き込み\n",
        "f = open(\"ensemble_eval.txt\", \"w\")\n",
        "for labeldata in ens:\n",
        "    f.write(str(int(labeldata)))\n",
        "    f.write(\"\\n\")\n",
        "f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7OTMNptxvIs",
        "outputId": "f31df9c9-c652-46eb-e962-392a59ae9972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.24\n",
            "0.98\n",
            "-0.27\n",
            "0.98\n",
            "2.0\n",
            "0.71\n",
            "-0.22\n",
            "0.0\n",
            "0.51\n",
            "1.49\n",
            "0.24\n",
            "1.49\n",
            "0.78\n",
            "0.98\n",
            "-0.22\n",
            "2.0\n",
            "2.0\n",
            "2.0\n",
            "1.78\n",
            "0.24\n",
            "0.24\n",
            "0.53\n",
            "1.24\n",
            "-0.22\n",
            "1.02\n",
            "-0.47\n",
            "-0.78\n",
            "1.49\n",
            "0.030000000000000027\n",
            "-1.0\n",
            "-0.49\n",
            "0.73\n",
            "1.02\n",
            "-0.27\n",
            "-0.27\n",
            "2.0\n",
            "-0.51\n",
            "-0.24\n",
            "0.0\n",
            "0.24\n",
            "0.78\n",
            "0.020000000000000018\n",
            "0.47\n",
            "2.0\n",
            "1.78\n",
            "0.51\n",
            "1.0\n",
            "0.78\n",
            "-1.49\n",
            "-0.98\n",
            "1.73\n",
            "0.0\n",
            "-1.27\n",
            "-0.98\n",
            "1.27\n",
            "-1.49\n",
            "1.56\n",
            "-0.49\n",
            "-0.27\n",
            "1.51\n",
            "0.020000000000000018\n",
            "0.0\n",
            "0.51\n",
            "0.0\n",
            "0.98\n",
            "0.98\n",
            "-1.0\n",
            "1.24\n",
            "0.27\n",
            "-0.49\n",
            "0.98\n",
            "0.24\n",
            "0.76\n",
            "-0.27\n",
            "-0.27\n",
            "-0.49\n",
            "1.49\n",
            "2.0\n",
            "0.0\n",
            "1.51\n",
            "-1.49\n",
            "1.49\n",
            "-1.73\n",
            "-0.05000000000000002\n",
            "1.49\n",
            "-0.49\n",
            "-1.0\n",
            "-1.0\n",
            "1.51\n",
            "0.0\n",
            "0.73\n",
            "-2.0\n",
            "0.0\n",
            "0.0\n",
            "0.49\n",
            "-0.27\n",
            "0.0\n",
            "0.49\n",
            "-0.71\n",
            "0.020000000000000018\n",
            "2.0\n",
            "-0.020000000000000018\n",
            "0.27\n",
            "0.49\n",
            "-0.27\n",
            "-1.0\n",
            "1.56\n",
            "-0.78\n",
            "-0.25\n",
            "0.0\n",
            "-0.49\n",
            "-0.49\n",
            "2.0\n",
            "-1.0\n",
            "1.78\n",
            "0.98\n",
            "1.05\n",
            "0.78\n",
            "1.78\n",
            "-0.51\n",
            "2.0\n",
            "-1.49\n",
            "0.49\n",
            "-1.49\n",
            "1.78\n",
            "1.24\n",
            "-0.49\n",
            "2.0\n",
            "-0.22\n",
            "0.51\n",
            "-0.27\n",
            "-0.73\n",
            "1.27\n",
            "0.030000000000000027\n",
            "-1.27\n",
            "-0.71\n",
            "0.51\n",
            "1.02\n",
            "-1.49\n",
            "1.49\n",
            "1.49\n",
            "0.78\n",
            "0.24\n",
            "-0.98\n",
            "0.24\n",
            "2.0\n",
            "0.98\n",
            "1.49\n",
            "-0.49\n",
            "-1.0\n",
            "1.49\n",
            "0.24\n",
            "-0.47\n",
            "1.29\n",
            "0.49\n",
            "-0.98\n",
            "0.29000000000000004\n",
            "0.51\n",
            "0.24\n",
            "0.020000000000000018\n",
            "-0.51\n",
            "-0.22\n",
            "-0.25\n",
            "1.27\n",
            "-0.98\n",
            "0.51\n",
            "1.78\n",
            "2.0\n",
            "0.76\n",
            "0.51\n",
            "-0.22\n",
            "0.24\n",
            "0.8\n",
            "0.020000000000000018\n",
            "0.0\n",
            "0.24\n",
            "-1.49\n",
            "0.040000000000000036\n",
            "-1.0\n",
            "1.78\n",
            "-0.51\n",
            "-0.27\n",
            "-0.73\n",
            "-0.19999999999999996\n",
            "-0.71\n",
            "-0.27\n",
            "1.0\n",
            "0.98\n",
            "-0.29000000000000004\n",
            "0.73\n",
            "0.24\n",
            "0.27\n",
            "0.98\n",
            "0.24\n",
            "0.73\n",
            "1.51\n",
            "0.020000000000000018\n",
            "-0.49\n",
            "-0.51\n",
            "1.02\n",
            "0.73\n",
            "2.0\n",
            "-0.040000000000000036\n",
            "0.030000000000000027\n",
            "-0.51\n",
            "0.76\n",
            "-0.27\n",
            "0.020000000000000018\n",
            "0.73\n",
            "1.27\n",
            "-0.22\n",
            "-0.78\n",
            "1.78\n",
            "0.51\n",
            "-0.27\n",
            "-0.22\n",
            "1.49\n",
            "0.0\n",
            "-0.25\n",
            "-0.78\n",
            "1.22\n",
            "0.51\n",
            "1.73\n",
            "0.0\n",
            "0.78\n",
            "2.0\n",
            "0.25\n",
            "0.98\n",
            "-0.49\n",
            "-1.0\n",
            "0.020000000000000018\n",
            "1.49\n",
            "-0.29000000000000004\n",
            "0.45999999999999996\n",
            "1.51\n",
            "-1.0\n",
            "0.78\n",
            "-0.19999999999999996\n",
            "-0.020000000000000018\n",
            "1.49\n",
            "1.49\n",
            "1.51\n",
            "2.0\n",
            "0.0\n",
            "0.22\n",
            "0.49\n",
            "0.27\n",
            "-1.49\n",
            "1.78\n",
            "0.76\n",
            "0.27\n",
            "-0.47\n",
            "0.98\n",
            "-1.22\n",
            "-0.27\n",
            "-1.49\n",
            "2.0\n",
            "-0.98\n",
            "0.49\n",
            "-1.22\n",
            "-1.0\n",
            "-0.27\n",
            "0.0\n",
            "1.49\n",
            "-0.24\n",
            "-1.49\n",
            "-1.27\n",
            "0.29000000000000004\n",
            "0.26\n",
            "-0.27\n",
            "-0.98\n",
            "0.29000000000000004\n",
            "2.0\n",
            "0.29000000000000004\n",
            "-0.71\n",
            "0.76\n",
            "0.07\n",
            "1.27\n",
            "-0.98\n",
            "0.020000000000000018\n",
            "0.0\n",
            "0.24\n",
            "-0.49\n",
            "-0.49\n",
            "0.020000000000000018\n",
            "1.73\n",
            "2.0\n",
            "-0.73\n",
            "-0.24\n",
            "1.22\n",
            "2.0\n",
            "1.78\n",
            "-0.78\n",
            "0.29000000000000004\n",
            "0.73\n",
            "-0.49\n",
            "1.02\n",
            "0.73\n",
            "-0.49\n",
            "0.020000000000000018\n",
            "1.29\n",
            "-0.54\n",
            "0.31000000000000005\n",
            "1.78\n",
            "0.73\n",
            "0.98\n",
            "-0.49\n",
            "-0.78\n",
            "-0.98\n",
            "0.0\n",
            "-0.020000000000000018\n",
            "-0.71\n",
            "1.49\n",
            "-1.0\n",
            "0.51\n",
            "-0.51\n",
            "0.040000000000000036\n",
            "-0.49\n",
            "0.98\n",
            "-0.98\n",
            "0.51\n",
            "-0.98\n",
            "0.24\n",
            "0.51\n",
            "0.020000000000000018\n",
            "0.0\n",
            "1.49\n",
            "0.24\n",
            "-0.49\n",
            "1.05\n",
            "0.98\n",
            "2.0\n",
            "-0.49\n",
            "1.27\n",
            "0.51\n",
            "1.49\n",
            "0.78\n",
            "-0.020000000000000018\n",
            "0.98\n",
            "1.56\n",
            "0.98\n",
            "0.0\n",
            "0.51\n",
            "0.0\n",
            "-0.76\n",
            "0.020000000000000018\n",
            "0.71\n",
            "0.76\n",
            "2.0\n",
            "1.0\n",
            "0.020000000000000018\n",
            "-0.47\n",
            "-0.47\n",
            "-0.76\n",
            "-0.47\n",
            "1.27\n",
            "0.49\n",
            "0.75\n",
            "0.98\n",
            "1.78\n",
            "0.0\n",
            "0.22\n",
            "0.0\n",
            "1.02\n",
            "0.020000000000000018\n",
            "-1.0\n",
            "0.98\n",
            "1.78\n",
            "-1.0\n",
            "2.0\n",
            "0.25\n",
            "0.78\n",
            "-0.020000000000000018\n",
            "0.020000000000000018\n",
            "1.78\n",
            "1.27\n",
            "-0.22\n",
            "-0.73\n",
            "0.76\n",
            "1.02\n",
            "0.51\n",
            "-1.49\n",
            "-0.49\n",
            "0.47\n",
            "0.47\n",
            "-0.8\n",
            "0.73\n",
            "-0.27\n",
            "1.78\n",
            "0.29000000000000004\n",
            "1.05\n",
            "2.0\n",
            "1.0\n",
            "-1.49\n",
            "0.0\n",
            "0.27\n",
            "0.78\n",
            "-0.95\n",
            "0.78\n",
            "0.0\n",
            "0.73\n",
            "0.24\n",
            "2.0\n",
            "1.27\n",
            "-0.51\n",
            "-0.71\n",
            "0.51\n",
            "1.0\n",
            "0.51\n",
            "-0.73\n",
            "-0.76\n",
            "-0.22\n",
            "1.05\n",
            "-0.27\n",
            "0.51\n",
            "0.0\n",
            "2.0\n",
            "-0.49\n",
            "-0.71\n",
            "0.22\n",
            "0.51\n",
            "-0.76\n",
            "0.020000000000000018\n",
            "0.0\n",
            "0.78\n",
            "2.0\n",
            "1.51\n",
            "1.78\n",
            "-0.98\n",
            "-0.49\n",
            "0.76\n",
            "0.49\n",
            "1.78\n",
            "-1.29\n",
            "-0.030000000000000027\n",
            "0.75\n",
            "2.0\n",
            "-0.49\n",
            "-0.98\n",
            "0.49\n",
            "2.0\n",
            "0.020000000000000018\n",
            "0.0\n",
            "1.27\n",
            "-0.98\n",
            "1.51\n",
            "0.78\n",
            "-0.07\n",
            "-0.22\n",
            "-0.44\n",
            "1.02\n",
            "-0.71\n",
            "-0.51\n",
            "2.0\n",
            "-0.020000000000000018\n",
            "0.98\n",
            "-1.0\n",
            "0.24\n",
            "1.56\n",
            "0.24\n",
            "-0.19999999999999996\n",
            "1.27\n",
            "1.56\n",
            "2.0\n",
            "0.51\n",
            "-0.22\n",
            "1.27\n",
            "0.24\n",
            "0.98\n",
            "-0.020000000000000018\n",
            "0.020000000000000018\n",
            "1.22\n",
            "1.22\n",
            "-0.22\n",
            "0.0\n",
            "-0.98\n",
            "0.27\n",
            "0.51\n",
            "-1.27\n",
            "1.78\n",
            "1.78\n",
            "0.0\n",
            "-1.02\n",
            "0.51\n",
            "0.51\n",
            "-1.49\n",
            "0.51\n",
            "0.0\n",
            "0.54\n",
            "0.8\n",
            "0.78\n",
            "0.51\n",
            "0.49\n",
            "-1.49\n",
            "0.49\n",
            "2.0\n",
            "-0.51\n",
            "0.44\n",
            "0.51\n",
            "0.49\n",
            "1.29\n",
            "-1.49\n",
            "0.76\n",
            "-0.71\n",
            "1.73\n",
            "0.51\n",
            "-0.27\n",
            "1.49\n",
            "-1.73\n",
            "1.0\n",
            "-0.51\n",
            "-0.71\n",
            "-0.27\n",
            "0.78\n",
            "0.53\n",
            "-0.22\n",
            "-0.19999999999999996\n",
            "2.0\n",
            "-0.49\n",
            "0.29000000000000004\n",
            "0.47\n",
            "-1.51\n",
            "-0.51\n",
            "-0.49\n",
            "0.47\n",
            "0.51\n",
            "-0.22\n",
            "1.49\n",
            "-0.98\n",
            "-0.020000000000000018\n",
            "-0.71\n",
            "-0.51\n",
            "0.24\n",
            "-0.49\n",
            "-0.71\n",
            "0.75\n",
            "-0.27\n",
            "-0.98\n",
            "0.020000000000000018\n",
            "1.51\n",
            "0.0\n",
            "-1.27\n",
            "0.22\n",
            "1.78\n",
            "0.51\n",
            "0.22\n",
            "0.73\n",
            "1.78\n",
            "0.54\n",
            "0.98\n",
            "-0.27\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.020000000000000018\n",
            "-0.020000000000000018\n",
            "1.49\n",
            "-1.49\n",
            "-0.27\n",
            "-0.71\n",
            "-0.98\n",
            "2.0\n",
            "0.47\n",
            "0.51\n",
            "0.020000000000000018\n",
            "-0.49\n",
            "-1.49\n",
            "1.27\n",
            "1.56\n",
            "0.76\n",
            "-0.76\n",
            "2.0\n",
            "2.0\n",
            "0.78\n",
            "-0.54\n",
            "0.22\n",
            "0.98\n",
            "1.02\n",
            "0.0\n",
            "0.22\n",
            "0.0\n",
            "0.53\n",
            "-0.98\n",
            "-0.51\n",
            "1.02\n",
            "-0.78\n",
            "-1.02\n",
            "-1.22\n",
            "0.22\n",
            "1.78\n",
            "-1.78\n",
            "2.0\n",
            "0.44\n",
            "0.73\n",
            "1.49\n",
            "-1.02\n",
            "0.51\n",
            "0.24\n",
            "1.0\n",
            "-0.27\n",
            "0.07\n",
            "-0.49\n",
            "0.020000000000000018\n",
            "1.27\n",
            "0.22\n",
            "0.0\n",
            "-0.49\n",
            "-0.51\n",
            "2.0\n",
            "0.51\n",
            "0.49\n",
            "-1.49\n",
            "1.78\n",
            "0.51\n",
            "1.0\n",
            "-2.0\n",
            "-0.27\n",
            "0.020000000000000018\n",
            "-0.19999999999999996\n",
            "-0.49\n",
            "-0.49\n",
            "0.24\n",
            "0.98\n",
            "0.020000000000000018\n",
            "0.0\n",
            "-0.71\n",
            "0.98\n",
            "0.24\n",
            "1.29\n",
            "-0.49\n",
            "-0.76\n",
            "-1.49\n",
            "0.24\n",
            "-1.49\n",
            "0.51\n",
            "-1.0\n",
            "0.44\n",
            "1.0\n",
            "1.0\n",
            "-1.49\n",
            "2.0\n",
            "-0.27\n",
            "-1.22\n",
            "-0.76\n",
            "0.22\n",
            "-0.98\n",
            "-1.22\n",
            "0.0\n",
            "0.020000000000000018\n",
            "-0.22\n",
            "1.78\n",
            "0.0\n",
            "-1.0\n",
            "-0.51\n",
            "1.22\n",
            "2.0\n",
            "1.49\n",
            "2.0\n",
            "0.31000000000000005\n",
            "0.71\n",
            "0.31000000000000005\n",
            "-0.51\n",
            "1.24\n",
            "0.49\n",
            "0.98\n",
            "-1.0\n",
            "0.8\n",
            "0.020000000000000018\n",
            "0.51\n",
            "-0.49\n",
            "2.0\n",
            "0.29000000000000004\n",
            "0.0\n",
            "0.51\n",
            "-1.0\n",
            "0.51\n",
            "0.25\n",
            "0.73\n",
            "-0.27\n",
            "1.24\n",
            "0.51\n",
            "1.02\n",
            "2.0\n",
            "0.020000000000000018\n",
            "1.05\n",
            "0.51\n",
            "1.56\n",
            "-0.27\n",
            "0.78\n",
            "1.49\n",
            "0.24\n",
            "0.0\n",
            "-0.47\n",
            "-0.78\n",
            "-0.27\n",
            "2.0\n",
            "0.49\n",
            "-0.75\n",
            "2.0\n",
            "-0.27\n",
            "0.22\n",
            "1.0\n",
            "1.0\n",
            "1.24\n",
            "-0.27\n",
            "-1.49\n",
            "1.49\n",
            "1.78\n",
            "-0.19999999999999996\n",
            "0.24\n",
            "0.020000000000000018\n",
            "1.46\n",
            "-0.29000000000000004\n",
            "-0.27\n",
            "-0.98\n",
            "0.78\n",
            "0.76\n",
            "-0.27\n",
            "-0.020000000000000018\n",
            "0.51\n",
            "-1.49\n",
            "1.0\n",
            "1.49\n",
            "0.53\n",
            "-1.49\n",
            "2.0\n",
            "1.78\n",
            "-0.27\n",
            "1.56\n",
            "-1.27\n",
            "-0.78\n",
            "1.02\n",
            "-1.27\n",
            "0.0\n",
            "0.76\n",
            "1.22\n",
            "1.78\n",
            "0.31000000000000005\n",
            "0.020000000000000018\n",
            "1.0\n",
            "-0.22\n",
            "1.49\n",
            "0.22\n",
            "-0.29000000000000004\n",
            "-0.05000000000000002\n",
            "0.24\n",
            "0.0\n",
            "1.49\n",
            "0.76\n",
            "0.98\n",
            "-0.49\n",
            "1.46\n",
            "0.76\n",
            "0.98\n",
            "0.8\n",
            "1.22\n",
            "1.46\n",
            "-0.29000000000000004\n",
            "0.0\n",
            "2.0\n",
            "1.51\n",
            "0.0\n",
            "-0.49\n",
            "0.0\n",
            "0.0\n",
            "0.24\n",
            "1.02\n",
            "-0.47\n",
            "0.98\n",
            "-0.24\n",
            "-2.0\n",
            "0.76\n",
            "0.51\n",
            "1.49\n",
            "-1.27\n",
            "2.0\n",
            "-1.02\n",
            "-0.44\n",
            "-0.78\n",
            "0.0\n",
            "-0.29000000000000004\n",
            "0.040000000000000036\n",
            "1.22\n",
            "1.05\n",
            "0.78\n",
            "-0.07\n",
            "0.0\n",
            "-0.22\n",
            "0.0\n",
            "1.51\n",
            "2.0\n",
            "-0.22\n",
            "1.51\n",
            "-0.54\n",
            "0.0\n",
            "2.0\n",
            "-0.47\n",
            "-0.49\n",
            "1.0\n",
            "-1.0\n",
            "1.78\n",
            "-1.49\n",
            "-0.27\n",
            "0.95\n",
            "2.0\n",
            "-0.71\n",
            "0.0\n",
            "-0.98\n",
            "2.0\n",
            "-1.0\n",
            "0.51\n",
            "1.02\n",
            "1.49\n",
            "0.24\n",
            "-0.05000000000000002\n",
            "0.49\n",
            "2.0\n",
            "-1.0\n",
            "0.51\n",
            "0.24\n",
            "-0.76\n",
            "0.47\n",
            "0.27\n",
            "0.98\n",
            "1.0\n",
            "-0.98\n",
            "0.020000000000000018\n",
            "-0.71\n",
            "-0.49\n",
            "0.76\n",
            "0.040000000000000036\n",
            "-0.27\n",
            "0.71\n",
            "0.49\n",
            "0.49\n",
            "0.0\n",
            "0.51\n",
            "0.73\n",
            "1.78\n",
            "-1.49\n",
            "1.0\n",
            "1.0\n",
            "1.24\n",
            "0.8\n",
            "-0.98\n",
            "0.51\n",
            "0.0\n",
            "-0.71\n",
            "0.24\n",
            "-1.0\n",
            "2.0\n",
            "-1.29\n",
            "-0.49\n",
            "0.49\n",
            "0.0\n",
            "-0.54\n",
            "-0.76\n",
            "0.020000000000000018\n",
            "0.51\n",
            "0.75\n",
            "0.75\n",
            "0.51\n",
            "1.0\n",
            "1.05\n",
            "1.49\n",
            "2.0\n",
            "2.0\n",
            "1.27\n",
            "-0.49\n",
            "-0.78\n",
            "1.73\n",
            "-0.73\n",
            "-0.29000000000000004\n",
            "1.0\n",
            "1.51\n",
            "0.24\n",
            "0.0\n",
            "-0.27\n",
            "-0.49\n",
            "2.0\n",
            "0.49\n",
            "0.73\n",
            "0.47\n",
            "-0.22\n",
            "-0.71\n",
            "-0.98\n",
            "0.0\n",
            "-0.54\n",
            "2.0\n",
            "-0.27\n",
            "1.0\n",
            "0.71\n",
            "-1.49\n",
            "-0.78\n",
            "-0.27\n",
            "2.0\n",
            "0.19999999999999996\n",
            "1.56\n",
            "0.22\n",
            "-0.020000000000000018\n",
            "1.49\n",
            "0.0\n",
            "0.51\n",
            "1.78\n",
            "-1.73\n",
            "1.78\n",
            "0.44\n",
            "-0.22\n",
            "0.51\n",
            "0.24\n",
            "0.49\n",
            "0.0\n",
            "0.0\n",
            "1.24\n",
            "-0.98\n",
            "-0.47\n",
            "0.25\n",
            "-0.98\n",
            "-0.49\n",
            "-0.49\n",
            "2.0\n",
            "0.49\n",
            "1.49\n",
            "-1.0\n",
            "1.78\n",
            "0.27\n",
            "1.49\n",
            "0.27\n",
            "0.49\n",
            "0.0\n",
            "-0.98\n",
            "0.0\n",
            "1.29\n",
            "0.53\n",
            "1.51\n",
            "1.0\n",
            "-0.27\n",
            "2.0\n",
            "2.0\n",
            "0.51\n",
            "2.0\n",
            "0.73\n",
            "-1.49\n",
            "1.24\n",
            "0.47\n",
            "0.0\n",
            "-0.27\n",
            "1.49\n",
            "1.29\n",
            "0.44\n",
            "-1.49\n",
            "1.24\n",
            "1.78\n",
            "-2.0\n",
            "1.73\n",
            "-1.0\n",
            "-0.71\n",
            "-0.98\n",
            "0.78\n",
            "1.73\n",
            "-0.05000000000000002\n",
            "0.76\n",
            "2.0\n",
            "0.73\n",
            "-0.27\n",
            "0.27\n",
            "-1.0\n",
            "-0.98\n",
            "1.51\n",
            "0.75\n",
            "1.29\n",
            "-1.49\n",
            "0.73\n",
            "0.27\n",
            "2.0\n",
            "2.0\n",
            "1.49\n",
            "1.51\n",
            "0.49\n",
            "0.51\n",
            "-0.27\n",
            "0.22\n",
            "1.49\n",
            "1.02\n",
            "0.0\n",
            "-1.0\n",
            "1.49\n",
            "0.0\n",
            "0.0\n",
            "0.51\n",
            "0.51\n",
            "-0.47\n",
            "1.0\n",
            "2.0\n",
            "0.020000000000000018\n",
            "2.0\n",
            "-0.19999999999999996\n",
            "0.27\n",
            "-0.51\n",
            "-1.73\n",
            "0.76\n",
            "-1.49\n",
            "-0.05000000000000002\n",
            "0.24\n",
            "-0.98\n",
            "-0.71\n",
            "2.0\n",
            "1.0\n",
            "-0.56\n",
            "1.27\n",
            "-0.49\n",
            "1.22\n",
            "0.51\n",
            "-0.51\n",
            "2.0\n",
            "0.020000000000000018\n",
            "-0.27\n",
            "1.49\n",
            "-0.22\n",
            "0.47\n",
            "0.95\n",
            "-1.22\n",
            "-1.0\n",
            "-0.27\n",
            "1.49\n",
            "-1.49\n",
            "0.020000000000000018\n",
            "1.24\n",
            "-0.49\n",
            "0.71\n",
            "-0.51\n",
            "0.78\n",
            "2.0\n",
            "1.27\n",
            "2.0\n",
            "1.27\n",
            "1.78\n",
            "0.51\n",
            "1.49\n",
            "0.73\n",
            "2.0\n",
            "0.51\n",
            "1.24\n",
            "0.51\n",
            "0.24\n",
            "-1.0\n",
            "-0.27\n",
            "2.0\n",
            "0.51\n",
            "1.29\n",
            "-0.020000000000000018\n",
            "2.0\n",
            "0.24\n",
            "1.02\n",
            "0.22\n",
            "-0.19999999999999996\n",
            "1.02\n",
            "1.51\n",
            "1.49\n",
            "1.02\n",
            "1.78\n",
            "-0.76\n",
            "1.0\n",
            "1.73\n",
            "-0.78\n",
            "-0.22\n",
            "0.73\n",
            "-0.19999999999999996\n",
            "0.51\n",
            "-0.51\n",
            "0.71\n",
            "1.24\n",
            "1.78\n",
            "-0.78\n",
            "-1.0\n",
            "2.0\n",
            "0.22\n",
            "-2.0\n",
            "-0.8\n",
            "0.71\n",
            "0.75\n",
            "1.78\n",
            "1.27\n",
            "1.22\n",
            "-0.29000000000000004\n",
            "1.49\n",
            "-0.76\n",
            "1.05\n",
            "-0.73\n",
            "-0.54\n",
            "0.78\n",
            "0.0\n",
            "1.78\n",
            "-0.49\n",
            "1.24\n",
            "2.0\n",
            "1.0\n",
            "-0.51\n",
            "1.78\n",
            "-0.53\n",
            "-0.27\n",
            "0.49\n",
            "-0.27\n",
            "0.49\n",
            "0.22\n",
            "0.020000000000000018\n",
            "-0.49\n",
            "1.56\n",
            "0.51\n",
            "1.02\n",
            "0.24\n",
            "1.22\n",
            "1.05\n",
            "0.53\n",
            "0.020000000000000018\n",
            "1.02\n",
            "-0.49\n",
            "0.24\n",
            "-0.27\n",
            "0.78\n",
            "-0.98\n",
            "-0.49\n",
            "1.51\n",
            "0.73\n",
            "0.73\n",
            "-0.78\n",
            "1.0\n",
            "-0.49\n",
            "-0.98\n",
            "-1.49\n",
            "1.78\n",
            "-0.49\n",
            "0.78\n",
            "1.78\n",
            "2.0\n",
            "1.78\n",
            "1.22\n",
            "1.24\n",
            "1.78\n",
            "1.0\n",
            "0.76\n",
            "1.51\n",
            "-0.27\n",
            "0.22\n",
            "1.0\n",
            "-0.98\n",
            "-1.0\n",
            "1.02\n",
            "-0.26\n",
            "0.24\n",
            "0.51\n",
            "-0.27\n",
            "0.0\n",
            "0.73\n",
            "1.78\n",
            "1.27\n",
            "-0.56\n",
            "0.0\n",
            "0.020000000000000018\n",
            "0.76\n",
            "-0.25\n",
            "0.73\n",
            "-0.040000000000000036\n",
            "2.0\n",
            "0.71\n",
            "2.0\n",
            "-0.29000000000000004\n",
            "0.020000000000000018\n",
            "1.24\n",
            "0.020000000000000018\n",
            "0.22\n",
            "0.0\n",
            "0.51\n",
            "-0.49\n",
            "1.29\n",
            "0.0\n",
            "0.76\n",
            "-0.27\n",
            "1.27\n",
            "0.31000000000000005\n",
            "0.040000000000000036\n",
            "-1.49\n",
            "0.29000000000000004\n",
            "1.29\n",
            "2.0\n",
            "-0.040000000000000036\n",
            "0.51\n",
            "0.0\n",
            "0.49\n",
            "0.78\n",
            "0.27\n",
            "-0.27\n",
            "0.98\n",
            "2.0\n",
            "-0.49\n",
            "1.51\n",
            "-0.27\n",
            "-0.49\n",
            "0.29000000000000004\n",
            "0.27\n",
            "1.24\n",
            "0.24\n",
            "0.98\n",
            "2.0\n",
            "-0.27\n",
            "0.24\n",
            "-1.49\n",
            "1.27\n",
            "0.75\n",
            "-0.27\n",
            "1.51\n",
            "-0.71\n",
            "-1.27\n",
            "0.0\n",
            "-0.49\n",
            "2.0\n",
            "0.73\n",
            "0.78\n",
            "-0.27\n",
            "1.78\n",
            "0.22\n",
            "-0.49\n",
            "0.78\n",
            "-0.05000000000000002\n",
            "-1.49\n",
            "-0.44\n",
            "-0.27\n",
            "1.49\n",
            "-0.98\n",
            "0.0\n",
            "0.22\n",
            "-0.73\n",
            "-0.78\n",
            "-0.98\n",
            "2.0\n",
            "-0.98\n",
            "-0.49\n",
            "-0.24\n",
            "0.24\n",
            "-0.030000000000000027\n",
            "0.22\n",
            "0.24\n",
            "0.49\n",
            "1.24\n",
            "-1.51\n",
            "1.51\n",
            "0.98\n",
            "-0.51\n",
            "2.0\n",
            "-0.71\n",
            "0.25\n",
            "0.0\n",
            "-0.47\n",
            "-0.98\n",
            "0.0\n",
            "1.78\n",
            "1.27\n",
            "0.22\n",
            "1.02\n",
            "2.0\n",
            "-1.49\n",
            "-1.49\n",
            "-0.71\n",
            "-0.51\n",
            "0.040000000000000036\n",
            "0.73\n",
            "0.75\n",
            "2.0\n",
            "1.51\n",
            "2.0\n",
            "-0.49\n",
            "0.51\n",
            "0.78\n",
            "-0.19999999999999996\n",
            "1.49\n",
            "0.95\n",
            "1.0\n",
            "0.53\n",
            "2.0\n",
            "0.0\n",
            "0.76\n",
            "1.78\n",
            "-0.27\n",
            "-1.22\n",
            "0.78\n",
            "0.98\n",
            "1.0\n",
            "-0.22\n",
            "1.27\n",
            "0.22\n",
            "2.0\n",
            "2.0\n",
            "0.51\n",
            "-0.27\n",
            "0.51\n",
            "0.0\n",
            "0.51\n",
            "0.31000000000000005\n",
            "1.24\n",
            "-0.49\n",
            "0.78\n",
            "0.0\n",
            "1.49\n",
            "0.98\n",
            "-0.49\n",
            "0.71\n",
            "0.98\n",
            "0.0\n",
            "0.76\n",
            "0.020000000000000018\n",
            "0.51\n",
            "-0.98\n",
            "-1.51\n",
            "0.22\n",
            "0.44\n",
            "1.27\n",
            "0.76\n",
            "0.0\n",
            "-0.73\n",
            "0.73\n",
            "1.02\n",
            "-1.49\n",
            "2.0\n",
            "-0.27\n",
            "0.51\n",
            "0.51\n",
            "-0.020000000000000018\n",
            "1.02\n",
            "0.0\n",
            "0.07\n",
            "-1.49\n",
            "1.27\n",
            "0.0\n",
            "2.0\n",
            "-0.98\n",
            "-0.27\n",
            "0.24\n",
            "0.25\n",
            "-1.27\n",
            "1.49\n",
            "-0.49\n",
            "0.51\n",
            "1.49\n",
            "0.73\n",
            "1.24\n",
            "-0.19999999999999996\n",
            "-0.51\n",
            "0.24\n",
            "0.49\n",
            "0.020000000000000018\n",
            "1.24\n",
            "0.22\n",
            "2.0\n",
            "0.73\n",
            "1.73\n",
            "0.0\n",
            "0.98\n",
            "-0.49\n",
            "0.54\n",
            "0.22\n",
            "0.040000000000000036\n",
            "-0.47\n",
            "0.76\n",
            "1.49\n",
            "-0.49\n",
            "1.78\n",
            "1.78\n",
            "-0.27\n",
            "-0.78\n",
            "-0.27\n",
            "-0.49\n",
            "0.51\n",
            "0.76\n",
            "0.24\n",
            "-0.49\n",
            "-0.51\n",
            "1.51\n",
            "0.29000000000000004\n",
            "1.24\n",
            "0.49\n",
            "0.45999999999999996\n",
            "0.0\n",
            "1.49\n",
            "-1.49\n",
            "0.54\n",
            "-0.73\n",
            "1.02\n",
            "1.29\n",
            "0.020000000000000018\n",
            "-0.49\n",
            "-0.27\n",
            "1.49\n",
            "0.24\n",
            "-0.47\n",
            "1.0\n",
            "1.02\n",
            "1.05\n",
            "-0.78\n",
            "2.0\n",
            "-0.27\n",
            "1.02\n",
            "0.51\n",
            "1.49\n",
            "-1.78\n",
            "2.0\n",
            "0.020000000000000018\n",
            "0.24\n",
            "0.0\n",
            "1.51\n",
            "-0.25\n",
            "1.29\n",
            "0.0\n",
            "0.020000000000000018\n",
            "1.46\n",
            "-0.27\n",
            "1.02\n",
            "0.27\n",
            "0.22\n",
            "0.22\n",
            "-0.49\n",
            "-0.27\n",
            "-1.49\n",
            "-0.22\n",
            "0.73\n",
            "-0.27\n",
            "0.98\n",
            "-0.98\n",
            "0.51\n",
            "0.020000000000000018\n",
            "0.25\n",
            "1.22\n",
            "0.25\n",
            "-0.51\n",
            "-0.27\n",
            "0.51\n",
            "1.27\n",
            "0.71\n",
            "0.29000000000000004\n",
            "0.49\n",
            "2.0\n",
            "-0.05000000000000002\n",
            "0.51\n",
            "1.56\n",
            "1.24\n",
            "2.0\n",
            "-0.49\n",
            "-1.0\n",
            "1.49\n",
            "1.22\n",
            "1.49\n",
            "0.51\n",
            "-0.71\n",
            "1.56\n",
            "0.95\n",
            "-0.19999999999999996\n",
            "-0.49\n",
            "0.73\n",
            "0.71\n",
            "-0.49\n",
            "1.29\n",
            "0.98\n",
            "-0.49\n",
            "-0.98\n",
            "-0.98\n",
            "1.56\n",
            "0.0\n",
            "1.56\n",
            "0.51\n",
            "-0.98\n",
            "-0.22\n",
            "-0.27\n",
            "-0.51\n",
            "0.78\n",
            "-0.49\n",
            "-1.49\n",
            "-0.27\n",
            "-1.0\n",
            "2.0\n",
            "1.02\n",
            "-0.27\n",
            "1.22\n",
            "0.0\n",
            "-0.27\n",
            "-0.49\n",
            "0.71\n",
            "-0.25\n",
            "1.73\n",
            "-0.27\n",
            "0.73\n",
            "1.0\n",
            "0.73\n",
            "0.49\n",
            "1.78\n",
            "0.0\n",
            "2.0\n",
            "0.98\n",
            "-0.47\n",
            "0.020000000000000018\n",
            "0.98\n",
            "0.98\n",
            "-0.98\n",
            "1.56\n",
            "0.98\n",
            "0.76\n",
            "0.75\n",
            "0.51\n",
            "0.98\n",
            "1.78\n",
            "-0.73\n",
            "-0.47\n",
            "-0.49\n",
            "-0.49\n",
            "1.51\n",
            "1.78\n",
            "0.24\n",
            "0.0\n",
            "-0.51\n",
            "1.02\n",
            "2.0\n",
            "1.0\n",
            "0.24\n",
            "0.0\n",
            "0.24\n",
            "0.76\n",
            "0.76\n",
            "-0.47\n",
            "0.31000000000000005\n",
            "0.0\n",
            "1.0\n",
            "0.98\n",
            "0.22\n",
            "-1.73\n",
            "-0.29000000000000004\n",
            "0.020000000000000018\n",
            "0.24\n",
            "0.8\n",
            "0.29000000000000004\n",
            "-0.27\n",
            "1.49\n",
            "0.98\n",
            "-0.27\n",
            "2.0\n",
            "1.29\n",
            "2.0\n",
            "-0.49\n",
            "0.0\n",
            "-0.24\n",
            "0.8\n",
            "-0.54\n",
            "2.0\n",
            "1.49\n",
            "0.49\n",
            "-0.27\n",
            "-0.49\n",
            "0.51\n",
            "-1.0\n",
            "1.0\n",
            "1.49\n",
            "0.75\n",
            "0.51\n",
            "-1.49\n",
            "0.19999999999999996\n",
            "-0.49\n",
            "1.27\n",
            "1.49\n",
            "0.0\n",
            "0.24\n",
            "-0.49\n",
            "0.98\n",
            "0.020000000000000018\n",
            "-0.71\n",
            "1.27\n",
            "1.78\n",
            "0.78\n",
            "1.51\n",
            "0.49\n",
            "0.75\n",
            "0.51\n",
            "-0.27\n",
            "0.51\n",
            "-0.24\n",
            "0.020000000000000018\n",
            "-0.47\n",
            "0.51\n",
            "0.24\n",
            "1.73\n",
            "0.0\n",
            "-0.27\n",
            "-1.0\n",
            "-1.27\n",
            "0.78\n",
            "0.020000000000000018\n",
            "-0.98\n",
            "0.98\n",
            "-0.27\n",
            "0.0\n",
            "1.51\n",
            "0.73\n",
            "-1.0\n",
            "-0.27\n",
            "0.020000000000000018\n",
            "-1.0\n",
            "-1.29\n",
            "0.73\n",
            "-0.98\n",
            "-0.51\n",
            "0.51\n",
            "1.78\n",
            "1.0\n",
            "0.98\n",
            "-0.49\n",
            "-1.0\n",
            "0.0\n",
            "0.49\n",
            "2.0\n",
            "0.27\n",
            "1.78\n",
            "-1.49\n",
            "0.22\n",
            "2.0\n",
            "2.0\n",
            "0.71\n",
            "0.0\n",
            "-1.0\n",
            "-1.0\n",
            "1.02\n",
            "0.78\n",
            "0.020000000000000018\n",
            "0.0\n",
            "-1.49\n",
            "0.73\n",
            "0.22\n",
            "2.0\n",
            "-0.22\n",
            "2.0\n",
            "-0.47\n",
            "0.0\n",
            "1.0\n",
            "0.49\n",
            "0.78\n",
            "1.24\n",
            "-1.0\n",
            "2.0\n",
            "-0.78\n",
            "0.0\n",
            "2.0\n",
            "-1.22\n",
            "-0.51\n",
            "-0.76\n",
            "-1.0\n",
            "0.51\n",
            "0.51\n",
            "1.78\n",
            "-0.49\n",
            "2.0\n",
            "-1.0\n",
            "-0.27\n",
            "0.78\n",
            "-1.73\n",
            "2.0\n",
            "-1.49\n",
            "-0.71\n",
            "-0.27\n",
            "0.020000000000000018\n",
            "-0.27\n",
            "0.0\n",
            "0.24\n",
            "0.98\n",
            "-0.47\n",
            "-1.22\n",
            "0.22\n",
            "0.24\n",
            "-0.27\n",
            "-0.020000000000000018\n",
            "1.49\n",
            "0.98\n",
            "-0.71\n",
            "1.24\n",
            "-1.22\n",
            "-0.19999999999999996\n",
            "1.56\n",
            "0.98\n",
            "-1.29\n",
            "1.0\n",
            "1.56\n",
            "0.98\n",
            "-0.27\n",
            "-1.49\n",
            "1.0\n",
            "0.24\n",
            "-0.19999999999999996\n",
            "-1.73\n",
            "-0.49\n",
            "0.76\n",
            "-1.0\n",
            "0.51\n",
            "2.0\n",
            "2.0\n",
            "-0.98\n",
            "0.0\n",
            "1.78\n",
            "1.24\n",
            "0.51\n",
            "1.02\n",
            "0.29000000000000004\n",
            "1.51\n",
            "-1.49\n",
            "-1.0\n",
            "0.22\n",
            "-0.56\n",
            "-0.51\n",
            "0.24\n",
            "1.27\n",
            "0.0\n",
            "0.040000000000000036\n",
            "1.51\n",
            "2.0\n",
            "1.27\n",
            "0.51\n",
            "0.29000000000000004\n",
            "-0.49\n",
            "0.51\n",
            "2.0\n",
            "2.0\n",
            "1.49\n",
            "0.29000000000000004\n",
            "-0.27\n",
            "1.0\n",
            "0.24\n",
            "0.51\n",
            "-0.24\n",
            "0.49\n",
            "1.78\n",
            "-0.78\n",
            "-1.0\n",
            "0.0\n",
            "0.020000000000000018\n",
            "0.24\n",
            "0.24\n",
            "0.0\n",
            "0.29000000000000004\n",
            "-1.73\n",
            "0.76\n",
            "0.51\n",
            "1.0\n",
            "-0.76\n",
            "0.49\n",
            "2.0\n",
            "1.49\n",
            "1.02\n",
            "1.27\n",
            "0.71\n",
            "-0.47\n",
            "1.78\n",
            "0.31000000000000005\n",
            "-1.51\n",
            "-0.49\n",
            "-0.98\n",
            "-0.49\n",
            "0.51\n",
            "0.24\n",
            "2.0\n",
            "0.0\n",
            "-0.98\n",
            "0.49\n",
            "0.0\n",
            "1.02\n",
            "2.0\n",
            "0.71\n",
            "2.0\n",
            "-0.020000000000000018\n",
            "-1.22\n",
            "-0.020000000000000018\n",
            "2.0\n",
            "1.29\n",
            "-0.47\n",
            "1.51\n",
            "0.51\n",
            "-0.78\n",
            "-0.27\n",
            "-0.54\n",
            "-0.78\n",
            "0.020000000000000018\n",
            "2.0\n",
            "-0.24\n",
            "0.51\n",
            "0.73\n",
            "0.27\n",
            "0.51\n",
            "0.0\n",
            "0.22\n",
            "-0.27\n",
            "-0.22\n",
            "-0.27\n",
            "-0.47\n",
            "2.0\n",
            "0.98\n",
            "0.78\n",
            "2.0\n",
            "0.98\n",
            "-0.27\n",
            "-0.49\n",
            "-0.030000000000000027\n",
            "1.73\n",
            "1.78\n",
            "-1.78\n",
            "1.0\n",
            "0.51\n",
            "0.27\n",
            "-0.49\n",
            "-0.49\n",
            "-0.49\n",
            "1.22\n",
            "0.49\n",
            "0.51\n",
            "0.27\n",
            "0.0\n",
            "1.49\n",
            "-1.22\n",
            "0.78\n",
            "0.0\n",
            "0.51\n",
            "1.73\n",
            "-0.98\n",
            "0.020000000000000018\n",
            "0.49\n",
            "1.56\n",
            "-1.29\n",
            "0.24\n",
            "-0.27\n",
            "0.29000000000000004\n",
            "-1.22\n",
            "0.51\n",
            "0.76\n",
            "-0.71\n",
            "0.76\n",
            "0.0\n",
            "0.22\n",
            "1.0\n",
            "-0.98\n",
            "1.56\n",
            "-0.45999999999999996\n",
            "1.49\n",
            "0.020000000000000018\n",
            "1.27\n",
            "-0.76\n",
            "0.8300000000000001\n",
            "0.24\n",
            "0.22\n",
            "0.73\n",
            "0.24\n",
            "-0.98\n",
            "0.98\n",
            "0.24\n",
            "0.07\n",
            "0.020000000000000018\n",
            "-0.22\n",
            "1.24\n",
            "2.0\n",
            "0.020000000000000018\n",
            "-1.0\n",
            "0.51\n",
            "0.73\n",
            "1.02\n",
            "-0.45999999999999996\n",
            "0.29000000000000004\n",
            "2.0\n",
            "1.22\n",
            "0.73\n",
            "-1.49\n",
            "0.51\n",
            "2.0\n",
            "-1.22\n",
            "-1.0\n",
            "0.51\n",
            "-0.19999999999999996\n",
            "1.27\n",
            "0.24\n",
            "0.07\n",
            "-0.47\n",
            "1.56\n",
            "0.51\n",
            "-0.71\n",
            "-1.22\n",
            "0.27\n",
            "0.0\n",
            "1.02\n",
            "0.29000000000000004\n",
            "-0.29000000000000004\n",
            "-0.05000000000000002\n",
            "-0.49\n",
            "-0.71\n",
            "1.07\n",
            "0.020000000000000018\n",
            "2.0\n",
            "0.0\n",
            "1.51\n",
            "1.49\n",
            "-0.51\n",
            "0.24\n",
            "1.0\n",
            "-0.49\n",
            "0.78\n",
            "-0.27\n",
            "-0.71\n",
            "0.0\n",
            "-0.27\n",
            "-0.29000000000000004\n",
            "1.0\n",
            "-1.0\n",
            "2.0\n",
            "-1.27\n",
            "0.24\n",
            "0.0\n",
            "0.040000000000000036\n",
            "0.0\n",
            "-0.76\n",
            "0.020000000000000018\n",
            "-0.49\n",
            "-0.19999999999999996\n",
            "2.0\n",
            "-0.98\n",
            "0.27\n",
            "-0.53\n",
            "0.22\n",
            "1.29\n",
            "2.0\n",
            "0.22\n",
            "0.98\n",
            "0.27\n",
            "0.97\n",
            "0.25\n",
            "1.02\n",
            "-0.27\n",
            "1.0\n",
            "0.78\n",
            "0.0\n",
            "-1.29\n",
            "-0.98\n",
            "1.49\n",
            "-1.0\n",
            "0.49\n",
            "-0.51\n",
            "-0.47\n",
            "-0.98\n",
            "-0.49\n",
            "0.47\n",
            "0.98\n",
            "-0.19999999999999996\n",
            "0.51\n",
            "0.71\n",
            "-0.98\n",
            "2.0\n",
            "0.71\n",
            "-1.51\n",
            "-0.49\n",
            "0.31000000000000005\n",
            "0.0\n",
            "0.27\n",
            "-0.76\n",
            "-1.51\n",
            "2.0\n",
            "-1.29\n",
            "0.22\n",
            "0.0\n",
            "1.24\n",
            "1.49\n",
            "-0.49\n",
            "0.76\n",
            "-0.98\n",
            "1.49\n",
            "0.0\n",
            "0.73\n",
            "-1.0\n",
            "0.0\n",
            "1.51\n",
            "0.020000000000000018\n",
            "0.24\n",
            "-1.0\n",
            "0.030000000000000027\n",
            "0.24\n",
            "1.22\n",
            "0.27\n",
            "-0.49\n",
            "2.0\n",
            "0.51\n",
            "-0.71\n",
            "0.22\n",
            "2.0\n",
            "-0.78\n",
            "0.0\n",
            "-0.27\n",
            "-0.49\n",
            "0.24\n",
            "1.22\n",
            "0.0\n",
            "-0.27\n",
            "0.24\n",
            "-0.47\n",
            "1.0\n",
            "0.27\n",
            "2.0\n",
            "-1.49\n",
            "-1.22\n",
            "0.020000000000000018\n",
            "0.0\n",
            "1.02\n",
            "-0.49\n",
            "2.0\n",
            "0.73\n",
            "-0.27\n",
            "0.51\n",
            "-0.19999999999999996\n",
            "2.0\n",
            "0.51\n",
            "-0.49\n",
            "-0.27\n",
            "1.27\n",
            "-0.22\n",
            "-1.49\n",
            "-0.78\n",
            "0.98\n",
            "0.020000000000000018\n",
            "1.78\n",
            "1.29\n",
            "0.98\n",
            "-0.22\n",
            "0.49\n",
            "-1.49\n",
            "0.71\n",
            "1.02\n",
            "1.56\n",
            "-1.0\n",
            "-1.22\n",
            "0.020000000000000018\n",
            "0.0\n",
            "1.27\n",
            "0.51\n",
            "-0.19999999999999996\n",
            "0.78\n",
            "0.0\n",
            "0.24\n",
            "0.49\n",
            "-0.22\n",
            "0.98\n",
            "0.0\n",
            "0.98\n",
            "1.0\n",
            "0.73\n",
            "-1.49\n",
            "-0.71\n",
            "1.51\n",
            "2.0\n",
            "1.56\n",
            "0.22\n",
            "2.0\n",
            "0.0\n",
            "-0.71\n",
            "2.0\n",
            "-0.22\n",
            "1.78\n",
            "-0.51\n",
            "1.02\n",
            "0.98\n",
            "-0.78\n",
            "1.51\n",
            "-1.22\n",
            "0.78\n",
            "2.0\n",
            "1.78\n",
            "0.73\n",
            "-1.49\n",
            "1.78\n",
            "2.0\n",
            "-0.98\n",
            "0.78\n",
            "-0.47\n",
            "1.49\n",
            "-0.19999999999999996\n",
            "0.030000000000000027\n",
            "1.51\n",
            "0.16999999999999998\n",
            "0.27\n",
            "1.56\n",
            "1.49\n",
            "0.22\n",
            "0.0\n",
            "1.78\n",
            "0.49\n",
            "0.020000000000000018\n",
            "-0.98\n",
            "0.78\n",
            "1.27\n",
            "0.24\n",
            "2.0\n",
            "0.22\n",
            "0.47\n",
            "0.49\n",
            "-0.020000000000000018\n",
            "0.51\n",
            "-0.98\n",
            "0.020000000000000018\n",
            "0.76\n",
            "0.27\n",
            "2.0\n",
            "0.27\n",
            "-0.78\n",
            "0.53\n",
            "-0.98\n",
            "1.49\n",
            "0.51\n",
            "0.020000000000000018\n",
            "-0.29000000000000004\n",
            "-1.49\n",
            "0.98\n",
            "-1.22\n",
            "0.51\n",
            "-1.49\n",
            "-1.49\n",
            "-0.97\n",
            "-0.27\n",
            "-0.49\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.51\n",
            "0.51\n",
            "0.51\n",
            "2.0\n",
            "1.02\n",
            "0.22\n",
            "1.0\n",
            "0.49\n",
            "0.51\n",
            "0.22\n",
            "-1.49\n",
            "1.51\n",
            "0.22\n",
            "-0.24\n",
            "2.0\n",
            "-0.26\n",
            "0.0\n",
            "0.49\n",
            "0.98\n",
            "-0.27\n",
            "1.49\n",
            "0.0\n",
            "1.56\n",
            "-0.49\n",
            "1.46\n",
            "2.0\n",
            "0.24\n",
            "-1.49\n",
            "-1.49\n",
            "-0.76\n",
            "0.020000000000000018\n",
            "0.75\n",
            "-0.27\n",
            "0.73\n",
            "0.51\n",
            "0.54\n",
            "0.76\n",
            "-0.27\n",
            "0.8\n",
            "2.0\n",
            "-0.49\n",
            "-1.22\n",
            "0.020000000000000018\n",
            "1.78\n",
            "-0.49\n",
            "0.19999999999999996\n",
            "0.020000000000000018\n",
            "-0.27\n",
            "1.27\n",
            "0.51\n",
            "-1.22\n",
            "0.73\n",
            "0.76\n",
            "1.07\n",
            "-0.27\n",
            "0.29000000000000004\n",
            "-1.49\n",
            "-0.29000000000000004\n",
            "1.49\n",
            "1.49\n",
            "0.49\n",
            "0.51\n",
            "-0.51\n",
            "0.0\n",
            "0.75\n",
            "1.78\n",
            "2.0\n",
            "0.020000000000000018\n",
            "1.49\n",
            "2.0\n",
            "1.24\n",
            "-0.27\n",
            "0.22\n",
            "1.0\n",
            "0.49\n",
            "-0.19999999999999996\n",
            "1.29\n",
            "1.0\n",
            "-1.51\n",
            "0.24\n",
            "-0.73\n",
            "0.22\n",
            "-0.19999999999999996\n",
            "-0.51\n",
            "1.24\n",
            "1.02\n",
            "0.51\n",
            "-0.76\n",
            "1.22\n",
            "1.46\n",
            "0.020000000000000018\n",
            "-0.76\n",
            "2.0\n",
            "0.24\n",
            "1.24\n",
            "0.95\n",
            "1.02\n",
            "-0.49\n",
            "1.51\n",
            "-1.0\n",
            "1.0\n",
            "0.07\n",
            "0.73\n",
            "0.73\n",
            "1.27\n",
            "-0.27\n",
            "1.05\n",
            "0.76\n",
            "0.51\n",
            "0.51\n",
            "0.49\n",
            "1.02\n",
            "0.53\n",
            "-0.49\n",
            "0.95\n",
            "0.27\n",
            "0.78\n",
            "0.020000000000000018\n",
            "0.49\n",
            "1.0\n",
            "-0.27\n",
            "0.51\n",
            "0.73\n",
            "-0.98\n",
            "-0.78\n",
            "0.24\n",
            "0.0\n",
            "0.51\n",
            "-0.73\n",
            "1.24\n",
            "0.22\n",
            "0.75\n",
            "0.020000000000000018\n",
            "-0.27\n",
            "0.51\n",
            "2.0\n",
            "1.51\n",
            "0.47\n",
            "-0.51\n",
            "-0.27\n",
            "0.020000000000000018\n",
            "-0.47\n",
            "2.0\n",
            "1.29\n",
            "0.29000000000000004\n",
            "0.0\n",
            "1.49\n",
            "1.78\n",
            "0.24\n",
            "0.0\n",
            "-0.49\n",
            "0.0\n",
            "0.22\n",
            "1.02\n",
            "0.020000000000000018\n",
            "-0.73\n",
            "-1.49\n",
            "0.8\n",
            "0.54\n",
            "0.51\n",
            "0.0\n",
            "0.78\n",
            "-1.0\n",
            "0.0\n",
            "-1.49\n",
            "0.78\n",
            "-0.24\n",
            "-0.49\n",
            "1.02\n",
            "2.0\n",
            "0.49\n",
            "1.56\n",
            "1.49\n",
            "1.51\n",
            "0.24\n",
            "0.020000000000000018\n",
            "-0.49\n",
            "-1.73\n",
            "1.78\n",
            "-0.78\n",
            "0.24\n",
            "1.02\n",
            "0.51\n",
            "-0.51\n",
            "2.0\n",
            "0.25\n",
            "-0.29000000000000004\n",
            "-1.49\n",
            "-0.51\n",
            "0.78\n",
            "1.19\n",
            "0.98\n",
            "2.0\n",
            "0.29000000000000004\n",
            "0.78\n",
            "0.49\n",
            "1.24\n",
            "0.0\n",
            "0.78\n",
            "0.24\n",
            "0.73\n",
            "0.020000000000000018\n",
            "0.24\n",
            "0.73\n",
            "0.0\n",
            "-1.49\n",
            "0.98\n",
            "1.0\n",
            "-1.22\n",
            "0.51\n",
            "0.0\n",
            "1.0\n",
            "1.78\n",
            "0.75\n",
            "1.27\n",
            "-0.19999999999999996\n",
            "0.76\n",
            "1.49\n",
            "-0.27\n",
            "1.02\n",
            "0.98\n",
            "0.51\n",
            "0.76\n",
            "-0.27\n",
            "1.0\n",
            "0.71\n",
            "0.020000000000000018\n",
            "0.49\n",
            "2.0\n",
            "0.0\n",
            "-0.71\n",
            "2.0\n",
            "0.27\n",
            "-0.27\n",
            "0.73\n",
            "-1.0\n",
            "1.49\n",
            "1.78\n",
            "0.98\n",
            "-0.71\n",
            "-0.78\n",
            "0.020000000000000018\n",
            "1.49\n",
            "-0.29000000000000004\n",
            "2.0\n",
            "1.0\n",
            "-0.76\n",
            "0.98\n",
            "-0.51\n",
            "0.98\n",
            "-0.51\n",
            "1.24\n",
            "1.24\n",
            "0.0\n",
            "0.0\n",
            "-0.78\n",
            "-0.49\n",
            "0.98\n",
            "-0.71\n",
            "0.020000000000000018\n",
            "1.49\n",
            "0.29000000000000004\n",
            "0.73\n",
            "-1.49\n",
            "0.78\n",
            "-0.47\n",
            "-0.49\n",
            "1.07\n",
            "-0.51\n",
            "0.0\n",
            "1.05\n",
            "-0.27\n",
            "1.78\n",
            "0.0\n",
            "-0.25\n",
            "-0.49\n",
            "1.49\n",
            "-0.27\n",
            "0.51\n",
            "0.0\n",
            "0.0\n",
            "-0.22\n",
            "0.73\n",
            "-0.47\n",
            "1.22\n",
            "-0.78\n",
            "-0.76\n",
            "-0.51\n",
            "2.0\n",
            "-0.71\n",
            "-0.27\n",
            "0.73\n",
            "0.27\n",
            "-0.71\n",
            "0.51\n",
            "-0.49\n",
            "-0.27\n",
            "-0.49\n",
            "0.0\n",
            "-1.22\n",
            "0.0\n",
            "-0.27\n",
            "2.0\n",
            "0.29000000000000004\n",
            "-1.27\n",
            "1.56\n",
            "-1.0\n",
            "-0.71\n",
            "0.47\n",
            "-0.98\n",
            "-0.49\n",
            "0.49\n",
            "-0.27\n",
            "1.27\n",
            "1.29\n",
            "-0.27\n",
            "-0.98\n",
            "1.56\n",
            "-0.19999999999999996\n",
            "1.02\n",
            "-0.19999999999999996\n",
            "-0.98\n",
            "1.27\n",
            "-0.19999999999999996\n",
            "-1.0\n",
            "-0.98\n",
            "-0.98\n",
            "1.02\n",
            "2.0\n",
            "1.56\n",
            "-0.27\n",
            "-0.47\n",
            "-0.78\n",
            "-1.22\n",
            "-0.47\n",
            "0.27\n",
            "1.78\n",
            "0.98\n",
            "0.51\n",
            "-0.78\n",
            "0.020000000000000018\n",
            "1.73\n",
            "0.0\n",
            "-0.51\n",
            "1.27\n",
            "0.020000000000000018\n",
            "0.22\n",
            "1.49\n",
            "0.24\n",
            "-0.49\n",
            "0.51\n",
            "1.02\n",
            "1.49\n",
            "1.22\n",
            "0.0\n",
            "1.49\n",
            "-0.25\n",
            "0.75\n",
            "0.020000000000000018\n",
            "0.27\n",
            "-1.49\n",
            "-0.27\n",
            "0.0\n",
            "1.22\n",
            "0.0\n",
            "-0.29000000000000004\n",
            "-0.49\n",
            "-0.49\n",
            "1.0\n",
            "2.0\n",
            "-1.27\n",
            "0.78\n",
            "0.47\n",
            "-0.27\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}